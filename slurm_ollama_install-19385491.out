üöÄ OLLAMA MODELS INSTALLER
================================================
Job ID: 19385491
Nodo: lrdn0393.leonardo.local
Data: Wed Aug 27 12:54:54 CEST 2025
User: smattiol

üìã MODELLI DA INSTALLARE:
  - qwen2.5:7b
  - qwen2.5:14b
  - deepseek-r1:32b
  - deepseek-v3:8b

üì¶ Setup ambiente HPC...
Loading python/3.11.6--gcc--8.5.0
  Loading requirement: bzip2/1.0.8-gp5wcz5 libmd/1.0.4-wja3f5q
    libbsd/0.11.7-cgxjopl expat/2.5.0-bptl3xw ncurses/6.4-asx3jea
    readline/8.2-nyw6mp6 gdbm/1.23-fs6otck libiconv/1.17-d7yvx2s
    xz/5.4.1-hubmwr5 zlib-ng/2.1.4-6htiapk libxml2/2.10.3-5eeeokp
    pigz/2.7-bopr5vp zstd/1.5.5-gawytfl tar/1.34-amqus5s gettext/0.22.3-2g7elif
    libffi/3.4.4-6r7brdq libxcrypt/4.4.35-ss2rzin sqlite/3.43.2
    util-linux-uuid/2.38.1-jkdi7kv
‚úÖ Python: Python 3.11.6
‚úÖ CUDA: Cuda compilation tools, release 12.3, V12.3.103

üîç GPU DETECTION:
0, NVIDIA A100-SXM-64GB, 65536 MiB, 42
1, NVIDIA A100-SXM-64GB, 65536 MiB, 43
2, NVIDIA A100-SXM-64GB, 65536 MiB, 42
3, NVIDIA A100-SXM-64GB, 65536 MiB, 42

üîß CONFIGURAZIONE:
- Ollama binary: /leonardo_work/IscrC_LLM-Mob/opt/bin/ollama
- Models directory: /leonardo_work/IscrC_LLM-Mob/.ollama/models
- Cache directory: /leonardo_work/IscrC_LLM-Mob/.ollama/cache
- Temp directory: /leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385491

üíæ VERIFICA SPAZIO DISCO
========================
Spazio disponibile: 919GB
Spazio attuale Ollama: 47G

üßπ Cleanup preventivo...
üöÄ Avvio server Ollama...
Server PID: 637337
‚è≥ Attesa disponibilit√† API...
‚úÖ Server pronto dopo 1 tentativi!

üìã MODELLI INSTALLATI (PRIMA)
--------------------------
NAME                  ID              SIZE      MODIFIED    
deepseek-coder:33b    acec7c0b0fd9    18 GB     2 weeks ago    
mixtral:8x7b          a3b6bef0f836    26 GB     2 weeks ago    
llama3.1:8b           46e0c10c039e    4.9 GB    8 weeks ago    

üìä Totale modelli: 3

üíæ SPAZIO DISCO PRE-INSTALLAZIONE
=================================
Filesystem                                        Size  Used Avail Use% Mounted on
10.128.82.1@o2ib:10.128.82.2@o2ib:/larchive/work  1.0T  107G  918G  11% /leonardo_work

üöÄ INIZIO INSTALLAZIONI
=======================
Totale modelli da processare: 4

üìç Progresso: 1/4

üîΩ INSTALLAZIONE: qwen2.5:7b
---------------------------
Inizio: Wed Aug 27 12:56:13 CEST 2025
üì• Download e installazione in corso...
   (Questo pu√≤ richiedere molto tempo per modelli grandi)
/var/spool/slurmd/job19385491/slurm_script: line 283: 637421 Terminated              { while kill -0 $$ 2> /dev/null; do
    sleep 60; echo "‚è≥ $(date): Download $model ancora in corso..."; echo "   GPU Status:"; nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv,noheader,nounits | while IFS=',' read -r idx mem_used mem_total; do
        mem_percent=$((mem_used * 100 / mem_total)); printf "     GPU %s: %d%% (%d/%d MB)\n" "$idx" "$mem_percent" "$mem_used" "$mem_total";
    done; local space_now=$(df "$WORK" | tail -1 | awk '{print $4}'); local space_now_gb=$((space_now / 1024 / 1024)); echo "   Spazio rimanente: ${space_now_gb}GB";
done; }
‚ùå qwen2.5:7b installazione fallita!
   Tempo impiegato: 0 minuti
   Exit code: 1

Ultime righe output:
   [?25lpulling manifest ‚†ã [?25h[?25l[2K[1Gpulling manifest ‚†ô [?25h[?25l[2K[1Gpulling manifest [?25h
   Error: pull model manifest: Get "https://registry.ollama.ai/v2/library/qwen2.5/manifests/7b": dial tcp 172.67.182.229:443: connect: network is unreachable

‚ö†Ô∏è Installazione qwen2.5:7b fallita. Continuo con il prossimo...
/var/spool/slurmd/job19385491/slurm_script: line 358: local: can only be used in a function
/var/spool/slurmd/job19385491/slurm_script: line 359: local: can only be used in a function
/var/spool/slurmd/job19385491/slurm_script: line 360: [: -lt: unary operator expected

üìä Stato attuale: ‚úÖ0 ‚ùå1

‚è∏Ô∏è Pausa 30s prima del prossimo modello...
üìç Progresso: 2/4

üîΩ INSTALLAZIONE: qwen2.5:14b
----------------------------
Inizio: Wed Aug 27 12:56:43 CEST 2025
üì• Download e installazione in corso...
   (Questo pu√≤ richiedere molto tempo per modelli grandi)
/var/spool/slurmd/job19385491/slurm_script: line 283: 637466 Terminated              { while kill -0 $$ 2> /dev/null; do
    sleep 60; echo "‚è≥ $(date): Download $model ancora in corso..."; echo "   GPU Status:"; nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv,noheader,nounits | while IFS=',' read -r idx mem_used mem_total; do
        mem_percent=$((mem_used * 100 / mem_total)); printf "     GPU %s: %d%% (%d/%d MB)\n" "$idx" "$mem_percent" "$mem_used" "$mem_total";
    done; local space_now=$(df "$WORK" | tail -1 | awk '{print $4}'); local space_now_gb=$((space_now / 1024 / 1024)); echo "   Spazio rimanente: ${space_now_gb}GB";
done; }
‚ùå qwen2.5:14b installazione fallita!
   Tempo impiegato: 0 minuti
   Exit code: 1

Ultime righe output:
   [?25lpulling manifest [?25h
   Error: pull model manifest: Get "https://registry.ollama.ai/v2/library/qwen2.5/manifests/14b": dial tcp 172.67.182.229:443: connect: network is unreachable

‚ö†Ô∏è Installazione qwen2.5:14b fallita. Continuo con il prossimo...
/var/spool/slurmd/job19385491/slurm_script: line 358: local: can only be used in a function
/var/spool/slurmd/job19385491/slurm_script: line 359: local: can only be used in a function
/var/spool/slurmd/job19385491/slurm_script: line 360: [: -lt: unary operator expected

üìä Stato attuale: ‚úÖ0 ‚ùå2

‚è∏Ô∏è Pausa 30s prima del prossimo modello...
üìç Progresso: 3/4

üîΩ INSTALLAZIONE: deepseek-r1:32b
--------------------------------
Inizio: Wed Aug 27 12:57:13 CEST 2025
üì• Download e installazione in corso...
   (Questo pu√≤ richiedere molto tempo per modelli grandi)
/var/spool/slurmd/job19385491/slurm_script: line 283: 637506 Terminated              { while kill -0 $$ 2> /dev/null; do
    sleep 60; echo "‚è≥ $(date): Download $model ancora in corso..."; echo "   GPU Status:"; nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv,noheader,nounits | while IFS=',' read -r idx mem_used mem_total; do
        mem_percent=$((mem_used * 100 / mem_total)); printf "     GPU %s: %d%% (%d/%d MB)\n" "$idx" "$mem_percent" "$mem_used" "$mem_total";
    done; local space_now=$(df "$WORK" | tail -1 | awk '{print $4}'); local space_now_gb=$((space_now / 1024 / 1024)); echo "   Spazio rimanente: ${space_now_gb}GB";
done; }
‚ùå deepseek-r1:32b installazione fallita!
   Tempo impiegato: 0 minuti
   Exit code: 1

Ultime righe output:
   [?25lpulling manifest [?25h
   Error: pull model manifest: Get "https://registry.ollama.ai/v2/library/deepseek-r1/manifests/32b": dial tcp 104.21.75.227:443: connect: network is unreachable

‚ö†Ô∏è Installazione deepseek-r1:32b fallita. Continuo con il prossimo...
/var/spool/slurmd/job19385491/slurm_script: line 358: local: can only be used in a function
/var/spool/slurmd/job19385491/slurm_script: line 359: local: can only be used in a function
/var/spool/slurmd/job19385491/slurm_script: line 360: [: -lt: unary operator expected

üìä Stato attuale: ‚úÖ0 ‚ùå3

‚è∏Ô∏è Pausa 30s prima del prossimo modello...
üìç Progresso: 4/4

üîΩ INSTALLAZIONE: deepseek-v3:8b
-------------------------------
Inizio: Wed Aug 27 12:57:43 CEST 2025
üì• Download e installazione in corso...
   (Questo pu√≤ richiedere molto tempo per modelli grandi)
/var/spool/slurmd/job19385491/slurm_script: line 283: 637551 Terminated              { while kill -0 $$ 2> /dev/null; do
    sleep 60; echo "‚è≥ $(date): Download $model ancora in corso..."; echo "   GPU Status:"; nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv,noheader,nounits | while IFS=',' read -r idx mem_used mem_total; do
        mem_percent=$((mem_used * 100 / mem_total)); printf "     GPU %s: %d%% (%d/%d MB)\n" "$idx" "$mem_percent" "$mem_used" "$mem_total";
    done; local space_now=$(df "$WORK" | tail -1 | awk '{print $4}'); local space_now_gb=$((space_now / 1024 / 1024)); echo "   Spazio rimanente: ${space_now_gb}GB";
done; }
‚ùå deepseek-v3:8b installazione fallita!
   Tempo impiegato: 0 minuti
   Exit code: 1

Ultime righe output:
   [?25lpulling manifest [?25h
   Error: pull model manifest: Get "https://registry.ollama.ai/v2/library/deepseek-v3/manifests/8b": dial tcp 172.67.182.229:443: connect: network is unreachable

‚ö†Ô∏è Installazione deepseek-v3:8b fallita. Continuo con il prossimo...
/var/spool/slurmd/job19385491/slurm_script: line 358: local: can only be used in a function
/var/spool/slurmd/job19385491/slurm_script: line 359: local: can only be used in a function
/var/spool/slurmd/job19385491/slurm_script: line 360: [: -lt: unary operator expected

üìä Stato attuale: ‚úÖ0 ‚ùå4


üèÅ INSTALLAZIONI COMPLETATE
============================

üìã MODELLI INSTALLATI (DOPO)
-------------------------
NAME                  ID              SIZE      MODIFIED    
deepseek-coder:33b    acec7c0b0fd9    18 GB     2 weeks ago    
mixtral:8x7b          a3b6bef0f836    26 GB     2 weeks ago    
llama3.1:8b           46e0c10c039e    4.9 GB    8 weeks ago    

üìä Totale modelli: 3

üíæ SPAZIO DISCO POST-INSTALLAZIONE
==================================
Filesystem                                        Size  Used Avail Use% Mounted on
10.128.82.1@o2ib:10.128.82.2@o2ib:/larchive/work  1.0T  107G  918G  11% /leonardo_work

Spazio totale utilizzato da Ollama:
47G	/leonardo_work/IscrC_LLM-Mob/.ollama/models

Top 10 file pi√π grandi:
25G	/leonardo_work/IscrC_LLM-Mob/.ollama/models/blobs/sha256-f2dc41fa964b42bfe34e9fb09c0acdcfbfd6e52f1332930b4eacc9d6ad1c6cd2
18G	/leonardo_work/IscrC_LLM-Mob/.ollama/models/blobs/sha256-065b9a7416ba28634cd4efc2cd3024d4755731c1275dc0286b81b01793185fbb
4.6G	/leonardo_work/IscrC_LLM-Mob/.ollama/models/blobs/sha256-667b0c1932bc6ffc593ed1d03f895bf2dc8dc6df21db3042284a6f4416b06a29
16K	/leonardo_work/IscrC_LLM-Mob/.ollama/models/blobs/sha256-a3a0e9449cb691a12f4de1d03725fd41326614fdeaf5d80b28c51187da0bed0e
16K	/leonardo_work/IscrC_LLM-Mob/.ollama/models/blobs/sha256-0ba8f0e314b4264dfd19df045cde9d4c394a52474bf92ed6a3de22a4ca31a177
12K	/leonardo_work/IscrC_LLM-Mob/.ollama/models/blobs/sha256-43070e2d4e532684de521b885f385d0841030efa2b1a20bafb76133a5e1379c1
4.0K	/leonardo_work/IscrC_LLM-Mob/.ollama/models/manifests/registry.ollama.ai/library/mixtral/8x7b
4.0K	/leonardo_work/IscrC_LLM-Mob/.ollama/models/manifests/registry.ollama.ai/library/llama3.1/8b
4.0K	/leonardo_work/IscrC_LLM-Mob/.ollama/models/manifests/registry.ollama.ai/library/deepseek-coder/33b
4.0K	/leonardo_work/IscrC_LLM-Mob/.ollama/models/blobs/sha256-ed11eda7790d05b49395598a42b155812b17e263214292f7b87d15e14003d337

üìä RIEPILOGO FINALE
===================
Modelli da installare: 4
‚úÖ Installazioni riuscite: 0
‚ùå Installazioni fallite: 4
‚è≠Ô∏è Installazioni saltate: 0
‚è±Ô∏è Tempo totale: 2 minuti

üìú Log dettagliato disponibile in: ollama_installation_detailed.log
Dimensione log: 4.0K

üèÅ JOB COMPLETATO
=================
‚ùå Nessun modello installato

üßπ Cleanup finale...
Stopping Ollama server (PID 637337)...
Removing temporary directory...
‚úÖ Cleanup completato
