2025/08/27 13:03:20 routes.go:1158: INFO server config env="map[CUDA_VISIBLE_DEVICES:0 GPU_DEVICE_ORDINAL:0,1,2,3 HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_DEBUG:true OLLAMA_FLASH_ATTENTION:true OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:39000 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:30m0s OLLAMA_LLM_LIBRARY:cuda_v12 OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/leonardo_work/IscrC_LLM-Mob/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_SCHED_SPREAD:false OLLAMA_TMPDIR:/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385776 ROCR_VISIBLE_DEVICES:0,1,2,3 http_proxy: https_proxy: no_proxy:]"
time=2025-08-27T13:03:20.100+02:00 level=INFO source=images.go:754 msg="total blobs: 15"
time=2025-08-27T13:03:20.164+02:00 level=INFO source=images.go:761 msg="total unused blobs removed: 0"
time=2025-08-27T13:03:20.183+02:00 level=INFO source=routes.go:1205 msg="Listening on 127.0.0.1:39000 (version 0.3.14)"
time=2025-08-27T13:03:20.199+02:00 level=INFO source=common.go:135 msg="extracting embedded files" dir=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385776/ollama1781197213/runners
time=2025-08-27T13:03:20.216+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu payload=linux/amd64/cpu/libggml.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu payload=linux/amd64/cpu/libllama.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu payload=linux/amd64/cpu/ollama_llama_server.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx payload=linux/amd64/cpu_avx/libggml.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx payload=linux/amd64/cpu_avx/libllama.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx payload=linux/amd64/cpu_avx/ollama_llama_server.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx2 payload=linux/amd64/cpu_avx2/libggml.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx2 payload=linux/amd64/cpu_avx2/libllama.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx2 payload=linux/amd64/cpu_avx2/ollama_llama_server.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v11 payload=linux/amd64/cuda_v11/libggml.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v11 payload=linux/amd64/cuda_v11/libllama.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v11 payload=linux/amd64/cuda_v11/ollama_llama_server.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v12 payload=linux/amd64/cuda_v12/libggml.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v12 payload=linux/amd64/cuda_v12/libllama.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v12 payload=linux/amd64/cuda_v12/ollama_llama_server.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=rocm_v60102 payload=linux/amd64/rocm_v60102/libggml.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=rocm_v60102 payload=linux/amd64/rocm_v60102/libllama.so.gz
time=2025-08-27T13:03:20.220+02:00 level=DEBUG source=common.go:168 msg=extracting runner=rocm_v60102 payload=linux/amd64/rocm_v60102/ollama_llama_server.gz
time=2025-08-27T13:04:47.979+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385776/ollama1781197213/runners/cpu/ollama_llama_server
time=2025-08-27T13:04:47.981+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385776/ollama1781197213/runners/cpu_avx/ollama_llama_server
time=2025-08-27T13:04:47.981+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385776/ollama1781197213/runners/cpu_avx2/ollama_llama_server
time=2025-08-27T13:04:47.981+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385776/ollama1781197213/runners/cuda_v11/ollama_llama_server
time=2025-08-27T13:04:47.981+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385776/ollama1781197213/runners/cuda_v12/ollama_llama_server
time=2025-08-27T13:04:47.981+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385776/ollama1781197213/runners/rocm_v60102/ollama_llama_server
time=2025-08-27T13:04:47.981+02:00 level=INFO source=common.go:49 msg="Dynamic LLM libraries" runners="[cuda_v12 rocm_v60102 cpu cpu_avx cpu_avx2 cuda_v11]"
time=2025-08-27T13:04:47.982+02:00 level=DEBUG source=common.go:50 msg="Override detection logic by setting OLLAMA_LLM_LIBRARY"
time=2025-08-27T13:04:47.982+02:00 level=DEBUG source=sched.go:105 msg="starting llm scheduler"
time=2025-08-27T13:04:47.995+02:00 level=INFO source=gpu.go:221 msg="looking for compatible GPUs"
time=2025-08-27T13:04:48.047+02:00 level=DEBUG source=gpu.go:94 msg="searching for GPU discovery libraries for NVIDIA"
time=2025-08-27T13:04:48.047+02:00 level=DEBUG source=gpu.go:505 msg="Searching for GPU library" name=libcuda.so*
time=2025-08-27T13:04:48.047+02:00 level=DEBUG source=gpu.go:528 msg="gpu library search" globs="[/leonardo_work/IscrC_LLM-Mob/opt/lib/ollama/libcuda.so* /leonardo/prod/opt/compilers/cuda/12.3/none/lib64/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/python-3.11.6-i5k3c6ggftqkzgqyymfbkynpgm2lgjtd/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/util-linux-uuid-2.38.1-jkdi7kvvma7367qdmvpkada4pyiafoud/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/sqlite-3.43.2-casyrltocz5edzjhs5vzlqhwkamn7y4a/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libxcrypt-4.4.35-ss2rzin25ozjy4gyy3dack36njs6navg/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libffi-3.4.4-6r7brdq5dnreoad6f7sn7ybjjvwdmvue/lib64/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libffi-3.4.4-6r7brdq5dnreoad6f7sn7ybjjvwdmvue/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/gettext-0.22.3-2g7elifkgxzpypbswqnjuu5hefn4mjts/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/zstd-1.5.5-gawytflrhedqdc2riwax7oduoqddx22s/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libxml2-2.10.3-5eeeokp4kszufozbayq4bewwmyeuwy27/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/zlib-ng-2.1.4-6htiapkoa6fx2medhyabzo575skozuir/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/xz-5.4.1-hubmwr5wc5nf6zk3ghuaikxiejuyt6bi/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libiconv-1.17-d7yvx2s6da4x2rfx44bc3perbb33rvuy/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/gdbm-1.23-fs6otcki47azeywcckquj2sy4mzsnzxg/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/readline-8.2-nyw6mp6b7dvizewrf7exopvap2q32s5j/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/ncurses-6.4-asx3jea367shsxjt6bdj2bu5olxll6ni/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/expat-2.5.0-bptl3xwbvbkxxoc5x3dhviorarv4dvxv/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libbsd-0.11.7-cgxjopleu7se4y4cgi7oefbljgasr457/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libmd-1.0.4-wja3f5q3w75tqtro333fptfnji7oqxiu/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/bzip2-1.0.8-gp5wcz5lksrbm2gqiqjppumrhjz6gahy/lib/libcuda.so* /usr/local/cuda*/targets/*/lib/libcuda.so* /usr/lib/*-linux-gnu/nvidia/current/libcuda.so* /usr/lib/*-linux-gnu/libcuda.so* /usr/lib/wsl/lib/libcuda.so* /usr/lib/wsl/drivers/*/libcuda.so* /opt/cuda/lib*/libcuda.so* /usr/local/cuda/lib*/libcuda.so* /usr/lib*/libcuda.so* /usr/local/lib*/libcuda.so*]"
time=2025-08-27T13:04:48.085+02:00 level=DEBUG source=gpu.go:562 msg="discovered GPU libraries" paths=[/usr/lib64/libcuda.so.535.54.03]
CUDA driver version: 12.2
time=2025-08-27T13:04:48.125+02:00 level=DEBUG source=gpu.go:129 msg="detected GPUs" count=1 library=/usr/lib64/libcuda.so.535.54.03
[GPU-4ab555c7-8ba0-b4ab-ba6c-69e72dfcd0b0] CUDA totalMem 64944 mb
[GPU-4ab555c7-8ba0-b4ab-ba6c-69e72dfcd0b0] CUDA freeMem 64462 mb
[GPU-4ab555c7-8ba0-b4ab-ba6c-69e72dfcd0b0] Compute Capability 8.0
time=2025-08-27T13:04:48.227+02:00 level=DEBUG source=amd_linux.go:416 msg="amdgpu driver not detected /sys/module/amdgpu"
releasing cuda driver library
time=2025-08-27T13:04:48.227+02:00 level=INFO source=types.go:123 msg="inference compute" id=GPU-4ab555c7-8ba0-b4ab-ba6c-69e72dfcd0b0 library=cuda variant=v12 compute=8.0 driver=12.2 name="NVIDIA A100-SXM-64GB" total="63.4 GiB" available="63.0 GiB"
[GIN] 2025/08/27 - 13:04:48 | 200 |    8.352952ms |       127.0.0.1 | GET      "/api/version"
[GIN] 2025/08/27 - 13:04:48 | 200 |      27.425µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/27 - 13:04:48 | 200 |    49.50238ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/08/27 - 13:04:48 | 200 |      12.595µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/27 - 13:04:48 | 200 |   15.783731ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/08/27 - 13:04:48 | 200 |      11.779µs |       127.0.0.1 | HEAD     "/"
time=2025-08-27T13:04:48.707+02:00 level=INFO source=images.go:1021 msg="request failed: Get \"https://registry.ollama.ai/v2/library/qwen2.5/manifests/7b\": dial tcp 172.67.182.229:443: connect: network is unreachable"
[GIN] 2025/08/27 - 13:04:48 | 200 |   96.246985ms |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/08/27 - 13:05:18 | 200 |      18.374µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/27 - 13:05:18 | 200 |    7.249975ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/08/27 - 13:05:18 | 200 |      13.996µs |       127.0.0.1 | HEAD     "/"
time=2025-08-27T13:05:18.845+02:00 level=INFO source=images.go:1021 msg="request failed: Get \"https://registry.ollama.ai/v2/library/qwen2.5/manifests/14b\": dial tcp 104.21.75.227:443: connect: network is unreachable"
[GIN] 2025/08/27 - 13:05:18 | 200 |   34.248322ms |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/08/27 - 13:05:48 | 200 |      20.684µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/27 - 13:05:48 | 200 |    6.259565ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/08/27 - 13:05:48 | 200 |      11.902µs |       127.0.0.1 | HEAD     "/"
time=2025-08-27T13:05:48.987+02:00 level=INFO source=images.go:1021 msg="request failed: Get \"https://registry.ollama.ai/v2/library/deepseek-r1/manifests/32b\": dial tcp 104.21.75.227:443: connect: network is unreachable"
[GIN] 2025/08/27 - 13:05:48 | 200 |   30.373449ms |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/08/27 - 13:06:19 | 200 |      14.061µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/27 - 13:06:19 | 200 |    4.582733ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/08/27 - 13:06:19 | 200 |      11.933µs |       127.0.0.1 | HEAD     "/"
time=2025-08-27T13:06:19.171+02:00 level=INFO source=images.go:1021 msg="request failed: Get \"https://registry.ollama.ai/v2/library/deepseek-v3/manifests/8b\": dial tcp 172.67.182.229:443: connect: network is unreachable"
[GIN] 2025/08/27 - 13:06:19 | 200 |      6.3499ms |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/08/27 - 13:06:19 | 200 |      10.875µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/27 - 13:06:19 | 200 |    8.129386ms |       127.0.0.1 | GET      "/api/tags"
time=2025-08-27T13:06:19.395+02:00 level=DEBUG source=common.go:73 msg="cleaning up" dir=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19385776/ollama1781197213
time=2025-08-27T13:06:19.395+02:00 level=DEBUG source=sched.go:119 msg="shutting down scheduler pending loop"
time=2025-08-27T13:06:19.395+02:00 level=DEBUG source=sched.go:318 msg="shutting down scheduler completed loop"
