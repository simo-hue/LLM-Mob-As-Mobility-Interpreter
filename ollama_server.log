2025/08/27 11:15:51 routes.go:1158: INFO server config env="map[CUDA_VISIBLE_DEVICES:0 GPU_DEVICE_ORDINAL:0,1,2,3 HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_DEBUG:true OLLAMA_FLASH_ATTENTION:true OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:39000 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:30m0s OLLAMA_LLM_LIBRARY:cuda_v12 OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/leonardo_work/IscrC_LLM-Mob/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_SCHED_SPREAD:false OLLAMA_TMPDIR:/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079 ROCR_VISIBLE_DEVICES:0,1,2,3 http_proxy: https_proxy: no_proxy:]"
time=2025-08-27T11:15:51.512+02:00 level=INFO source=images.go:754 msg="total blobs: 15"
time=2025-08-27T11:15:51.554+02:00 level=INFO source=images.go:761 msg="total unused blobs removed: 0"
time=2025-08-27T11:15:51.572+02:00 level=INFO source=routes.go:1205 msg="Listening on 127.0.0.1:39000 (version 0.3.14)"
time=2025-08-27T11:15:51.580+02:00 level=INFO source=common.go:135 msg="extracting embedded files" dir=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079/ollama321408910/runners
time=2025-08-27T11:15:51.596+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu payload=linux/amd64/cpu/libggml.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu payload=linux/amd64/cpu/libllama.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu payload=linux/amd64/cpu/ollama_llama_server.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx payload=linux/amd64/cpu_avx/libggml.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx payload=linux/amd64/cpu_avx/libllama.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx payload=linux/amd64/cpu_avx/ollama_llama_server.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx2 payload=linux/amd64/cpu_avx2/libggml.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx2 payload=linux/amd64/cpu_avx2/libllama.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cpu_avx2 payload=linux/amd64/cpu_avx2/ollama_llama_server.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v11 payload=linux/amd64/cuda_v11/libggml.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v11 payload=linux/amd64/cuda_v11/libllama.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v11 payload=linux/amd64/cuda_v11/ollama_llama_server.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v12 payload=linux/amd64/cuda_v12/libggml.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v12 payload=linux/amd64/cuda_v12/libllama.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=cuda_v12 payload=linux/amd64/cuda_v12/ollama_llama_server.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=rocm_v60102 payload=linux/amd64/rocm_v60102/libggml.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=rocm_v60102 payload=linux/amd64/rocm_v60102/libllama.so.gz
time=2025-08-27T11:15:51.599+02:00 level=DEBUG source=common.go:168 msg=extracting runner=rocm_v60102 payload=linux/amd64/rocm_v60102/ollama_llama_server.gz
time=2025-08-27T11:16:34.192+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079/ollama321408910/runners/cpu/ollama_llama_server
time=2025-08-27T11:16:34.192+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079/ollama321408910/runners/cpu_avx/ollama_llama_server
time=2025-08-27T11:16:34.192+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079/ollama321408910/runners/cpu_avx2/ollama_llama_server
time=2025-08-27T11:16:34.192+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079/ollama321408910/runners/cuda_v11/ollama_llama_server
time=2025-08-27T11:16:34.192+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079/ollama321408910/runners/cuda_v12/ollama_llama_server
time=2025-08-27T11:16:34.192+02:00 level=DEBUG source=common.go:294 msg="availableServers : found" file=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079/ollama321408910/runners/rocm_v60102/ollama_llama_server
time=2025-08-27T11:16:34.192+02:00 level=INFO source=common.go:49 msg="Dynamic LLM libraries" runners="[rocm_v60102 cpu cpu_avx cpu_avx2 cuda_v11 cuda_v12]"
time=2025-08-27T11:16:34.192+02:00 level=DEBUG source=common.go:50 msg="Override detection logic by setting OLLAMA_LLM_LIBRARY"
time=2025-08-27T11:16:34.192+02:00 level=DEBUG source=sched.go:105 msg="starting llm scheduler"
time=2025-08-27T11:16:34.203+02:00 level=INFO source=gpu.go:221 msg="looking for compatible GPUs"
time=2025-08-27T11:16:34.242+02:00 level=DEBUG source=gpu.go:94 msg="searching for GPU discovery libraries for NVIDIA"
time=2025-08-27T11:16:34.242+02:00 level=DEBUG source=gpu.go:505 msg="Searching for GPU library" name=libcuda.so*
time=2025-08-27T11:16:34.242+02:00 level=DEBUG source=gpu.go:528 msg="gpu library search" globs="[/leonardo_work/IscrC_LLM-Mob/opt/lib/ollama/libcuda.so* /leonardo/prod/opt/compilers/cuda/12.3/none/lib64/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/python-3.11.6-i5k3c6ggftqkzgqyymfbkynpgm2lgjtd/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/util-linux-uuid-2.38.1-jkdi7kvvma7367qdmvpkada4pyiafoud/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/sqlite-3.43.2-casyrltocz5edzjhs5vzlqhwkamn7y4a/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libxcrypt-4.4.35-ss2rzin25ozjy4gyy3dack36njs6navg/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libffi-3.4.4-6r7brdq5dnreoad6f7sn7ybjjvwdmvue/lib64/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libffi-3.4.4-6r7brdq5dnreoad6f7sn7ybjjvwdmvue/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/gettext-0.22.3-2g7elifkgxzpypbswqnjuu5hefn4mjts/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/zstd-1.5.5-gawytflrhedqdc2riwax7oduoqddx22s/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libxml2-2.10.3-5eeeokp4kszufozbayq4bewwmyeuwy27/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/zlib-ng-2.1.4-6htiapkoa6fx2medhyabzo575skozuir/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/xz-5.4.1-hubmwr5wc5nf6zk3ghuaikxiejuyt6bi/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libiconv-1.17-d7yvx2s6da4x2rfx44bc3perbb33rvuy/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/gdbm-1.23-fs6otcki47azeywcckquj2sy4mzsnzxg/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/readline-8.2-nyw6mp6b7dvizewrf7exopvap2q32s5j/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/ncurses-6.4-asx3jea367shsxjt6bdj2bu5olxll6ni/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/expat-2.5.0-bptl3xwbvbkxxoc5x3dhviorarv4dvxv/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libbsd-0.11.7-cgxjopleu7se4y4cgi7oefbljgasr457/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/libmd-1.0.4-wja3f5q3w75tqtro333fptfnji7oqxiu/lib/libcuda.so* /leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/bzip2-1.0.8-gp5wcz5lksrbm2gqiqjppumrhjz6gahy/lib/libcuda.so* /usr/local/cuda*/targets/*/lib/libcuda.so* /usr/lib/*-linux-gnu/nvidia/current/libcuda.so* /usr/lib/*-linux-gnu/libcuda.so* /usr/lib/wsl/lib/libcuda.so* /usr/lib/wsl/drivers/*/libcuda.so* /opt/cuda/lib*/libcuda.so* /usr/local/cuda/lib*/libcuda.so* /usr/lib*/libcuda.so* /usr/local/lib*/libcuda.so*]"
time=2025-08-27T11:16:34.253+02:00 level=DEBUG source=gpu.go:562 msg="discovered GPU libraries" paths=[/usr/lib64/libcuda.so.535.54.03]
CUDA driver version: 12.2
time=2025-08-27T11:16:34.283+02:00 level=DEBUG source=gpu.go:129 msg="detected GPUs" count=1 library=/usr/lib64/libcuda.so.535.54.03
[GPU-81d3fe40-6a24-aac7-16be-3cf641fccb6b] CUDA totalMem 64944 mb
[GPU-81d3fe40-6a24-aac7-16be-3cf641fccb6b] CUDA freeMem 64462 mb
[GPU-81d3fe40-6a24-aac7-16be-3cf641fccb6b] Compute Capability 8.0
time=2025-08-27T11:16:34.384+02:00 level=DEBUG source=amd_linux.go:416 msg="amdgpu driver not detected /sys/module/amdgpu"
releasing cuda driver library
time=2025-08-27T11:16:34.384+02:00 level=INFO source=types.go:123 msg="inference compute" id=GPU-81d3fe40-6a24-aac7-16be-3cf641fccb6b library=cuda variant=v12 compute=8.0 driver=12.2 name="NVIDIA A100-SXM-64GB" total="63.4 GiB" available="63.0 GiB"
[GIN] 2025/08/27 - 11:16:34 | 200 |      82.062µs |       127.0.0.1 | GET      "/api/version"
[GIN] 2025/08/27 - 11:16:34 | 200 |      24.575µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/27 - 11:16:34 | 200 |   28.317478ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/08/27 - 11:16:34 | 200 |      13.439µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/27 - 11:16:34 | 200 |    3.027101ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/08/27 - 11:16:34 | 200 |      11.638µs |       127.0.0.1 | HEAD     "/"
time=2025-08-27T11:16:34.807+02:00 level=INFO source=images.go:1021 msg="request failed: Get \"https://registry.ollama.ai/v2/library/qwen2.5/manifests/7b\": dial tcp 104.21.75.227:443: connect: network is unreachable"
[GIN] 2025/08/27 - 11:16:34 | 200 |  195.781637ms |       127.0.0.1 | POST     "/api/pull"
[GIN] 2025/08/27 - 11:17:04 | 200 |      15.932µs |       127.0.0.1 | HEAD     "/"
[GIN] 2025/08/27 - 11:17:04 | 200 |    2.859226ms |       127.0.0.1 | GET      "/api/tags"
[GIN] 2025/08/27 - 11:17:04 | 200 |      13.816µs |       127.0.0.1 | HEAD     "/"
time=2025-08-27T11:17:05.040+02:00 level=INFO source=images.go:1021 msg="request failed: Get \"https://registry.ollama.ai/v2/library/qwen2.5/manifests/14b\": dial tcp 172.67.182.229:443: connect: network is unreachable"
[GIN] 2025/08/27 - 11:17:05 | 200 |  153.715646ms |       127.0.0.1 | POST     "/api/pull"
time=2025-08-27T11:17:13.442+02:00 level=DEBUG source=common.go:73 msg="cleaning up" dir=/leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079/ollama321408910
time=2025-08-27T11:17:13.442+02:00 level=DEBUG source=sched.go:318 msg="shutting down scheduler completed loop"
time=2025-08-27T11:17:13.442+02:00 level=DEBUG source=sched.go:119 msg="shutting down scheduler pending loop"
