ğŸš€ LLM-MOB PARALLEL PRODUCTION RUN
==================================
Job ID: 19248401
Nodo: lrdn0065.leonardo.local
Data: Thu Aug 21 18:30:25 CEST 2025
ğŸ”¥ MODALITÃ€: Elaborazione parallela su 4x A100

ğŸ“¦ Caricamento moduli e ambiente...
Loading python/3.11.6--gcc--8.5.0
  Loading requirement: bzip2/1.0.8-gp5wcz5 libmd/1.0.4-wja3f5q
    libbsd/0.11.7-cgxjopl expat/2.5.0-bptl3xw ncurses/6.4-asx3jea
    readline/8.2-nyw6mp6 gdbm/1.23-fs6otck libiconv/1.17-d7yvx2s
    xz/5.4.1-hubmwr5 zlib-ng/2.1.4-6htiapk libxml2/2.10.3-5eeeokp
    pigz/2.7-bopr5vp zstd/1.5.5-gawytfl tar/1.34-amqus5s gettext/0.22.3-2g7elif
    libffi/3.4.4-6r7brdq libxcrypt/4.4.35-ss2rzin sqlite/3.43.2
    util-linux-uuid/2.38.1-jkdi7kv
âœ… Python: Python 3.11.6
âœ… Virtual env: /leonardo_work/IscrC_LLM-Mob/venv
âœ… CUDA: Cuda compilation tools, release 12.3, V12.3.103

ğŸ” INFO GPU DETTAGLIATE:
0, NVIDIA A100-SXM-64GB, 65536 MiB, 2 MiB, 0 %, 42
1, NVIDIA A100-SXM-64GB, 65536 MiB, 2 MiB, 0 %, 43
2, NVIDIA A100-SXM-64GB, 65536 MiB, 2 MiB, 0 %, 43
3, NVIDIA A100-SXM-64GB, 65536 MiB, 2 MiB, 0 %, 42
CUDA_VISIBLE_DEVICES: 0,1,2,3
GPU disponibili per il job: 4

âš™ï¸ Configurazione Ollama per elaborazione parallela...
âœ… Versione Ollama: 0.3.14

ğŸš€ Avvio server Ollama per elaborazione parallela...
âœ… Porta server: 39003
ğŸ§¹ Pulizia processi precedenti...
ğŸ”¥ Avvio con supporto 4x A100...
âœ… Server PID: 836874
âœ… Log file: ollama_parallel.log

â³ Attesa avvio server multi-GPU (max 120s)...
âœ… Server multi-GPU operativo dopo 18s

ğŸ”¥ Preparazione modello per elaborazione parallela...
ğŸ“‹ Modelli disponibili:
  âœ… deepseek-coder:33b
  âœ… mixtral:8x7b
  âœ… llama3.1:8b
âœ… Modello llama3.1:8b disponibile
ğŸ”¥ Pre-caricamento modello su tutte le GPU...
ğŸ“¡ Warm-up GPU 0...
ğŸ“¡ Warm-up GPU 1...
ğŸ“¡ Warm-up GPU 2...
ğŸ“¡ Warm-up GPU 3...
slurmstepd: error: *** JOB 19248401 ON lrdn0065 CANCELLED AT 2025-08-21T18:43:50 DUE TO TIME LIMIT ***

ğŸ§¹ CLEANUP PRODUZIONE PARALLELA...
â±ï¸ Tempo totale job: 805 secondi (0h 13m)
ğŸ“Š Stato finale tutte le GPU:
index, memory.used [MiB], memory.total [MiB], utilization.gpu [%], temperature.gpu, power.draw [W]
0, 7252 MiB, 65536 MiB, 0 %, 43, 71.44 W
1, 6 MiB, 65536 MiB, 0 %, 43, 62.59 W
2, 6 MiB, 65536 MiB, 0 %, 43, 60.43 W
3, 6 MiB, 65536 MiB, 0 %, 42, 61.76 W
ğŸ”„ Shutdown graceful Ollama multi-GPU...
Unable to disable persistence mode for GPU 00000000:1D:00.0: Insufficient Permissions
âœ… Cleanup completato
