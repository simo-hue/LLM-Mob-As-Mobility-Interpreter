ğŸš€ LLM-MOB PRODUCTION RUN - TUTTI GLI UTENTI
=============================================
Job ID: 19248437
Nodo: lrdn0991.leonardo.local
Data: Thu Aug 21 18:04:11 CEST 2025
ğŸ’¡ MODALITÃ€: Processamento completo senza limiti utenti

ğŸ“¦ Caricamento moduli e ambiente...
Loading python/3.11.6--gcc--8.5.0
  Loading requirement: bzip2/1.0.8-gp5wcz5 libmd/1.0.4-wja3f5q
    libbsd/0.11.7-cgxjopl expat/2.5.0-bptl3xw ncurses/6.4-asx3jea
    readline/8.2-nyw6mp6 gdbm/1.23-fs6otck libiconv/1.17-d7yvx2s
    xz/5.4.1-hubmwr5 zlib-ng/2.1.4-6htiapk libxml2/2.10.3-5eeeokp
    pigz/2.7-bopr5vp zstd/1.5.5-gawytfl tar/1.34-amqus5s gettext/0.22.3-2g7elif
    libffi/3.4.4-6r7brdq libxcrypt/4.4.35-ss2rzin sqlite/3.43.2
    util-linux-uuid/2.38.1-jkdi7kv
âœ“ Python: Python 3.11.6
âœ“ Virtual env: /leonardo_work/IscrC_LLM-Mob/venv
âœ“ CUDA: Cuda compilation tools, release 12.3, V12.3.103

ğŸ” INFO GPU:
name, memory.total [MiB], memory.used [MiB], utilization.gpu [%], temperature.gpu
NVIDIA A100-SXM-64GB, 65536 MiB, 2 MiB, 0 %, 43
CUDA_VISIBLE_DEVICES: 0

âš™ï¸  Configurazione Ollama...
âœ“ Versione Ollama: 0.3.14

ğŸš€ Avvio server Ollama per produzione...
âœ“ Porta server: 39003
ğŸ§¹ Pulizia processi precedenti...
âœ“ Server PID: 1240058
âœ“ Log file: ollama_production.log

â³ Attesa avvio server (max 60s)...
   â±ï¸  Attesa... (20s) - controllo log:
     time=2025-08-21T18:04:25.586+02:00 level=INFO source=routes.go:1205 msg="Listening on 127.0.0.1:39003 (version 0.3.14)"
     time=2025-08-21T18:04:25.624+02:00 level=INFO source=common.go:135 msg="extracting embedded files" dir=/tmp/ollama2610270192/runners
âœ… Server operativo dopo 26s

ğŸ”¥ Preparazione modello per produzione...
ğŸ“‹ Modelli disponibili:
  âœ“ deepseek-coder:33b
  âœ“ mixtral:8x7b
  âœ“ llama3.1:8b
âœ… Modello mixtral:8x7b disponibile

ğŸ¯ AVVIO PRODUZIONE - PROCESSAMENTO COMPLETO
=============================================
âœ… Configurazione produzione attiva
ğŸ“Š Nessun limite utenti - processamento completo
â±ï¸  Tempo stimato: variabile (dipende dai dati)
ğŸ”„ Retry automatici: 5 tentativi per richiesta

ğŸ“¦ Verifica dipendenze Python...
ğŸ“ Directory risultati: /leonardo_work/IscrC_LLM-Mob/LLM-Mob-As-Mobility-Interpreter/results/
ğŸš€ AVVIO SCRIPT PRODUZIONE...
ğŸ“ Log dettagliato disponibile in tempo reale

2025-08-21 18:07:25,045 WARNING: âš ï¸ Timeout tentativo 1/3
2025-08-21 18:08:15,970 INFO: âœ… Ollama test passed - Response: 'Hello'
2025-08-21 18:08:15,972 INFO: ğŸ¯ Processamento file singolo: veronacard_2022_original.csv
2025-08-21 18:08:15,972 INFO: ğŸ“ Path completo: /leonardo_work/IscrC_LLM-Mob/LLM-Mob-As-Mobility-Interpreter/data/verona/veronacard_2020_2023/veronacard_2022_original.csv
2025-08-21 18:08:15,974 INFO:  Output esistente per veronacard_2022_original. Usa --force o --append.
2025-08-21 18:08:15,974 INFO: âœ… Processamento completato per veronacard_2022_original.csv
ğŸ‘‰ Porta letta da ollama_port.txt: '39003'
ğŸ‘‰ Provo a contattare http://127.0.0.1:39003/api/tags
ğŸ“‚ Working dir: /leonardo_work/IscrC_LLM-Mob/LLM-Mob-As-Mobility-Interpreter
ğŸ“„ Contenuto di ollama_port.txt: '39003'
ğŸ”„ Attesa Ollama su http://127.0.0.1:39003...
âœ“ Ollama risponde con status 200
âœ“ Runner LLaMA completamente attivo
ğŸ‰ Connessione Ollama stabilita con successo!

ğŸ‰ PRODUZIONE COMPLETATA CON SUCCESSO!
â±ï¸  Tempo totale Python: 133 secondi (0h 2m)

ğŸ“‹ REPORT FINALE PRODUZIONE
============================
â±ï¸  Tempo totale job: 245 secondi (0h 4m)
ğŸ”§ Versione Ollama: 0.3.14
ğŸ“Š ModalitÃ : Produzione completa (tutti gli utenti)
âœ… Python success: true
/var/spool/slurmd/job19248437/slurm_script: line 332: 1240439 Terminated              monitor_progress

ğŸ“ RISULTATI GENERATI:
   ğŸ“Š Total files: 2
   ğŸ’¾ Total size: 496K

   ğŸ“‹ File generati:
     -rw-r--r-- 1 smattiol interactive 248K Aug 21 16:10 results/veronacard_2021_original_pred_20250821_155335.csv
     -rw-r--r-- 1 smattiol interactive 242K Aug 21 15:36 results/veronacard_2022_original_pred_20250821_152008.csv

ğŸ”§ STATO FINALE SISTEMA:
memory.used [MiB], memory.total [MiB], utilization.gpu [%], temperature.gpu
25968 MiB, 65536 MiB, 0 %, 44

ğŸ“Š LOG OLLAMA (ultimi 20 righe):
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 33/33 layers to GPU
llm_load_tensors:        CPU buffer size =    70.31 MiB
llm_load_tensors:      CUDA0 buffer size = 25147.55 MiB
llama_new_context_with_model: n_ctx      = 1024
llama_new_context_with_model: n_batch    = 512
llama_new_context_with_model: n_ubatch   = 512
llama_new_context_with_model: flash_attn = 0
llama_new_context_with_model: freq_base  = 1000000.0
llama_new_context_with_model: freq_scale = 1
llama_kv_cache_init:      CUDA0 KV buffer size =   128.00 MiB
llama_new_context_with_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB
llama_new_context_with_model:  CUDA_Host  output buffer size =     0.28 MiB
llama_new_context_with_model:      CUDA0 compute buffer size =   138.00 MiB
llama_new_context_with_model:  CUDA_Host compute buffer size =    10.01 MiB
llama_new_context_with_model: graph nodes  = 1510
llama_new_context_with_model: graph splits = 2
INFO [main] model loaded | tid="23081593950208" timestamp=1755792495
time=2025-08-21T18:08:15.791+02:00 level=INFO source=server.go:626 msg="llama runner started in 40.52 seconds"
[GIN] 2025/08/21 - 18:08:15 | 200 | 40.919278033s |       127.0.0.1 | POST     "/api/generate"

ğŸ‰ JOB PRODUZIONE COMPLETATO CON SUCCESSO!
âœ… Tutti i dataset sono stati processati senza limiti utenti

ğŸ Fine job: Thu Aug 21 18:08:16 CEST 2025
=============================================

ğŸ§¹ CLEANUP PRODUZIONE...
ğŸ• Tempo totale job: 245 secondi (0h 4m)
ğŸ“Š Stato GPU finale:
memory.used [MiB], memory.total [MiB], utilization.gpu [%], temperature.gpu
25968 MiB, 65536 MiB, 0 %, 44
ğŸ“ Risultati generati: 2 files
ğŸ’¾ Dimensione risultati: 496K
ğŸ”„ Shutdown graceful Ollama...
âœ“ Cleanup completato
