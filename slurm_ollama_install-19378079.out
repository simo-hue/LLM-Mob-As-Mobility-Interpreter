üöÄ OLLAMA MODELS INSTALLER
================================================
Job ID: 19378079
Nodo: lrdn1954.leonardo.local
Data: Wed Aug 27 11:15:35 CEST 2025
User: smattiol

üìã MODELLI DA INSTALLARE:
  - qwen2.5:7b
  - qwen2.5:14b
  - deepseek-r1:32b
  - deepseek-v3:8b

üì¶ Setup ambiente HPC...
Loading python/3.11.6--gcc--8.5.0
  Loading requirement: bzip2/1.0.8-gp5wcz5 libmd/1.0.4-wja3f5q
    libbsd/0.11.7-cgxjopl expat/2.5.0-bptl3xw ncurses/6.4-asx3jea
    readline/8.2-nyw6mp6 gdbm/1.23-fs6otck libiconv/1.17-d7yvx2s
    xz/5.4.1-hubmwr5 zlib-ng/2.1.4-6htiapk libxml2/2.10.3-5eeeokp
    pigz/2.7-bopr5vp zstd/1.5.5-gawytfl tar/1.34-amqus5s gettext/0.22.3-2g7elif
    libffi/3.4.4-6r7brdq libxcrypt/4.4.35-ss2rzin sqlite/3.43.2
    util-linux-uuid/2.38.1-jkdi7kv
‚úÖ Python: Python 3.11.6
‚úÖ CUDA: Cuda compilation tools, release 12.3, V12.3.103

üîç GPU DETECTION:
0, NVIDIA A100-SXM-64GB, 65536 MiB, 43
1, NVIDIA A100-SXM-64GB, 65536 MiB, 43
2, NVIDIA A100-SXM-64GB, 65536 MiB, 43
3, NVIDIA A100-SXM-64GB, 65536 MiB, 42

üîß CONFIGURAZIONE:
- Ollama binary: /leonardo_work/IscrC_LLM-Mob/opt/bin/ollama
- Models directory: /leonardo_work/IscrC_LLM-Mob/.ollama/models
- Cache directory: /leonardo_work/IscrC_LLM-Mob/.ollama/cache
- Temp directory: /leonardo_work/IscrC_LLM-Mob/tmp_ollama_install_19378079

üíæ VERIFICA SPAZIO DISCO
========================
Spazio disponibile: 930GB
Spazio attuale Ollama: 47G

üßπ Cleanup preventivo...
üöÄ Avvio server Ollama...
Server PID: 3908633
‚è≥ Attesa disponibilit√† API...
‚úÖ Server pronto dopo 1 tentativi!

üìã MODELLI INSTALLATI (PRIMA)
--------------------------
NAME                  ID              SIZE      MODIFIED    
deepseek-coder:33b    acec7c0b0fd9    18 GB     13 days ago    
mixtral:8x7b          a3b6bef0f836    26 GB     13 days ago    
llama3.1:8b           46e0c10c039e    4.9 GB    8 weeks ago    

üìä Totale modelli: 3

üíæ SPAZIO DISCO PRE-INSTALLAZIONE
=================================
Filesystem                                        Size  Used Avail Use% Mounted on
10.128.82.1@o2ib:10.128.82.2@o2ib:/larchive/work  1.0T   96G  929G  10% /leonardo_work

üöÄ INIZIO INSTALLAZIONI
=======================
Totale modelli da processare: 4

üìç Progresso: 1/4

üîΩ INSTALLAZIONE: qwen2.5:7b
---------------------------
Inizio: Wed Aug 27 11:16:34 CEST 2025
üì• Download e installazione in corso...
   (Questo pu√≤ richiedere molto tempo per modelli grandi)
/var/spool/slurmd/job19378079/slurm_script: line 283: 3908718 Terminated              { while kill -0 $$ 2> /dev/null; do
    sleep 60; echo "‚è≥ $(date): Download $model ancora in corso..."; echo "   GPU Status:"; nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv,noheader,nounits | while IFS=',' read -r idx mem_used mem_total; do
        mem_percent=$((mem_used * 100 / mem_total)); printf "     GPU %s: %d%% (%d/%d MB)\n" "$idx" "$mem_percent" "$mem_used" "$mem_total";
    done; local space_now=$(df "$WORK" | tail -1 | awk '{print $4}'); local space_now_gb=$((space_now / 1024 / 1024)); echo "   Spazio rimanente: ${space_now_gb}GB";
done; }
‚ùå qwen2.5:7b installazione fallita!
   Tempo impiegato: 0 minuti
   Exit code: 1

Ultime righe output:
   [?25lpulling manifest ‚†ã [?25h[?25l[2K[1Gpulling manifest [?25h
   Error: pull model manifest: Get "https://registry.ollama.ai/v2/library/qwen2.5/manifests/7b": dial tcp 104.21.75.227:443: connect: network is unreachable

‚ö†Ô∏è Installazione qwen2.5:7b fallita. Continuo con il prossimo...
/var/spool/slurmd/job19378079/slurm_script: line 358: local: can only be used in a function
/var/spool/slurmd/job19378079/slurm_script: line 359: local: can only be used in a function
/var/spool/slurmd/job19378079/slurm_script: line 360: [: -lt: unary operator expected

üìä Stato attuale: ‚úÖ0 ‚ùå1

‚è∏Ô∏è Pausa 30s prima del prossimo modello...
üìç Progresso: 2/4

üîΩ INSTALLAZIONE: qwen2.5:14b
----------------------------
Inizio: Wed Aug 27 11:17:04 CEST 2025
üì• Download e installazione in corso...
   (Questo pu√≤ richiedere molto tempo per modelli grandi)
/var/spool/slurmd/job19378079/slurm_script: line 283: 3908760 Terminated              { while kill -0 $$ 2> /dev/null; do
    sleep 60; echo "‚è≥ $(date): Download $model ancora in corso..."; echo "   GPU Status:"; nvidia-smi --query-gpu=index,memory.used,memory.total --format=csv,noheader,nounits | while IFS=',' read -r idx mem_used mem_total; do
        mem_percent=$((mem_used * 100 / mem_total)); printf "     GPU %s: %d%% (%d/%d MB)\n" "$idx" "$mem_percent" "$mem_used" "$mem_total";
    done; local space_now=$(df "$WORK" | tail -1 | awk '{print $4}'); local space_now_gb=$((space_now / 1024 / 1024)); echo "   Spazio rimanente: ${space_now_gb}GB";
done; }
‚ùå qwen2.5:14b installazione fallita!
   Tempo impiegato: 0 minuti
   Exit code: 1

Ultime righe output:
   [?25lpulling manifest ‚†ã [?25h[?25l[2K[1Gpulling manifest [?25h
   Error: pull model manifest: Get "https://registry.ollama.ai/v2/library/qwen2.5/manifests/14b": dial tcp 172.67.182.229:443: connect: network is unreachable

‚ö†Ô∏è Installazione qwen2.5:14b fallita. Continuo con il prossimo...
/var/spool/slurmd/job19378079/slurm_script: line 358: local: can only be used in a function
/var/spool/slurmd/job19378079/slurm_script: line 359: local: can only be used in a function
/var/spool/slurmd/job19378079/slurm_script: line 360: [: -lt: unary operator expected

üìä Stato attuale: ‚úÖ0 ‚ùå2

‚è∏Ô∏è Pausa 30s prima del prossimo modello...
slurmstepd: error: *** JOB 19378079 ON lrdn1954 CANCELLED AT 2025-08-27T11:17:13 ***

üßπ Cleanup finale...
Stopping Ollama server (PID 3908633)...
Removing temporary directory...
‚úÖ Cleanup completato
