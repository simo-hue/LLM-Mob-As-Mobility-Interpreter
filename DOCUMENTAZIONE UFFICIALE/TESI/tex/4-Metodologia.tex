\section{Metodologia}

\subsection{Formulazione del Problema}

Formuliamo il problema di previsione della mobilità umana come un task di raccomandazione sequenziale spazio-temporale. Data la sequenza storica di POI visitati da un turista $S = \{p_1, p_2, ..., p_n\}$ ordinati cronologicamente, l'obiettivo è prevedere i $k$ POI più probabili che il turista visiterà successivamente, dove $k=5$ nel nostro setup sperimentale.

Diversamente dagli approcci tradizionali che modellano questo problema come classificazione multi-classe, adottiamo una strategia innovativa basata su \textit{anchor-based prompting}, dove:

\begin{itemize}
\item Ogni sequenza viene divisa in: storico delle visite $H = \{p_1, ..., p_{j-1}, p_{j+1}, ..., p_{n-1}\}$, POI corrente (anchor) $p_j$, e target da prevedere $p_n$
\item La strategia di selezione dell'anchor è configurabile: penultimate (default), first, middle, o indice esplicito
\item Il modello riceve informazioni contestuali multi-dimensionali: cluster comportamentale, cronologia delle visite, posizione geografica corrente, e POI nelle vicinanze
\end{itemize}

\subsection{Architettura del Sistema}

Il nostro framework si basa su un'architettura modulare che combina clustering comportamentale, analisi geospaziale e generazione linguistica attraverso LLM. La pipeline è ottimizzata per elaborazioni massive su cluster HPC con gestione robusta di timeout e fallimenti.

\subsubsection{Infrastructure e Deployment}

Il sistema è progettato per operare su cluster HPC (High Performance Computing) utilizzando:
\begin{itemize}
\item \textbf{LLM Backend}: Ollama, configurazione ottimizzata per GPU A100 ( visto che ho eseguito i miei test sull'HPC Italiano Leonardo )
\item \textbf{Gestione Risorse}: Sistema di checkpointing incrementale per elaborazioni interrotte
\item \textbf{Fault Tolerance}: Retry mechanism con backoff esponenziale e health checking automatico
\item \textbf{Scalabilità}: Processamento parallelizzabile per dataset multi-anno
\end{itemize}

\subsection{Dataset e Pre-elaborazione}

\subsubsection{Caratteristiche del Dataset VeronaCard}

Gli esperimenti sono condotti sul dataset VeronaCard (2014-2023), contenente:
\begin{itemize}
\item \textbf{Registrazioni turistiche}: 10 anni di log di utilizzo con timestamp precisi
\item \textbf{Copertura geografica}: 50+ POI distribuiti nel centro storico di Verona
\item \textbf{Diversità comportamentale}: Turisti con pattern di visita eterogenei (culturali, storici, ricreativi)
\item \textbf{Metadati geospaziali}: Coordinate GPS precise per ogni POI
\end{itemize}

\subsubsection{Pipeline di Pre-elaborazione}

La pre-elaborazione implementa un processo multi-stage con validazioni robuste:

\begin{enumerate}
\item \textbf{Data Cleaning}: 
   \begin{itemize}
   \item Merge delle timbrature con il catalogo POI validato ( JOIN fatto su name_short )
   \item Filtro delle sequenze con almeno 3 visite e 2+ POI distinti
   \item Standardizzazione dei timestamp e identificativi
   \end{itemize}

\item \textbf{Behavioral Clustering}:
   \begin{itemize}
   \item Costruzione matrice user-POI sparsa
   \item Standardizzazione con StandardScaler
   \item K-means clustering ($k=7$) per identificazione profili comportamentali
   \end{itemize}

\item \textbf{Spatial Analysis}:
   \begin{itemize}
   \item Calcolo distanze Haversine tra POI
   \item Identificazione POI nelle vicinanze (raggio 2km)
   \item Analisi pattern di movimento sequenziali
   \end{itemize}
\end{enumerate}

\subsection{Prompt Engineering e Context Construction}

\subsubsection{Strategia di Prompt Design}

Il prompt viene costruito dinamicamente incorporando:

\begin{itemize}
\item \textbf{Profilo comportamentale}: "Turista cluster X a Verona"
\item \textbf{Context storico}: Lista POI precedentemente visitati (escluso anchor)  
\item \textbf{Posizione corrente}: POI anchor con coordinate
\item \textbf{Prossimità geografica}: Top-10 POI più vicini con distanze in km
\item \textbf{Constraint task}: Richiesta di 5 raccomandazioni ordinati per probabilità
\end{itemize}

Il formato di output è strutturato in JSON per garantire parsing deterministico:
\begin{verbatim}
{"prediction": ["poi1", "poi2", "poi3", "poi4", "poi5"], 
 "reason": "spiegazione delle scelte"}
\end{verbatim}

\subsubsection{Gestione del Context Window}

Per ottimizzare l'utilizzo del context window limitato (1024 tokens), il prompt viene compattato:
\begin{itemize}
\item Selezione dei 10 POI più vicini geograficamente (vs. tutti i POI disponibili)
\item Formato condensato: "POI\_name (distance\_km)"
\item Eliminazione di testo ridondante mantenendo informazioni critiche
\end{itemize}

Tutto ciò per non fornire "troppe" informazioni ai modelli LLM, che almeno per i test iniziali, sono piccoli ( qualche miliardo di parametri ). Per scoprire fino a dove riusciamo ad ottenere dei risultati accettabili. 

\subsection{Strategia di Valutazione}

\subsubsection{Metriche di Performance}

Il sistema viene valutato attraverso metriche standard per sistemi di raccomandazione:

\begin{itemize}
\item \textbf{Top-1 Accuracy}: $\text{Acc}_{@1}=\frac{1}{N}\sum_{i=1}^{N}\mathbf{1}\{y_i=\hat{y}_i^{(1)}\}$
\item \textbf{Top-k Hit Rate}: $\text{HR}_{@k}=\frac{1}{N}\sum_{i=1}^{N}\mathbf{1}\{y_i\in\{\hat{y}_i^{(1)},\dots,\hat{y}_i^{(k)}\}\}$
\item \textbf{Mean Reciprocal Rank}: $\text{MRR}=\frac{1}{N}\sum_{i=1}^{N}\frac{1}{\operatorname{rank}_i}$
\item \textbf{Catalogue Coverage}: $\text{Coverage}=\frac{|\bigcup_{i}\{\hat{y}_i^{(1)},\dots,\hat{y}_i^{(k)}\}|}{|\mathcal{P}|}$
\end{itemize}

\subsubsection{Test Set Construction}

Per ogni turista con sequenza $\{p_1, p_2, ..., p_n\}$ (n≥3):
\begin{itemize}
\item \textbf{History}: $\{p_1, ..., p_{n-2}\}$ (escluso anchor)
\item \textbf{Current POI (anchor)}: $p_{n-1}$ 
\item \textbf{Ground truth}: $p_n$
\end{itemize}

Questa costruzione permette valutazione realistica del task di previsione "next-POI".

\subsubsection{Analisi di Errore}

Il framework include strumenti avanzati per interpretabilità:
\begin{itemize}
\item \textbf{Worst-performing pairs}: Identificazione coppie POI problematiche
\item \textbf{Confusion matrices}: Visualizzazione errori per subset temporali/geografici  
\item \textbf{Explainability}: Integrazione LIME per analisi features testuali nei prompt
\end{itemize}