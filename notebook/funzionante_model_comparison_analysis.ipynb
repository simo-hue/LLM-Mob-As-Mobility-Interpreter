{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ Multi-Model Comparison Analysis for Tourism Mobility Prediction\n",
    "\n",
    "*Automated analysis and visualization for comparing multiple LLM models with dual prompt strategies on VeronaCard dataset*\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Obiettivi del Notebook\n",
    "\n",
    "Questo notebook fornisce un **framework completo** per confrontare le performance di diversi modelli LLM con **due strategie di prompt** sulla predizione next-POI turistici:\n",
    "\n",
    "- **üìä Strategia Base**: Prompt senza informazioni geometriche  \n",
    "- **üåç Strategia Geometrica**: Prompt con informazioni spaziali integrate\n",
    "\n",
    "Genera automaticamente:\n",
    "\n",
    "- **üìà Grafici comparativi affiancati** per visualizzare entrambe le strategie\n",
    "- **üìä Analisi dei miglioramenti** dovuti all'informazione geometrica\n",
    "- **üé® Visualizzazioni side-by-side** pronte per inclusione nella tesi\n",
    "- **üìã Report automatici** con tabelle LaTeX-ready\n",
    "\n",
    "## üìÅ Struttura Repository Attuale\n",
    "\n",
    "**‚úÖ CONFIGURAZIONE AUTOMATICA**: Il notebook si adatta automaticamente alla struttura esistente:\n",
    "\n",
    "```\n",
    "LLM-Mob-As-Mobility-Interpreter/\n",
    "‚îú‚îÄ‚îÄ notebook/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ multi_model_comparison_analysis.ipynb  # questo notebook\n",
    "‚îú‚îÄ‚îÄ results/                                   # Modelli standard\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ llama3.1_8b/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_version/        # CSV strategia base\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ with_geom_srv_univr/ # CSV strategia geometrica\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ mixtral_8x7b/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base_version/        # CSV strategia base\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ qwen2.5_7b/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_version/        # CSV strategia base\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ with_geom/           # CSV strategia geometrica\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ qwen2.5_14b/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_version/        # CSV strategia base\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ with_geom/           # CSV strategia geometrica\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ DEV/                     # ‚ö†Ô∏è IGNORATA (file di debug)\n",
    "‚îú‚îÄ‚îÄ results_deepseek-coder_33b_base_version/   # DeepSeek base (directory separata)\n",
    "‚îú‚îÄ‚îÄ results_deepseek-coder_33b_with_geom/      # DeepSeek geom (directory separata)\n",
    "‚îú‚îÄ‚îÄ results_mixtr_with_geom/                   # Mixtral geom (directory separata)\n",
    "‚îî‚îÄ‚îÄ img/                                       # Output grafici\n",
    "    ‚îî‚îÄ‚îÄ multi_model_comparison/\n",
    "        ‚îú‚îÄ‚îÄ base/           # Grafici solo strategia base\n",
    "        ‚îú‚îÄ‚îÄ geom/           # Grafici solo strategia geometrica\n",
    "        ‚îî‚îÄ‚îÄ side_by_side/   # Grafici comparativi affiancati\n",
    "```\n",
    "\n",
    "## üöÄ Workflow di Utilizzo\n",
    "\n",
    "1. **‚úÖ Auto-detection**: Il notebook rileva automaticamente le directory disponibili\n",
    "2. **üîç Verifica dati**: Controlla che esistano file CSV in entrambe le strategie\n",
    "3. **üìä Carica ed analizza**: Processa entrambe le strategie per ogni modello\n",
    "4. **üìà Genera confronti**: Crea grafici affiancati e analisi miglioramenti\n",
    "5. **üíæ Salva output**: Esporta grafici, tabelle e codice LaTeX\n",
    "\n",
    "## üÜï Nuove Funzionalit√† Dual-Strategy\n",
    "\n",
    "- **Grafici 2x3 affiancati**: Strategia base sopra, geometrica sotto\n",
    "- **Barre sovrapposte**: Confronto diretto con frecce di miglioramento\n",
    "- **Analisi delta**: Grafici dei miglioramenti percentuali\n",
    "- **Radar charts**: Confronto multidimensionale per ogni modello\n",
    "- **Tabelle integrate**: Base e Geom nella stessa tabella con calcolo Œî%\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup e Configurazione\n",
    "\n",
    "### Configurazione dei modelli da analizzare\n",
    "Modifica questa configurazione in base ai modelli che hai testato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import ast\n",
    "import json\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "\n",
    "# Configurazione stile grafici\n",
    "plt.rcParams['figure.dpi'] = 300  # Alta qualit√† per la tesi\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "\n",
    "# Sopprime warning non critici\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"üì¶ Setup completato!\")\n",
    "print(f\"üìä Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurazione modelli e colori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURAZIONE MODELLI - Struttura corretta basata sulla repository reale\n",
    "# ============================================================================\n",
    "\n",
    "# Configurazione basata sulla struttura reale osservata\n",
    "MODELS = {\n",
    "    'deepseek-coder_33b': {\n",
    "        'name': 'DeepSeek-Coder 33B',\n",
    "        'base_dir': '../results/deepseek-coder_33b/base_version/',  # Directory separata\n",
    "        'geom_dir': '../results/deepseek-coder_33b/with_geom/',     # Directory separata\n",
    "        'color': '#d62728',  # Rosso\n",
    "        'params': '33B',\n",
    "        'type': 'Coding'\n",
    "    },\n",
    "    'llama3.1_8b': {\n",
    "        'name': 'LLaMA 3.1 8B',\n",
    "        'base_dir': '../results/llama3.1_8b/base_version/',\n",
    "        'geom_dir': '../results/llama3.1_8b/with_geom/',\n",
    "        'color': '#1f77b4',  # Blu\n",
    "        'params': '8B',\n",
    "        'type': 'Baseline'\n",
    "    },\n",
    "    'mixtral_8x7b': {\n",
    "        'name': 'Mixtral 8x7B',\n",
    "        'base_dir': '../results/mixtral_8x7b/base_version/',\n",
    "        'geom_dir': '../results/mixtral_8x7b/with_geom/',  # Directory separata per geom\n",
    "        'color': '#ff7f0e',  # Arancione\n",
    "        'params': '8x7B (47B active)',\n",
    "        'type': 'MoE'\n",
    "    },\n",
    "    'qwen2.5_7b': {\n",
    "        'name': 'Qwen 2.5 7B',\n",
    "        'base_dir': '../results/qwen2.5_7b/base_version/',\n",
    "        'geom_dir': '../results/qwen2.5_7b/with_geom/',\n",
    "        'color': '#2ca02c',  # Verde\n",
    "        'params': '7B',\n",
    "        'type': 'Multilingual'\n",
    "    },\n",
    "    'qwen2.5_14b': {\n",
    "        'name': 'Qwen 2.5 14B',\n",
    "        'base_dir': '../results/qwen2.5_14b/base_version/',\n",
    "        'geom_dir': '../results/qwen2.5_14b/with_geom/',\n",
    "        'color': '#9467bd',  # Viola\n",
    "        'params': '14B',\n",
    "        'type': 'Multilingual-Large'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Directory per salvare i grafici - organizzate per strategie\n",
    "OUTPUT_DIRS = {\n",
    "    'comparison': '../img/multi_model_comparison/',\n",
    "    'base_comparison': '../img/multi_model_comparison/base/',\n",
    "    'geom_comparison': '../img/multi_model_comparison/geom/',\n",
    "    'side_by_side': '../img/multi_model_comparison/side_by_side/',\n",
    "    'individual': '../img/'  # + model_key per grafici specifici\n",
    "}\n",
    "\n",
    "# Crea directory se non esistono\n",
    "for dir_path in OUTPUT_DIRS.values():\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üé® Configurazione modelli corretta per struttura repository reale:\")\n",
    "print(\"   üìä Struttura mista: alcune directory in results/, altre separate\")\n",
    "print(\"   üö´ Directory results/DEV/ IGNORATA (file di debug)\")\n",
    "print()\n",
    "\n",
    "# Verifica esistenza directory e correzione automatica per DeepSeek\n",
    "print(\"üîç Verifica e correzione directory configurate:\")\n",
    "\n",
    "# Controllo speciale per DeepSeek che ha directory separate dalla root\n",
    "deepseek_base_alt = '../results/deepseek-coder_33b_base_version/'\n",
    "deepseek_geom_alt = '../results/deepseek-coder_33b_with_geom/'\n",
    "\n",
    "if Path(deepseek_base_alt).exists():\n",
    "    MODELS['deepseek-coder_33b']['base_dir'] = deepseek_base_alt\n",
    "    print(\"‚úÖ DeepSeek-Coder 33B: Utilizzando directory base_version separata\")\n",
    "\n",
    "if Path(deepseek_geom_alt).exists():\n",
    "    MODELS['deepseek-coder_33b']['geom_dir'] = deepseek_geom_alt\n",
    "    print(\"‚úÖ DeepSeek-Coder 33B: Utilizzando directory with_geom separata\")\n",
    "\n",
    "# Controllo speciale per Mixtral che ha geom directory separata\n",
    "mixtral_geom_alt = '../results_mixtr_with_geom/'\n",
    "if Path(mixtral_geom_alt).exists():\n",
    "    MODELS['mixtral_8x7b']['geom_dir'] = mixtral_geom_alt\n",
    "    print(\"‚úÖ Mixtral 8x7B: Utilizzando directory geom separata\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Verifica finale di tutte le directory\n",
    "for key, model in MODELS.items():\n",
    "    print(f\"  {model['name']:>20s}:\")\n",
    "    \n",
    "    base_exists = Path(model['base_dir']).exists()\n",
    "    geom_exists = Path(model['geom_dir']).exists()\n",
    "    \n",
    "    print(f\"    Base: {model['base_dir']} {'‚úÖ' if base_exists else '‚ùå'}\")\n",
    "    print(f\"    Geom: {model['geom_dir']} {'‚úÖ' if geom_exists else '‚ùå'}\")\n",
    "    \n",
    "    if base_exists:\n",
    "        base_files = list(Path(model['base_dir']).glob('*_pred_*.csv'))\n",
    "        print(f\"          ‚îî‚îÄ {len(base_files)} file CSV base\")\n",
    "    \n",
    "    if geom_exists:\n",
    "        geom_files = list(Path(model['geom_dir']).glob('*_pred_*.csv'))\n",
    "        print(f\"          ‚îî‚îÄ {len(geom_files)} file CSV geom\")\n",
    "\n",
    "print(f\"\\nüìÅ Output directories create:\")\n",
    "for name, path in OUTPUT_DIRS.items():\n",
    "    print(f\"  {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 1. Caricamento e Preprocessing Dati\n",
    "\n",
    "### Funzioni di utilit√† per il caricamento dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poi_id(x):\n",
    "    \"\"\"\n",
    "    Normalizza identificatori POI per confronti consistenti.\n",
    "    Gestisce dict, liste, e stringhe/numeri.\n",
    "    \"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        for key in ('poi', 'poi_id', 'name', 'id'):\n",
    "            if key in x:\n",
    "                return str(x[key])\n",
    "        return json.dumps(x, sort_keys=True)\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        return tuple(map(poi_id, x))\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "def load_model_data(model_dir, model_name):\n",
    "    \"\"\"\n",
    "    Carica tutti i CSV di un modello e calcola le metriche.\n",
    "    \n",
    "    Args:\n",
    "        model_dir (str): Directory contenente i file CSV del modello\n",
    "        model_name (str): Nome del modello per logging\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con tutte le predizioni e metriche calcolate\n",
    "    \"\"\"\n",
    "    print(f\"üìÇ Caricamento {model_name}...\")\n",
    "    \n",
    "    # Trova tutti i file CSV\n",
    "    csv_pattern = str(Path(model_dir) / '*_pred_*.csv')\n",
    "    csv_files = glob.glob(csv_pattern)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"   ‚ö†Ô∏è  Nessun file CSV trovato in {model_dir}\")\n",
    "        print(f\"       Pattern cercato: {csv_pattern}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"   üìÑ Trovati {len(csv_files)} file CSV\")\n",
    "    \n",
    "    dfs = []\n",
    "    total_rows = 0\n",
    "    \n",
    "    for csv_file in sorted(csv_files):\n",
    "        try:\n",
    "            # Caricamento con gestione errori\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file)\n",
    "            except pd.errors.ParserError:\n",
    "                print(f\"   ‚ö†Ô∏è  Parser error in {Path(csv_file).name}, utilizzando error handling...\")\n",
    "                df = pd.read_csv(csv_file, on_bad_lines='skip', engine='python')\n",
    "            \n",
    "            # Estrai anno dal nome file\n",
    "            filename = Path(csv_file).stem\n",
    "            year_token = next((part for part in filename.split('_')\n",
    "                             if part.isdigit() and len(part) == 4), None)\n",
    "            df['year'] = int(year_token) if year_token else np.nan\n",
    "            df['model'] = model_name\n",
    "            \n",
    "            # Parse prediction list\n",
    "            df['prediction_list'] = df['prediction'].apply(\n",
    "                lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
    "            )\n",
    "            \n",
    "            # Filtra solo predizioni con esattamente 5 elementi\n",
    "            df = df[df['prediction_list'].apply(len) == 5]\n",
    "            \n",
    "            dfs.append(df)\n",
    "            total_rows += len(df)\n",
    "            print(f\"       {Path(csv_file).name}: {len(df):,} righe\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Errore caricando {Path(csv_file).name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not dfs:\n",
    "        print(f\"   ‚ùå Nessun file caricato con successo per {model_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Concatena tutti i dataframes\n",
    "    df_combined = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Normalizza POI per confronti consistenti\n",
    "    df_combined['prediction_norm'] = df_combined['prediction_list'].apply(\n",
    "        lambda lst: [poi_id(e) for e in lst]\n",
    "    )\n",
    "    df_combined['ground_truth_norm'] = df_combined['ground_truth'].apply(poi_id)\n",
    "    \n",
    "    print(f\"   ‚úÖ {model_name}: {total_rows:,} righe totali\")\n",
    "    return df_combined\n",
    "\n",
    "def calculate_metrics(df):\n",
    "    \"\"\"\n",
    "    Calcola le metriche di valutazione standard per un DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con colonne prediction_norm e ground_truth_norm\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dizionario con le metriche calcolate\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return {\n",
    "            'top1_accuracy': 0.0,\n",
    "            'top5_hit_rate': 0.0,\n",
    "            'mrr': 0.0,\n",
    "            'catalogue_coverage': 0.0,\n",
    "            'total_predictions': 0,\n",
    "            'processing_time_mean': 0.0\n",
    "        }\n",
    "    \n",
    "    # Calcola hit@1\n",
    "    df['hit@1'] = df['prediction_norm'].str[0] == df['ground_truth_norm']\n",
    "    \n",
    "    # Calcola hit@5\n",
    "    df['hit@5'] = df.apply(\n",
    "        lambda row: row['ground_truth_norm'] in row['prediction_norm'][:5], axis=1\n",
    "    )\n",
    "    \n",
    "    # Calcola reciprocal rank\n",
    "    def reciprocal_rank(row, k=5):\n",
    "        try:\n",
    "            rank = row['prediction_norm'][:k].index(row['ground_truth_norm']) + 1\n",
    "            return 1.0 / rank\n",
    "        except ValueError:\n",
    "            return 0.0\n",
    "    \n",
    "    df['rr'] = df.apply(reciprocal_rank, axis=1)\n",
    "    \n",
    "    # Calcola catalogue coverage\n",
    "    coverage_set = {poi for preds in df['prediction_norm'] for poi in preds}\n",
    "    unique_ground_truth = df['ground_truth_norm'].nunique()\n",
    "    \n",
    "    # Processing time medio\n",
    "    proc_time_mean = df['processing_time'].mean() if 'processing_time' in df.columns else 0.0\n",
    "    \n",
    "    metrics = {\n",
    "        'top1_accuracy': df['hit@1'].mean(),\n",
    "        'top5_hit_rate': df['hit@5'].mean(),\n",
    "        'mrr': df['rr'].mean(),\n",
    "        'catalogue_coverage': len(coverage_set) / unique_ground_truth if unique_ground_truth > 0 else 0.0,\n",
    "        'total_predictions': len(df),\n",
    "        'processing_time_mean': proc_time_mean\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"üîß Funzioni di utilit√† caricate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento dati per tutti i modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CARICAMENTO DATI PER TUTTI I MODELLI - VERSIONE DOPPIA STRATEGIA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üöÄ Avvio caricamento dati multi-modello con doppia strategia...\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dizionari per contenere tutti i dati divisi per strategia\n",
    "model_data_base = {}\n",
    "model_data_geom = {}\n",
    "model_metrics_base = {}\n",
    "model_metrics_geom = {}\n",
    "successfully_loaded_base = []\n",
    "successfully_loaded_geom = []\n",
    "\n",
    "# Carica dati per ogni modello (entrambe le strategie)\n",
    "for model_key, model_config in MODELS.items():\n",
    "    print(f\"\\nüìä MODELLO: {model_config['name']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # ==================== CARICA VERSIONE BASE ====================\n",
    "    print(f\"üìà Caricamento strategia BASE:\")\n",
    "    base_dir = Path(model_config['base_dir'])\n",
    "    if not base_dir.exists():\n",
    "        print(f\"   ‚ùå Directory BASE non trovata: {base_dir}\")\n",
    "    else:\n",
    "        df_base = load_model_data(model_config['base_dir'], f\"{model_config['name']} (Base)\")\n",
    "        if not df_base.empty:\n",
    "            metrics_base = calculate_metrics(df_base)\n",
    "            model_data_base[model_key] = df_base\n",
    "            model_metrics_base[model_key] = metrics_base\n",
    "            successfully_loaded_base.append(model_key)\n",
    "            \n",
    "            print(f\"   ‚úÖ Base - Metriche:\")\n",
    "            print(f\"       Top-1 Accuracy: {metrics_base['top1_accuracy']:.3f} ({metrics_base['top1_accuracy']*100:.1f}%)\")\n",
    "            print(f\"       Top-5 Hit Rate: {metrics_base['top5_hit_rate']:.3f} ({metrics_base['top5_hit_rate']*100:.1f}%)\")\n",
    "            print(f\"       MRR:            {metrics_base['mrr']:.3f}\")\n",
    "            print(f\"       Predizioni:     {metrics_base['total_predictions']:,}\")\n",
    "    \n",
    "    # ==================== CARICA VERSIONE GEOM ====================\n",
    "    print(f\"üåç Caricamento strategia GEOM:\")\n",
    "    geom_dir = Path(model_config['geom_dir'])\n",
    "    if not geom_dir.exists():\n",
    "        print(f\"   ‚ùå Directory GEOM non trovata: {geom_dir}\")\n",
    "    else:\n",
    "        df_geom = load_model_data(model_config['geom_dir'], f\"{model_config['name']} (Geom)\")\n",
    "        if not df_geom.empty:\n",
    "            metrics_geom = calculate_metrics(df_geom)\n",
    "            model_data_geom[model_key] = df_geom\n",
    "            model_metrics_geom[model_key] = metrics_geom\n",
    "            successfully_loaded_geom.append(model_key)\n",
    "            \n",
    "            print(f\"   ‚úÖ Geom - Metriche:\")\n",
    "            print(f\"       Top-1 Accuracy: {metrics_geom['top1_accuracy']:.3f} ({metrics_geom['top1_accuracy']*100:.1f}%)\")\n",
    "            print(f\"       Top-5 Hit Rate: {metrics_geom['top5_hit_rate']:.3f} ({metrics_geom['top5_hit_rate']*100:.1f}%)\")\n",
    "            print(f\"       MRR:            {metrics_geom['mrr']:.3f}\")\n",
    "            print(f\"       Predizioni:     {metrics_geom['total_predictions']:,}\")\n",
    "    \n",
    "    # ==================== CONFRONTO DIRETTO ====================\n",
    "    if model_key in successfully_loaded_base and model_key in successfully_loaded_geom:\n",
    "        print(f\"   üìä Confronto Base vs Geom:\")\n",
    "        \n",
    "        # Calcola miglioramenti\n",
    "        top1_improvement = (metrics_geom['top1_accuracy'] - metrics_base['top1_accuracy']) * 100\n",
    "        top5_improvement = (metrics_geom['top5_hit_rate'] - metrics_base['top5_hit_rate']) * 100\n",
    "        mrr_improvement = (metrics_geom['mrr'] - metrics_base['mrr']) * 100\n",
    "        \n",
    "        print(f\"       Top-1 Œî: {top1_improvement:+.1f}% {'‚úÖ' if top1_improvement > 0 else '‚ùå'}\")\n",
    "        print(f\"       Top-5 Œî: {top5_improvement:+.1f}% {'‚úÖ' if top5_improvement > 0 else '‚ùå'}\")\n",
    "        print(f\"       MRR Œî:   {mrr_improvement:+.1f}% {'‚úÖ' if mrr_improvement > 0 else '‚ùå'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"üìã RIEPILOGO CARICAMENTO DOPPIA STRATEGIA:\")\n",
    "print(f\"   Modelli configurati:     {len(MODELS)}\")\n",
    "print(f\"   Modelli caricati (Base): {len(successfully_loaded_base)}\")\n",
    "print(f\"   Modelli caricati (Geom): {len(successfully_loaded_geom)}\")\n",
    "print(f\"   Modelli con entrambe:    {len(set(successfully_loaded_base) & set(successfully_loaded_geom))}\")\n",
    "\n",
    "# Identifica modelli disponibili per entrambe le strategie\n",
    "models_both_strategies = list(set(successfully_loaded_base) & set(successfully_loaded_geom))\n",
    "print(f\"   Modelli completi: {', '.join([MODELS[k]['name'] for k in models_both_strategies])}\")\n",
    "\n",
    "if len(models_both_strategies) < 1:\n",
    "    print(\"\\n‚ö†Ô∏è  ATTENZIONE: Nessun modello ha entrambe le strategie!\")\n",
    "    print(\"   Verifica la struttura delle directory dei risultati\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Pronto per analisi comparativa con {len(models_both_strategies)} modelli completi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 2. Creazione Tabella Comparativa Principale\n",
    "\n",
    "Genera la tabella di performance comparative che sar√† integrata nel LaTeX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TABELLA COMPARATIVA DOPPIA STRATEGIA\n",
    "# ============================================================================\n",
    "\n",
    "if len(models_both_strategies) == 0:\n",
    "    print(\"‚ùå Nessun modello con entrambe le strategie. Saltando creazione tabella.\")\n",
    "else:\n",
    "    print(\"üìã Creazione tabella comparativa doppia strategia...\")\n",
    "    \n",
    "    # Prepara dati per la tabella comparativa\n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_key in models_both_strategies:\n",
    "        model_config = MODELS[model_key]\n",
    "        metrics_base = model_metrics_base[model_key]\n",
    "        metrics_geom = model_metrics_geom[model_key]\n",
    "        \n",
    "        # Calcola miglioramenti\n",
    "        top1_improvement = (metrics_geom['top1_accuracy'] - metrics_base['top1_accuracy']) * 100\n",
    "        top5_improvement = (metrics_geom['top5_hit_rate'] - metrics_base['top5_hit_rate']) * 100\n",
    "        mrr_improvement = (metrics_geom['mrr'] - metrics_base['mrr']) * 100\n",
    "        \n",
    "        # Riga per strategia BASE\n",
    "        comparison_data.append({\n",
    "            'Modello': model_config['name'],\n",
    "            'Strategia': 'Base',\n",
    "            'Parametri': model_config['params'],\n",
    "            'Top-1 Acc.': f\"{metrics_base['top1_accuracy']*100:.1f}%\",\n",
    "            'Top-5 HR': f\"{metrics_base['top5_hit_rate']*100:.1f}%\",\n",
    "            'MRR': f\"{metrics_base['mrr']*100:.1f}%\",\n",
    "            'Coverage': f\"{metrics_base['catalogue_coverage']:.2f}\",\n",
    "            'Predizioni': f\"{metrics_base['total_predictions']:,}\",\n",
    "            'Œî Top-1': f\"‚Äî\",\n",
    "            'Œî Top-5': f\"‚Äî\",\n",
    "            'Œî MRR': f\"‚Äî\"\n",
    "        })\n",
    "        \n",
    "        # Riga per strategia GEOM\n",
    "        comparison_data.append({\n",
    "            'Modello': model_config['name'],\n",
    "            'Strategia': 'Geom',\n",
    "            'Parametri': model_config['params'],\n",
    "            'Top-1 Acc.': f\"{metrics_geom['top1_accuracy']*100:.1f}%\",\n",
    "            'Top-5 HR': f\"{metrics_geom['top5_hit_rate']*100:.1f}%\",\n",
    "            'MRR': f\"{metrics_geom['mrr']*100:.1f}%\",\n",
    "            'Coverage': f\"{metrics_geom['catalogue_coverage']:.2f}\",\n",
    "            'Predizioni': f\"{metrics_geom['total_predictions']:,}\",\n",
    "            'Œî Top-1': f\"{top1_improvement:+.1f}%\",\n",
    "            'Œî Top-5': f\"{top5_improvement:+.1f}%\",\n",
    "            'Œî MRR': f\"{mrr_improvement:+.1f}%\"\n",
    "        })\n",
    "    \n",
    "    # Crea DataFrame per display\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(\"\\nüìä TABELLA COMPARATIVA DOPPIA STRATEGIA:\")\n",
    "    print(\"=\" * 120)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    # Salva la tabella per uso in LaTeX\n",
    "    latex_table_path = Path(OUTPUT_DIRS['comparison']) / 'dual_strategy_table.csv'\n",
    "    comparison_df.to_csv(latex_table_path, index=False)\n",
    "    print(f\"\\nüíæ Tabella salvata in: {latex_table_path}\")\n",
    "    \n",
    "    # Genera codice LaTeX pronto all'uso\n",
    "    latex_code_path = Path(OUTPUT_DIRS['comparison']) / 'dual_strategy_table.tex'\n",
    "    \n",
    "    with open(latex_code_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"% Tabella generata automaticamente - Doppia Strategia\\n\")\n",
    "        f.write(\"\\\\begin{table}[H]\\n\")\n",
    "        f.write(\"\\\\centering\\n\")\n",
    "        f.write(\"\\\\caption{Confronto Performance: Strategia Base vs Geometrica}\\n\")\n",
    "        f.write(\"\\\\label{tab:dual_strategy_comparison}\\n\")\n",
    "        f.write(\"\\\\begin{tabular}{llcccccccc}\\n\")\n",
    "        f.write(\"\\\\toprule\\n\")\n",
    "        f.write(\"\\\\textbf{Modello} & \\\\textbf{Strategia} & \\\\textbf{Parametri} & \\\\textbf{Top-1} & \\\\textbf{Top-5} & \\\\textbf{MRR} & \\\\textbf{Œî Top-1} & \\\\textbf{Œî Top-5} & \\\\textbf{Œî MRR} \\\\\\\\\\n\")\n",
    "        f.write(\"\\\\midrule\\n\")\n",
    "        \n",
    "        current_model = None\n",
    "        for _, row in comparison_df.iterrows():\n",
    "            if current_model != row['Modello']:\n",
    "                if current_model is not None:\n",
    "                    f.write(\"\\\\midrule\\n\")\n",
    "                current_model = row['Modello']\n",
    "            \n",
    "            model_name = row['Modello'] if row['Strategia'] == 'Base' else ''\n",
    "            f.write(f\"{model_name} & {row['Strategia']} & {row['Parametri']} & {row['Top-1 Acc.']} & {row['Top-5 HR']} & {row['MRR']} & {row['Œî Top-1']} & {row['Œî Top-5']} & {row['Œî MRR']} \\\\\\\\\\n\")\n",
    "        \n",
    "        f.write(\"\\\\bottomrule\\n\")\n",
    "        f.write(\"\\\\end{tabular}\\n\")\n",
    "        f.write(\"\\\\end{table}\\n\")\n",
    "    \n",
    "    print(f\"üìÑ Codice LaTeX salvato in: {latex_code_path}\")\n",
    "    \n",
    "    # Analisi miglioramenti con geometria\n",
    "    print(\"\\nüìà ANALISI MIGLIORAMENTI CON GEOMETRIA:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    total_improvements = {'top1': 0, 'top5': 0, 'mrr': 0}\n",
    "    positive_improvements = {'top1': 0, 'top5': 0, 'mrr': 0}\n",
    "    \n",
    "    for model_key in models_both_strategies:\n",
    "        model_name = MODELS[model_key]['name']\n",
    "        metrics_base = model_metrics_base[model_key]\n",
    "        metrics_geom = model_metrics_geom[model_key]\n",
    "        \n",
    "        top1_imp = (metrics_geom['top1_accuracy'] - metrics_base['top1_accuracy']) * 100\n",
    "        top5_imp = (metrics_geom['top5_hit_rate'] - metrics_base['top5_hit_rate']) * 100\n",
    "        mrr_imp = (metrics_geom['mrr'] - metrics_base['mrr']) * 100\n",
    "        \n",
    "        total_improvements['top1'] += top1_imp\n",
    "        total_improvements['top5'] += top5_imp  \n",
    "        total_improvements['mrr'] += mrr_imp\n",
    "        \n",
    "        if top1_imp > 0: positive_improvements['top1'] += 1\n",
    "        if top5_imp > 0: positive_improvements['top5'] += 1\n",
    "        if mrr_imp > 0: positive_improvements['mrr'] += 1\n",
    "        \n",
    "        print(f\"{model_name:>20s}: Top-1 {top1_imp:+.1f}%, Top-5 {top5_imp:+.1f}%, MRR {mrr_imp:+.1f}%\")\n",
    "    \n",
    "    # Media miglioramenti\n",
    "    n_models = len(models_both_strategies)\n",
    "    print(f\"\\nüéØ MEDIA MIGLIORAMENTI:\")\n",
    "    print(f\"   Top-1 Accuracy: {total_improvements['top1']/n_models:+.1f}% (positivi: {positive_improvements['top1']}/{n_models})\")\n",
    "    print(f\"   Top-5 Hit Rate: {total_improvements['top5']/n_models:+.1f}% (positivi: {positive_improvements['top5']}/{n_models})\")\n",
    "    print(f\"   MRR:            {total_improvements['mrr']/n_models:+.1f}% (positivi: {positive_improvements['mrr']}/{n_models})\")\n",
    "    \n",
    "    # Identifica best performers per strategia\n",
    "    print(f\"\\nüèÜ BEST PERFORMERS PER STRATEGIA:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Base\n",
    "    best_base_top1 = max(models_both_strategies, key=lambda k: model_metrics_base[k]['top1_accuracy'])\n",
    "    best_base_mrr = max(models_both_strategies, key=lambda k: model_metrics_base[k]['mrr'])\n",
    "    \n",
    "    print(f\"BASE - Top-1: {MODELS[best_base_top1]['name']} ({model_metrics_base[best_base_top1]['top1_accuracy']*100:.1f}%)\")\n",
    "    print(f\"BASE - MRR:   {MODELS[best_base_mrr]['name']} ({model_metrics_base[best_base_mrr]['mrr']*100:.1f}%)\")\n",
    "    \n",
    "    # Geom\n",
    "    best_geom_top1 = max(models_both_strategies, key=lambda k: model_metrics_geom[k]['top1_accuracy'])\n",
    "    best_geom_mrr = max(models_both_strategies, key=lambda k: model_metrics_geom[k]['mrr'])\n",
    "    \n",
    "    print(f\"GEOM - Top-1: {MODELS[best_geom_top1]['name']} ({model_metrics_geom[best_geom_top1]['top1_accuracy']*100:.1f}%)\")\n",
    "    print(f\"GEOM - MRR:   {MODELS[best_geom_mrr]['name']} ({model_metrics_geom[best_geom_mrr]['mrr']*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® 3. Generazione Grafici Comparativi Principali\n",
    "\n",
    "### 3.1 Grafico a Barre Comparativo Principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GRAFICI COMPARATIVI AFFIANCATI - BASE vs GEOM\n",
    "# ============================================================================\n",
    "\n",
    "if len(models_both_strategies) < 1:\n",
    "    print(\"‚è≠Ô∏è  Saltando grafici affiancati: serve almeno 1 modello con entrambe le strategie\")\n",
    "else:\n",
    "    print(\"üé® Creazione grafici comparativi affiancati (Base vs Geom)...\")\n",
    "    \n",
    "    # Prepara i dati per entrambe le strategie\n",
    "    models_list = [MODELS[k]['name'] for k in models_both_strategies]\n",
    "    colors_list = [MODELS[k]['color'] for k in models_both_strategies]\n",
    "    \n",
    "    # Metriche per entrambe le strategie\n",
    "    base_top1 = [model_metrics_base[k]['top1_accuracy'] * 100 for k in models_both_strategies]\n",
    "    geom_top1 = [model_metrics_geom[k]['top1_accuracy'] * 100 for k in models_both_strategies]\n",
    "    \n",
    "    base_top5 = [model_metrics_base[k]['top5_hit_rate'] * 100 for k in models_both_strategies]\n",
    "    geom_top5 = [model_metrics_geom[k]['top5_hit_rate'] * 100 for k in models_both_strategies]\n",
    "    \n",
    "    base_mrr = [model_metrics_base[k]['mrr'] * 100 for k in models_both_strategies]\n",
    "    geom_mrr = [model_metrics_geom[k]['mrr'] * 100 for k in models_both_strategies]\n",
    "    \n",
    "    # ==================== GRAFICO COMPARATIVO PRINCIPALE AFFIANCATO ====================\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle('Performance Comparison: Base Strategy vs Geometric Strategy', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    # RIGA SUPERIORE: Strategia BASE\n",
    "    # Top-1 Accuracy BASE\n",
    "    bars1 = axes[0,0].bar(models_list, base_top1, color=colors_list, alpha=0.7, \n",
    "                         edgecolor='black', linewidth=0.5, label='Base Strategy')\n",
    "    axes[0,0].set_title('Top-1 Accuracy - Base Strategy', fontsize=14, fontweight='bold')\n",
    "    axes[0,0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    axes[0,0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, value in zip(bars1, base_top1):\n",
    "        axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                      f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # Top-5 Hit Rate BASE\n",
    "    bars2 = axes[0,1].bar(models_list, base_top5, color=colors_list, alpha=0.7, \n",
    "                         edgecolor='black', linewidth=0.5, label='Base Strategy')\n",
    "    axes[0,1].set_title('Top-5 Hit Rate - Base Strategy', fontsize=14, fontweight='bold')\n",
    "    axes[0,1].set_ylabel('Hit Rate (%)', fontsize=12)\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    axes[0,1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, value in zip(bars2, base_top5):\n",
    "        axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                      f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # MRR BASE\n",
    "    bars3 = axes[0,2].bar(models_list, base_mrr, color=colors_list, alpha=0.7, \n",
    "                         edgecolor='black', linewidth=0.5, label='Base Strategy')\n",
    "    axes[0,2].set_title('Mean Reciprocal Rank - Base Strategy', fontsize=14, fontweight='bold')\n",
    "    axes[0,2].set_ylabel('MRR (%)', fontsize=12)\n",
    "    axes[0,2].tick_params(axis='x', rotation=45)\n",
    "    axes[0,2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, value in zip(bars3, base_mrr):\n",
    "        axes[0,2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                      f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # RIGA INFERIORE: Strategia GEOM\n",
    "    # Top-1 Accuracy GEOM\n",
    "    bars4 = axes[1,0].bar(models_list, geom_top1, color=colors_list, alpha=0.9, \n",
    "                         edgecolor='black', linewidth=0.5, label='Geometric Strategy')\n",
    "    axes[1,0].set_title('Top-1 Accuracy - Geometric Strategy', fontsize=14, fontweight='bold')\n",
    "    axes[1,0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    axes[1,0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, value in zip(bars4, geom_top1):\n",
    "        axes[1,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                      f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # Top-5 Hit Rate GEOM\n",
    "    bars5 = axes[1,1].bar(models_list, geom_top5, color=colors_list, alpha=0.9, \n",
    "                         edgecolor='black', linewidth=0.5, label='Geometric Strategy')\n",
    "    axes[1,1].set_title('Top-5 Hit Rate - Geometric Strategy', fontsize=14, fontweight='bold')\n",
    "    axes[1,1].set_ylabel('Hit Rate (%)', fontsize=12)\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    axes[1,1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, value in zip(bars5, geom_top5):\n",
    "        axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                      f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # MRR GEOM\n",
    "    bars6 = axes[1,2].bar(models_list, geom_mrr, color=colors_list, alpha=0.9, \n",
    "                         edgecolor='black', linewidth=0.5, label='Geometric Strategy')\n",
    "    axes[1,2].set_title('Mean Reciprocal Rank - Geometric Strategy', fontsize=14, fontweight='bold')\n",
    "    axes[1,2].set_ylabel('MRR (%)', fontsize=12)\n",
    "    axes[1,2].tick_params(axis='x', rotation=45)\n",
    "    axes[1,2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, value in zip(bars6, geom_mrr):\n",
    "        axes[1,2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                      f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # Aggiungi linee divisorie visive\n",
    "    for ax in axes.flat:\n",
    "        ax.set_ylim(bottom=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva il grafico\n",
    "    output_path = Path(OUTPUT_DIRS['side_by_side']) / 'base_vs_geom_comparison.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"üíæ Salvato: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # ==================== GRAFICI SOVRAPPOSTI PER CONFRONTO DIRETTO ====================\n",
    "    print(\"\\nüé® Creazione grafici sovrapposti per confronto diretto...\")\n",
    "    \n",
    "    metrics_info = [\n",
    "        ('Top-1 Accuracy', base_top1, geom_top1, 'top1_base_vs_geom_overlaid.png'),\n",
    "        ('Top-5 Hit Rate', base_top5, geom_top5, 'top5_base_vs_geom_overlaid.png'),\n",
    "        ('Mean Reciprocal Rank', base_mrr, geom_mrr, 'mrr_base_vs_geom_overlaid.png')\n",
    "    ]\n",
    "    \n",
    "    x = np.arange(len(models_list))\n",
    "    width = 0.35\n",
    "    \n",
    "    for metric_name, base_values, geom_values, filename in metrics_info:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Barre affiancate\n",
    "        bars1 = ax.bar(x - width/2, base_values, width, label='Base Strategy', \n",
    "                      color=[c + '80' for c in colors_list], edgecolor='black', linewidth=0.5)\n",
    "        bars2 = ax.bar(x + width/2, geom_values, width, label='Geometric Strategy', \n",
    "                      color=colors_list, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        ax.set_xlabel('Models', fontsize=12)\n",
    "        ax.set_ylabel(f'{metric_name} (%)', fontsize=12)\n",
    "        ax.set_title(f'{metric_name}: Base vs Geometric Strategy Comparison', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(models_list, rotation=45, ha='right')\n",
    "        ax.legend(loc='upper left', fontsize=11)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Aggiungi valori sopra le barre\n",
    "        for bar, value in zip(bars1, base_values):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(base_values)*0.01, \n",
    "                   f'{value:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for bar, value in zip(bars2, geom_values):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(geom_values)*0.01, \n",
    "                   f'{value:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        # Aggiungi frecce di miglioramento\n",
    "        for i, (base_val, geom_val) in enumerate(zip(base_values, geom_values)):\n",
    "            if geom_val > base_val:\n",
    "                ax.annotate('', xy=(i + width/2, geom_val), xytext=(i - width/2, base_val),\n",
    "                          arrowprops=dict(arrowstyle='->', color='green', lw=1.5, alpha=0.7))\n",
    "            elif geom_val < base_val:\n",
    "                ax.annotate('', xy=(i + width/2, geom_val), xytext=(i - width/2, base_val),\n",
    "                          arrowprops=dict(arrowstyle='->', color='red', lw=1.5, alpha=0.7))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva\n",
    "        output_path = Path(OUTPUT_DIRS['side_by_side']) / filename\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        print(f\"üíæ Salvato: {output_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Grafici comparativi affiancati completati!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Scatter Plot Performance vs Efficienza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GRAFICI DI MIGLIORAMENTO E DELTA ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "if len(models_both_strategies) < 1:\n",
    "    print(\"‚è≠Ô∏è  Saltando analisi miglioramenti: serve almeno 1 modello con entrambe le strategie\")\n",
    "else:\n",
    "    print(\"üìà Creazione grafici di analisi miglioramenti con strategia geometrica...\")\n",
    "    \n",
    "    # Calcola i delta per ogni modello\n",
    "    model_deltas = {}\n",
    "    for model_key in models_both_strategies:\n",
    "        base_metrics = model_metrics_base[model_key]\n",
    "        geom_metrics = model_metrics_geom[model_key]\n",
    "        \n",
    "        model_deltas[model_key] = {\n",
    "            'top1_delta': (geom_metrics['top1_accuracy'] - base_metrics['top1_accuracy']) * 100,\n",
    "            'top5_delta': (geom_metrics['top5_hit_rate'] - base_metrics['top5_hit_rate']) * 100,\n",
    "            'mrr_delta': (geom_metrics['mrr'] - base_metrics['mrr']) * 100,\n",
    "            'coverage_delta': (geom_metrics['catalogue_coverage'] - base_metrics['catalogue_coverage'])\n",
    "        }\n",
    "    \n",
    "    # ==================== GRAFICO DELTA IMPROVEMENTS ====================\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle('Performance Improvements with Geometric Information', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    models_list = [MODELS[k]['name'] for k in models_both_strategies]\n",
    "    colors_list = [MODELS[k]['color'] for k in models_both_strategies]\n",
    "    \n",
    "    # Delta Top-1\n",
    "    top1_deltas = [model_deltas[k]['top1_delta'] for k in models_both_strategies]\n",
    "    bars1 = ax1.bar(models_list, top1_deltas, color=colors_list, alpha=0.8, \n",
    "                   edgecolor='black', linewidth=0.5)\n",
    "    ax1.set_title('Top-1 Accuracy Improvement (Œî%)', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Improvement (%)', fontsize=12)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    ax1.axhline(y=0, color='red', linestyle='--', alpha=0.7, linewidth=1)\n",
    "    \n",
    "    for bar, value in zip(bars1, top1_deltas):\n",
    "        color = 'green' if value > 0 else 'red'\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + (0.1 if value > 0 else -0.1), \n",
    "                f'{value:+.1f}%', ha='center', va='bottom' if value > 0 else 'top', \n",
    "                fontweight='bold', color=color, fontsize=10)\n",
    "    \n",
    "    # Delta Top-5\n",
    "    top5_deltas = [model_deltas[k]['top5_delta'] for k in models_both_strategies]\n",
    "    bars2 = ax2.bar(models_list, top5_deltas, color=colors_list, alpha=0.8, \n",
    "                   edgecolor='black', linewidth=0.5)\n",
    "    ax2.set_title('Top-5 Hit Rate Improvement (Œî%)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Improvement (%)', fontsize=12)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    ax2.axhline(y=0, color='red', linestyle='--', alpha=0.7, linewidth=1)\n",
    "    \n",
    "    for bar, value in zip(bars2, top5_deltas):\n",
    "        color = 'green' if value > 0 else 'red'\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + (0.1 if value > 0 else -0.1), \n",
    "                f'{value:+.1f}%', ha='center', va='bottom' if value > 0 else 'top', \n",
    "                fontweight='bold', color=color, fontsize=10)\n",
    "    \n",
    "    # Delta MRR\n",
    "    mrr_deltas = [model_deltas[k]['mrr_delta'] for k in models_both_strategies]\n",
    "    bars3 = ax3.bar(models_list, mrr_deltas, color=colors_list, alpha=0.8, \n",
    "                   edgecolor='black', linewidth=0.5)\n",
    "    ax3.set_title('MRR Improvement (Œî%)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('Improvement (%)', fontsize=12)\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    ax3.axhline(y=0, color='red', linestyle='--', alpha=0.7, linewidth=1)\n",
    "    \n",
    "    for bar, value in zip(bars3, mrr_deltas):\n",
    "        color = 'green' if value > 0 else 'red'\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + (0.1 if value > 0 else -0.1), \n",
    "                f'{value:+.1f}%', ha='center', va='bottom' if value > 0 else 'top', \n",
    "                fontweight='bold', color=color, fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    output_path = Path(OUTPUT_DIRS['side_by_side']) / 'geometric_improvements_delta.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"üíæ Salvato: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # ==================== RADAR CHART COMPARISON ====================\n",
    "    print(\"\\nüé® Creazione radar chart per confronto multi-dimensionale...\")\n",
    "    \n",
    "    # Prepara dati per radar chart\n",
    "    metrics_labels = ['Top-1\\\\nAccuracy', 'Top-5\\\\nHit Rate', 'Mean Reciprocal\\\\nRank', 'Catalogue\\\\nCoverage']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(models_both_strategies), figsize=(6 * len(models_both_strategies), 6), \n",
    "                            subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    if len(models_both_strategies) == 1:\n",
    "        axes = [axes]  # Assicura che sia sempre una lista\n",
    "    \n",
    "    fig.suptitle('Multi-Dimensional Performance Comparison: Base vs Geometric', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, model_key in enumerate(models_both_strategies):\n",
    "        ax = axes[i]\n",
    "        model_config = MODELS[model_key]\n",
    "        \n",
    "        # Dati base e geom normalizzati (0-100)\n",
    "        base_metrics = model_metrics_base[model_key]\n",
    "        geom_metrics = model_metrics_geom[model_key]\n",
    "        \n",
    "        base_values = [\n",
    "            base_metrics['top1_accuracy'] * 100,\n",
    "            base_metrics['top5_hit_rate'] * 100,\n",
    "            base_metrics['mrr'] * 100,\n",
    "            min(base_metrics['catalogue_coverage'] * 100, 100)  # Cap at 100%\n",
    "        ]\n",
    "        \n",
    "        geom_values = [\n",
    "            geom_metrics['top1_accuracy'] * 100,\n",
    "            geom_metrics['top5_hit_rate'] * 100,\n",
    "            geom_metrics['mrr'] * 100,\n",
    "            min(geom_metrics['catalogue_coverage'] * 100, 100)  # Cap at 100%\n",
    "        ]\n",
    "        \n",
    "        # Angoli per il radar chart\n",
    "        angles = np.linspace(0, 2 * np.pi, len(metrics_labels), endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Chiude il cerchio\n",
    "        base_values += base_values[:1]\n",
    "        geom_values += geom_values[:1]\n",
    "        \n",
    "        # Plot\n",
    "        ax.plot(angles, base_values, 'o-', linewidth=2, label='Base Strategy', \n",
    "               color=model_config['color'], alpha=0.7)\n",
    "        ax.fill(angles, base_values, alpha=0.25, color=model_config['color'])\n",
    "        \n",
    "        ax.plot(angles, geom_values, 's-', linewidth=2, label='Geometric Strategy', \n",
    "               color=model_config['color'])\n",
    "        ax.fill(angles, geom_values, alpha=0.25, color=model_config['color'])\n",
    "        \n",
    "        # Configurazione\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(metrics_labels, fontsize=10)\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_title(f'{model_config[\"name\"]}', fontsize=14, fontweight='bold', pad=20)\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "        ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    output_path = Path(OUTPUT_DIRS['side_by_side']) / 'radar_chart_base_vs_geom.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"üíæ Salvato: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # ==================== SUMMARY IMPROVEMENT ANALYSIS ====================\n",
    "    print(\"\\nüìä SUMMARY ANALYSIS - Impatto della Strategia Geometrica:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Calcola statistiche aggregate\n",
    "    all_top1_deltas = [model_deltas[k]['top1_delta'] for k in models_both_strategies]\n",
    "    all_top5_deltas = [model_deltas[k]['top5_delta'] for k in models_both_strategies]\n",
    "    all_mrr_deltas = [model_deltas[k]['mrr_delta'] for k in models_both_strategies]\n",
    "    \n",
    "    print(f\"Miglioramenti medi con strategia geometrica:\")\n",
    "    print(f\"  üìà Top-1 Accuracy: {np.mean(all_top1_deltas):+.2f}% (¬±{np.std(all_top1_deltas):.2f}%)\")\n",
    "    print(f\"  üìà Top-5 Hit Rate: {np.mean(all_top5_deltas):+.2f}% (¬±{np.std(all_top5_deltas):.2f}%)\")\n",
    "    print(f\"  üìà MRR:            {np.mean(all_mrr_deltas):+.2f}% (¬±{np.std(all_mrr_deltas):.2f}%)\")\n",
    "    \n",
    "    # Conteggio miglioramenti positivi\n",
    "    positive_top1 = sum(1 for d in all_top1_deltas if d > 0)\n",
    "    positive_top5 = sum(1 for d in all_top5_deltas if d > 0)\n",
    "    positive_mrr = sum(1 for d in all_mrr_deltas if d > 0)\n",
    "    \n",
    "    n_models = len(models_both_strategies)\n",
    "    print(f\"\\nModelli con miglioramenti positivi:\")\n",
    "    print(f\"  ‚úÖ Top-1 Accuracy: {positive_top1}/{n_models} ({positive_top1/n_models*100:.1f}%)\")\n",
    "    print(f\"  ‚úÖ Top-5 Hit Rate: {positive_top5}/{n_models} ({positive_top5/n_models*100:.1f}%)\")\n",
    "    print(f\"  ‚úÖ MRR:            {positive_mrr}/{n_models} ({positive_mrr/n_models*100:.1f}%)\")\n",
    "    \n",
    "    # Modello con maggiori miglioramenti\n",
    "    best_improvement_model = max(models_both_strategies, \n",
    "                               key=lambda k: sum([model_deltas[k]['top1_delta'], \n",
    "                                                model_deltas[k]['top5_delta'], \n",
    "                                                model_deltas[k]['mrr_delta']]))\n",
    "    \n",
    "    print(f\"\\nüèÜ Modello che beneficia di pi√π dalla strategia geometrica:\")\n",
    "    print(f\"   {MODELS[best_improvement_model]['name']}\")\n",
    "    best_deltas = model_deltas[best_improvement_model]\n",
    "    print(f\"   Top-1: {best_deltas['top1_delta']:+.1f}%, Top-5: {best_deltas['top5_delta']:+.1f}%, MRR: {best_deltas['mrr_delta']:+.1f}%\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Analisi miglioramenti completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Heat Map Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HEAT MAP PERFORMANCE NORMALIZZATA\n",
    "# ============================================================================\n",
    "\n",
    "if len(successfully_loaded) < 2:\n",
    "    print(\"‚è≠Ô∏è  Saltando heat map: servono almeno 2 modelli\")\n",
    "else:\n",
    "    print(\"üé® Creazione heat map performance normalizzata...\")\n",
    "    \n",
    "    # Prepara dati per heat map\n",
    "    metrics_for_heatmap = ['top1_accuracy', 'top5_hit_rate', 'mrr', 'catalogue_coverage']\n",
    "    metric_labels = ['Top-1\\nAccuracy', 'Top-5\\nHit Rate', 'Mean Reciprocal\\nRank', 'Catalogue\\nCoverage']\n",
    "    \n",
    "    # Crea matrice dati\n",
    "    heatmap_data = []\n",
    "    model_labels = []\n",
    "    \n",
    "    for model_key in successfully_loaded:\n",
    "        model_config = MODELS[model_key]\n",
    "        metrics = model_metrics[model_key]\n",
    "        \n",
    "        row_data = []\n",
    "        for metric in metrics_for_heatmap:\n",
    "            if metric == 'catalogue_coverage':\n",
    "                # Coverage pu√≤ essere > 1, quindi normalizziamo diversamente\n",
    "                value = min(metrics[metric] * 100, 100)  # Cap a 100%\n",
    "            else:\n",
    "                value = metrics[metric] * 100\n",
    "            row_data.append(value)\n",
    "        \n",
    "        heatmap_data.append(row_data)\n",
    "        model_labels.append(model_config['name'])\n",
    "    \n",
    "    # Converte a numpy array per facilit√†\n",
    "    heatmap_matrix = np.array(heatmap_data)\n",
    "    \n",
    "    # Crea heat map\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Usa colormap personalizzata\n",
    "    im = ax.imshow(heatmap_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)\n",
    "    \n",
    "    # Configura assi\n",
    "    ax.set_xticks(range(len(metric_labels)))\n",
    "    ax.set_xticklabels(metric_labels, rotation=0, ha='center')\n",
    "    ax.set_yticks(range(len(model_labels)))\n",
    "    ax.set_yticklabels(model_labels)\n",
    "    \n",
    "    # Aggiungi valori nelle celle\n",
    "    for i in range(len(model_labels)):\n",
    "        for j in range(len(metric_labels)):\n",
    "            value = heatmap_matrix[i, j]\n",
    "            text_color = 'white' if value < 50 else 'black'\n",
    "            ax.text(j, i, f'{value:.1f}%', ha='center', va='center', \n",
    "                   color=text_color, fontweight='bold', fontsize=10)\n",
    "    \n",
    "    ax.set_title('Performance Heat Map - Model Comparison\\n(Normalized 0-100%)', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax, shrink=0.8, aspect=20)\n",
    "    cbar.set_label('Performance (%)', rotation=270, labelpad=20, fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    output_path = Path(OUTPUT_DIRS['comparison']) / 'models_performance_heatmap.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"üíæ Salvato: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Analisi best/worst per categoria\n",
    "    print(\"\\nüìä ANALISI HEAT MAP:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for j, metric_name in enumerate(['Top-1 Accuracy', 'Top-5 Hit Rate', 'MRR', 'Coverage']):\n",
    "        values_for_metric = heatmap_matrix[:, j]\n",
    "        best_idx = np.argmax(values_for_metric)\n",
    "        worst_idx = np.argmin(values_for_metric)\n",
    "        \n",
    "        print(f\"{metric_name}:\")\n",
    "        print(f\"  ü•á Best:  {model_labels[best_idx]} ({values_for_metric[best_idx]:.1f}%)\")\n",
    "        print(f\"  ü•â Worst: {model_labels[worst_idx]} ({values_for_metric[worst_idx]:.1f}%)\")\n",
    "        print()\n",
    "    \n",
    "    print(\"‚úÖ Heat map performance completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 4. Analisi Temporale Multi-Modello\n",
    "\n",
    "Confronto delle performance nel tempo per identificare stabilit√† e trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ANALISI TEMPORALE MULTI-MODELLO\n",
    "# ============================================================================\n",
    "\n",
    "if len(successfully_loaded) < 2:\n",
    "    print(\"‚è≠Ô∏è  Saltando analisi temporale: servono almeno 2 modelli\")\n",
    "else:\n",
    "    print(\"üìÖ Analisi temporale multi-modello...\")\n",
    "    \n",
    "    # Verifica che abbiamo dati temporali\n",
    "    temporal_data_available = False\n",
    "    for model_key in successfully_loaded:\n",
    "        df = model_data[model_key]\n",
    "        if 'year' in df.columns and not df['year'].isna().all():\n",
    "            temporal_data_available = True\n",
    "            break\n",
    "    \n",
    "    if not temporal_data_available:\n",
    "        print(\"   ‚ö†Ô∏è  Nessun dato temporale disponibile (colonna 'year' mancante o vuota)\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Dati temporali trovati, creazione grafici...\")\n",
    "        \n",
    "        # Calcola metriche per anno per ogni modello\n",
    "        temporal_results = {}\n",
    "        all_years = set()\n",
    "        \n",
    "        for model_key in successfully_loaded:\n",
    "            df = model_data[model_key]\n",
    "            if 'year' in df.columns:\n",
    "                # Filtra anni validi\n",
    "                df_with_year = df[df['year'].notna()]\n",
    "                \n",
    "                if len(df_with_year) > 0:\n",
    "                    # Calcola metriche per anno\n",
    "                    yearly_metrics = {}\n",
    "                    for year in df_with_year['year'].unique():\n",
    "                        year_data = df_with_year[df_with_year['year'] == year]\n",
    "                        if len(year_data) > 0:\n",
    "                            metrics = calculate_metrics(year_data)\n",
    "                            yearly_metrics[int(year)] = metrics\n",
    "                            all_years.add(int(year))\n",
    "                    \n",
    "                    temporal_results[model_key] = yearly_metrics\n",
    "        \n",
    "        if len(temporal_results) == 0:\n",
    "            print(\"   ‚ö†Ô∏è  Nessun risultato temporale calcolabile\")\n",
    "        else:\n",
    "            # Ordina gli anni\n",
    "            sorted_years = sorted(all_years)\n",
    "            print(f\"   üìä Anni disponibili: {sorted_years}\")\n",
    "            \n",
    "            # Crea grafici temporali\n",
    "            metrics_to_plot = [\n",
    "                ('top1_accuracy', 'Top-1 Accuracy (%)', 'temporal_top1_comparison.png'),\n",
    "                ('top5_hit_rate', 'Top-5 Hit Rate (%)', 'temporal_top5_comparison.png'),\n",
    "                ('mrr', 'Mean Reciprocal Rank (%)', 'temporal_mrr_comparison.png')\n",
    "            ]\n",
    "            \n",
    "            for metric_key, ylabel, filename in metrics_to_plot:\n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                \n",
    "                # Plot linea per ogni modello\n",
    "                for model_key in successfully_loaded:\n",
    "                    if model_key in temporal_results:\n",
    "                        model_config = MODELS[model_key]\n",
    "                        \n",
    "                        # Prepara dati per questo modello\n",
    "                        x_data = []\n",
    "                        y_data = []\n",
    "                        \n",
    "                        for year in sorted_years:\n",
    "                            if year in temporal_results[model_key]:\n",
    "                                x_data.append(year)\n",
    "                                y_data.append(temporal_results[model_key][year][metric_key] * 100)\n",
    "                        \n",
    "                        if len(x_data) > 0:\n",
    "                            ax.plot(x_data, y_data, color=model_config['color'], \n",
    "                                   marker='o', linewidth=2, markersize=6,\n",
    "                                   label=model_config['name'])\n",
    "                \n",
    "                ax.set_xlabel('Year', fontsize=12)\n",
    "                ax.set_ylabel(ylabel, fontsize=12)\n",
    "                ax.set_title(f'{ylabel.replace(\" (%)\", \"\")} - Temporal Comparison', \n",
    "                           fontsize=14, fontweight='bold')\n",
    "                ax.legend(loc='best')\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Evidenzia periodo COVID se presente\n",
    "                covid_years = [2020, 2021]\n",
    "                if any(year in sorted_years for year in covid_years):\n",
    "                    for covid_year in covid_years:\n",
    "                        if covid_year in sorted_years:\n",
    "                            ax.axvline(covid_year, color='red', linestyle='--', \n",
    "                                     alpha=0.5, linewidth=1)\n",
    "                    ax.text(0.02, 0.98, 'Red lines: COVID-19 period', \n",
    "                           transform=ax.transAxes, fontsize=10, \n",
    "                           verticalalignment='top', \n",
    "                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Salva\n",
    "                output_path = Path(OUTPUT_DIRS['comparison']) / filename\n",
    "                plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "                print(f\"üíæ Salvato: {output_path}\")\n",
    "                \n",
    "                plt.show()\n",
    "            \n",
    "            # Analisi di stabilit√† temporale\n",
    "            print(\"\\nüìä ANALISI STABILIT√Ä TEMPORALE:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            for model_key in successfully_loaded:\n",
    "                if model_key in temporal_results and len(temporal_results[model_key]) > 1:\n",
    "                    model_name = MODELS[model_key]['name']\n",
    "                    \n",
    "                    # Calcola variabilit√† per MRR\n",
    "                    mrr_values = [temporal_results[model_key][year]['mrr'] * 100 \n",
    "                                 for year in temporal_results[model_key].keys()]\n",
    "                    mrr_std = np.std(mrr_values)\n",
    "                    mrr_mean = np.mean(mrr_values)\n",
    "                    stability_score = mrr_mean / (mrr_std + 1e-6)  # Higher = more stable\n",
    "                    \n",
    "                    print(f\"{model_name:>15s}: MRR avg={mrr_mean:.1f}%, std={mrr_std:.1f}%, stability={stability_score:.1f}\")\n",
    "            \n",
    "            print(\"\\n‚úÖ Analisi temporale completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 5. Analisi Errori Comparativa\n",
    "\n",
    "Confronto dei pattern di errore tra i diversi modelli per identificare bias e differenze qualitative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ANALISI ERRORI COMPARATIVA\n",
    "# ============================================================================\n",
    "\n",
    "if len(successfully_loaded) < 2:\n",
    "    print(\"‚è≠Ô∏è  Saltando analisi errori: servono almeno 2 modelli\")\n",
    "else:\n",
    "    print(\"üîç Analisi comparativa degli errori...\")\n",
    "    \n",
    "    # Analizza i POI pi√π problematici per ogni modello\n",
    "    print(\"\\nüìä POI PI√ô PROBLEMATICI PER MODELLO:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    model_error_patterns = {}\n",
    "    \n",
    "    for model_key in successfully_loaded:\n",
    "        df = model_data[model_key]\n",
    "        model_name = MODELS[model_key]['name']\n",
    "        \n",
    "        if 'ground_truth_norm' in df.columns and 'prediction_norm' in df.columns:\n",
    "            # Calcola hit@1 se non presente\n",
    "            if 'hit@1' not in df.columns:\n",
    "                df['hit@1'] = df['prediction_norm'].str[0] == df['ground_truth_norm']\n",
    "            \n",
    "            # Analizza errori\n",
    "            errors_df = df[~df['hit@1']].copy()\n",
    "            \n",
    "            if len(errors_df) > 0:\n",
    "                # Top POI problematici (ground truth con pi√π errori)\n",
    "                error_counts = errors_df['ground_truth_norm'].value_counts().head(5)\n",
    "                total_counts = df['ground_truth_norm'].value_counts()\n",
    "                \n",
    "                print(f\"\\nüî¥ {model_name}:\")\n",
    "                print(\"   Top POI con pi√π errori:\")\n",
    "                \n",
    "                error_data = []\n",
    "                for poi, error_count in error_counts.items():\n",
    "                    total_count = total_counts.get(poi, error_count)\n",
    "                    error_rate = error_count / total_count\n",
    "                    print(f\"     {poi[:25]:>25s}: {error_count:>4d} errori ({error_rate:>5.1%})\")\n",
    "                    error_data.append((poi, error_count, error_rate))\n",
    "                \n",
    "                model_error_patterns[model_key] = error_data\n",
    "    \n",
    "    # Confronto bias geografici\n",
    "    print(f\"\\nüìä CONFRONTO BIAS NELLE PREDIZIONI:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for model_key in successfully_loaded:\n",
    "        df = model_data[model_key]\n",
    "        model_name = MODELS[model_key]['name']\n",
    "        \n",
    "        if 'prediction_norm' in df.columns:\n",
    "            # Analizza predizioni pi√π frequenti (possibili bias)\n",
    "            all_predictions = []\n",
    "            for pred_list in df['prediction_norm']:\n",
    "                if isinstance(pred_list, list) and len(pred_list) > 0:\n",
    "                    all_predictions.append(pred_list[0])  # Solo top-1 prediction\n",
    "            \n",
    "            if all_predictions:\n",
    "                pred_freq = Counter(all_predictions)\n",
    "                top_predictions = pred_freq.most_common(5)\n",
    "                \n",
    "                print(f\"\\nüéØ {model_name} - Predizioni pi√π frequenti:\")\n",
    "                total_preds = len(all_predictions)\n",
    "                for poi, count in top_predictions:\n",
    "                    percentage = (count / total_preds) * 100\n",
    "                    print(f\"     {poi[:25]:>25s}: {count:>5d} ({percentage:>4.1f}%)\")\n",
    "    \n",
    "    # Matrice di confusione comparativa (se fattibile)\n",
    "    if len(successfully_loaded) >= 2:\n",
    "        print(f\"\\nüìä Generazione matrici di confusione per confronto...\")\n",
    "        \n",
    "        # Identifica POI comuni pi√π frequenti\n",
    "        all_gt_pois = set()\n",
    "        for model_key in successfully_loaded:\n",
    "            df = model_data[model_key]\n",
    "            if 'ground_truth_norm' in df.columns:\n",
    "                all_gt_pois.update(df['ground_truth_norm'].unique())\n",
    "        \n",
    "        # Prendi top 10 POI pi√π comuni\n",
    "        poi_frequencies = Counter()\n",
    "        for model_key in successfully_loaded:\n",
    "            df = model_data[model_key]\n",
    "            if 'ground_truth_norm' in df.columns:\n",
    "                poi_frequencies.update(df['ground_truth_norm'].value_counts().to_dict())\n",
    "        \n",
    "        top_pois = [poi for poi, _ in poi_frequencies.most_common(10)]\n",
    "        \n",
    "        # Crea confusion matrix per ogni modello\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, model_key in enumerate(successfully_loaded):\n",
    "            if i >= len(axes):\n",
    "                break\n",
    "                \n",
    "            df = model_data[model_key]\n",
    "            model_name = MODELS[model_key]['name']\n",
    "            ax = axes[i]\n",
    "            \n",
    "            if 'ground_truth_norm' in df.columns and 'prediction_norm' in df.columns:\n",
    "                # Filtra per top POI\n",
    "                mask = (df['ground_truth_norm'].isin(top_pois) & \n",
    "                       df['prediction_norm'].str[0].isin(top_pois))\n",
    "                df_filtered = df[mask]\n",
    "                \n",
    "                if len(df_filtered) > 0:\n",
    "                    # Crea confusion matrix\n",
    "                    cm = pd.crosstab(df_filtered['ground_truth_norm'],\n",
    "                                   df_filtered['prediction_norm'].str[0],\n",
    "                                   normalize='index')\n",
    "                    \n",
    "                    # Plot heatmap\n",
    "                    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', \n",
    "                              ax=ax, cbar_kws={'shrink': 0.5})\n",
    "                    ax.set_title(f'{model_name}\\nConfusion Matrix', fontweight='bold')\n",
    "                    ax.set_xlabel('Predicted')\n",
    "                    ax.set_ylabel('True')\n",
    "                    \n",
    "                    # Ruota etichette per leggibilit√†\n",
    "                    ax.tick_params(axis='x', rotation=45)\n",
    "                    ax.tick_params(axis='y', rotation=0)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f'{model_name}\\nDati non disponibili', \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "        \n",
    "        # Nascondi assi non utilizzati\n",
    "        for j in range(len(successfully_loaded), len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.suptitle('Confusion Matrices Comparison - Top 10 POI', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva\n",
    "        output_path = Path(OUTPUT_DIRS['comparison']) / 'confusion_matrices_comparison.png'\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        print(f\"üíæ Salvato: {output_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Analisi errori comparativa completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã 6. Report Finale e Riepilogo\n",
    "\n",
    "Genera un report completo con tutti i risultati e le raccomandazioni per l'integrazione nella tesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# REPORT FINALE E RIEPILOGO - VERSIONE DOPPIA STRATEGIA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üìã Generazione report finale (Base + Geometric strategies)...\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"üéì DUAL-STRATEGY MULTI-MODEL COMPARISON ANALYSIS - FINAL REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(models_both_strategies) == 0:\n",
    "    print(\"\\n‚ùå NESSUN MODELLO CON ENTRAMBE LE STRATEGIE - VERIFICA CONFIGURAZIONE\")\n",
    "    print(\"\\nüí° AZIONI RICHIESTE:\")\n",
    "    print(\"   1. Verifica che esistano le directory:\")\n",
    "    print(\"      - results_deepseek-coder_33b_base_version/\")\n",
    "    print(\"      - results_deepseek-coder_33b_with_geom/\")  \n",
    "    print(\"      - results_mixtr_with_geom/\")\n",
    "    print(\"      - results/mixtral_8x7b/base_version/\")\n",
    "    print(\"      - results/qwen2.5_7b/base_version/ e /with_geom/\")\n",
    "    print(\"      - results/llama3.1_8b/base_version/ e /with_geom_srv_univr/\")\n",
    "    print(\"   2. Sposta i file CSV nelle directory appropriate\")\n",
    "    print(\"   3. Ri-esegui questo notebook\")\n",
    "else:\n",
    "    # Riepilogo modelli con doppia strategia\n",
    "    print(f\"\\nüìä MODELLI ANALIZZATI CON DOPPIA STRATEGIA: {len(models_both_strategies)}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    total_predictions_base = sum(model_metrics_base[k]['total_predictions'] for k in models_both_strategies)\n",
    "    total_predictions_geom = sum(model_metrics_geom[k]['total_predictions'] for k in models_both_strategies)\n",
    "    \n",
    "    for model_key in models_both_strategies:\n",
    "        model_config = MODELS[model_key]\n",
    "        metrics_base = model_metrics_base[model_key]\n",
    "        metrics_geom = model_metrics_geom[model_key]\n",
    "        \n",
    "        print(f\"‚úÖ {model_config['name']:>20s}:\")\n",
    "        print(f\"   Base:     {metrics_base['total_predictions']:>6,} predizioni\")\n",
    "        print(f\"   Geom:     {metrics_geom['total_predictions']:>6,} predizioni\")\n",
    "    \n",
    "    print(f\"\\nüìà TOTALE PREDIZIONI ANALIZZATE:\")\n",
    "    print(f\"   Base Strategy:      {total_predictions_base:,}\")\n",
    "    print(f\"   Geometric Strategy: {total_predictions_geom:,}\")\n",
    "    print(f\"   GRAN TOTALE:        {total_predictions_base + total_predictions_geom:,}\")\n",
    "    \n",
    "    # Best performers per strategia\n",
    "    print(f\"\\nüèÜ BEST PERFORMERS PER STRATEGIA:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    metrics_names = [\n",
    "        ('top1_accuracy', 'Top-1 Accuracy'),\n",
    "        ('top5_hit_rate', 'Top-5 Hit Rate'),\n",
    "        ('mrr', 'Mean Reciprocal Rank')\n",
    "    ]\n",
    "    \n",
    "    for metric_key, metric_name in metrics_names:\n",
    "        best_base = max(models_both_strategies, key=lambda k: model_metrics_base[k][metric_key])\n",
    "        best_geom = max(models_both_strategies, key=lambda k: model_metrics_geom[k][metric_key])\n",
    "        \n",
    "        best_base_value = model_metrics_base[best_base][metric_key] * 100\n",
    "        best_geom_value = model_metrics_geom[best_geom][metric_key] * 100\n",
    "        \n",
    "        print(f\"{metric_name:>18s}:\")\n",
    "        print(f\"   Base: {MODELS[best_base]['name']} ({best_base_value:.1f}%)\")\n",
    "        print(f\"   Geom: {MODELS[best_geom]['name']} ({best_geom_value:.1f}%)\")\n",
    "        \n",
    "        # Evidenzia se stesso modello vince in entrambe\n",
    "        if best_base == best_geom:\n",
    "            print(f\"   üèÜ {MODELS[best_base]['name']} domina entrambe le strategie!\")\n",
    "        print()\n",
    "    \n",
    "    # Analisi miglioramenti complessiva\n",
    "    if 'model_deltas' in locals():\n",
    "        print(f\"\\nüìà IMPATTO DELLA STRATEGIA GEOMETRICA:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        all_top1_deltas = [model_deltas[k]['top1_delta'] for k in models_both_strategies]\n",
    "        all_top5_deltas = [model_deltas[k]['top5_delta'] for k in models_both_strategies] \n",
    "        all_mrr_deltas = [model_deltas[k]['mrr_delta'] for k in models_both_strategies]\n",
    "        \n",
    "        print(f\"Miglioramenti medi:\")\n",
    "        print(f\"   Top-1 Accuracy: {np.mean(all_top1_deltas):+.2f}% ({'‚úÖ' if np.mean(all_top1_deltas) > 0 else '‚ùå'})\")\n",
    "        print(f\"   Top-5 Hit Rate: {np.mean(all_top5_deltas):+.2f}% ({'‚úÖ' if np.mean(all_top5_deltas) > 0 else '‚ùå'})\")\n",
    "        print(f\"   MRR:            {np.mean(all_mrr_deltas):+.2f}% ({'‚úÖ' if np.mean(all_mrr_deltas) > 0 else '‚ùå'})\")\n",
    "        \n",
    "        positive_improvements = sum(1 for d in all_top1_deltas + all_top5_deltas + all_mrr_deltas if d > 0)\n",
    "        total_comparisons = len(all_top1_deltas) * 3\n",
    "        success_rate = positive_improvements / total_comparisons * 100\n",
    "        \n",
    "        print(f\"\\nüéØ Tasso di successo strategia geometrica: {success_rate:.1f}%\")\n",
    "        print(f\"   ({positive_improvements}/{total_comparisons} metriche migliorate)\")\n",
    "    \n",
    "    # Files generati\n",
    "    print(f\"\\nüìÅ FILES GENERATI:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Controlla tutte le directory di output\n",
    "    all_generated_files = []\n",
    "    for output_dir_name, output_dir_path in OUTPUT_DIRS.items():\n",
    "        dir_path = Path(output_dir_path)\n",
    "        if dir_path.exists():\n",
    "            files = list(dir_path.glob('*.png')) + list(dir_path.glob('*.csv')) + list(dir_path.glob('*.tex'))\n",
    "            all_generated_files.extend(files)\n",
    "    \n",
    "    # Raggruppa per tipo\n",
    "    file_types = {\n",
    "        'PNG (Grafici)': [f for f in all_generated_files if f.suffix == '.png'],\n",
    "        'CSV (Tabelle)': [f for f in all_generated_files if f.suffix == '.csv'],\n",
    "        'TEX (LaTeX)': [f for f in all_generated_files if f.suffix == '.tex']\n",
    "    }\n",
    "    \n",
    "    for file_type, files in file_types.items():\n",
    "        if files:\n",
    "            print(f\"\\n{file_type}:\")\n",
    "            for file_path in sorted(files):\n",
    "                file_size = file_path.stat().st_size / 1024  # KB\n",
    "                rel_path = file_path.relative_to(Path.cwd().parent)\n",
    "                print(f\"  ‚úÖ {rel_path} ({file_size:.1f} KB)\")\n",
    "    \n",
    "    print(f\"\\nüìä TOTALE FILES GENERATI: {len(all_generated_files)}\")\n",
    "    \n",
    "    # Istruzioni per LaTeX\n",
    "    print(f\"\\nüìÑ INTEGRAZIONE LATEX AGGIORNATA:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"1. üìä Grafici salvati in:\")\n",
    "    print(\"   - img/multi_model_comparison/side_by_side/ (comparazioni affiancate)\")\n",
    "    print(\"   - img/multi_model_comparison/base/ (solo strategia base)\")\n",
    "    print(\"   - img/multi_model_comparison/geom/ (solo strategia geometrica)\")\n",
    "    \n",
    "    print(\"2. üìã Tabelle LaTeX generate:\")\n",
    "    print(\"   - dual_strategy_table.tex (tabella comparativa completa)\")\n",
    "    print(\"   - performance_table.tex (se disponibile)\")\n",
    "    \n",
    "    print(\"3. üñºÔ∏è  Grafici chiave per la tesi:\")\n",
    "    print(\"   - base_vs_geom_comparison.png (griglia 2x3 affiancata)\")\n",
    "    print(\"   - top1_base_vs_geom_overlaid.png (confronto diretto Top-1)\")\n",
    "    print(\"   - geometric_improvements_delta.png (analisi miglioramenti)\")\n",
    "    print(\"   - radar_chart_base_vs_geom.png (confronto multidimensionale)\")\n",
    "    \n",
    "    print(\"4. üìù Integrazione nel documento:\")\n",
    "    print(\"   - Usa \\\\input{img/multi_model_comparison/dual_strategy_table.tex}\")\n",
    "    print(\"   - \\\\includegraphics{img/multi_model_comparison/side_by_side/...}\")\n",
    "    \n",
    "    # Raccomandazioni strategiche\n",
    "    print(f\"\\nüí° RACCOMANDAZIONI STRATEGICHE:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if len(models_both_strategies) >= 2:\n",
    "        # Identifica modelli per diversi use case\n",
    "        most_improved_model = None\n",
    "        if 'model_deltas' in locals():\n",
    "            most_improved_model = max(models_both_strategies, \n",
    "                                    key=lambda k: sum([model_deltas[k]['top1_delta'], \n",
    "                                                     model_deltas[k]['top5_delta'], \n",
    "                                                     model_deltas[k]['mrr_delta']]))\n",
    "        \n",
    "        best_overall_base = max(models_both_strategies, \n",
    "                              key=lambda k: model_metrics_base[k]['top1_accuracy'])\n",
    "        best_overall_geom = max(models_both_strategies, \n",
    "                              key=lambda k: model_metrics_geom[k]['top1_accuracy'])\n",
    "        \n",
    "        print(f\"üéØ Per massima accuratezza (Base):      {MODELS[best_overall_base]['name']}\")\n",
    "        print(f\"üéØ Per massima accuratezza (Geom):      {MODELS[best_overall_geom]['name']}\")\n",
    "        \n",
    "        if most_improved_model:\n",
    "            improvement_sum = sum([model_deltas[most_improved_model]['top1_delta'],\n",
    "                                 model_deltas[most_improved_model]['top5_delta'],\n",
    "                                 model_deltas[most_improved_model]['mrr_delta']])\n",
    "            print(f\"üöÄ Maggior beneficio da geometria:      {MODELS[most_improved_model]['name']} (+{improvement_sum:.1f}%)\")\n",
    "        \n",
    "        # Analisi cost-benefit se disponibile info sui parametri\n",
    "        print(f\"\\n‚öñÔ∏è  TRADE-OFF ANALISI:\")\n",
    "        for model_key in models_both_strategies:\n",
    "            model_name = MODELS[model_key]['name']\n",
    "            params = MODELS[model_key]['params']\n",
    "            base_acc = model_metrics_base[model_key]['top1_accuracy'] * 100\n",
    "            geom_acc = model_metrics_geom[model_key]['top1_accuracy'] * 100\n",
    "            \n",
    "            print(f\"  {model_name} ({params}): Base {base_acc:.1f}% ‚Üí Geom {geom_acc:.1f}%\")\n",
    "    \n",
    "    # Status completamento\n",
    "    print(f\"\\n‚úÖ ANALISI DOPPIA STRATEGIA COMPLETATA CON SUCCESSO!\")\n",
    "    print(f\"   üìä {len(models_both_strategies)} modelli analizzati\")\n",
    "    print(f\"   üîÑ 2 strategie di prompt confrontate\")\n",
    "    print(f\"   üìà {len(all_generated_files)} file generati\")\n",
    "    print(f\"   üéØ Pronto per integrazione nella tesi\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéì DUAL-STRATEGY MULTI-MODEL ANALYSIS COMPLETED\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Note Finali e Prossimi Passi - Dual Strategy Analysis\n",
    "\n",
    "### ‚úÖ Checklist Completamento Dual-Strategy\n",
    "\n",
    "- [ ] **Auto-detection completata**: Directory rilevate automaticamente per entrambe le strategie\n",
    "- [ ] **Dati caricati**: Modelli con strategia base E geometrica identificati\n",
    "- [ ] **Grafici affiancati generati**: Files PNG creati in `img/multi_model_comparison/side_by_side/`\n",
    "- [ ] **Analisi miglioramenti**: Grafici delta e radar charts completati\n",
    "- [ ] **Tabelle dual-strategy**: File LaTeX con confronto base vs geom generato\n",
    "\n",
    "### üîÑ Prossimi Passi per Tesi\n",
    "\n",
    "1. **üìä Verifica grafici chiave**:\n",
    "   - `base_vs_geom_comparison.png` - Griglia 2x3 comparativa principale\n",
    "   - `top1_base_vs_geom_overlaid.png` - Confronto diretto Top-1\n",
    "   - `geometric_improvements_delta.png` - Analisi miglioramenti\n",
    "   - `radar_chart_base_vs_geom.png` - Confronto multidimensionale\n",
    "\n",
    "2. **üìã Integra tabelle LaTeX**: \n",
    "   - Copia `dual_strategy_table.tex` nel documento principale\n",
    "   - Include tabella con `\\input{img/multi_model_comparison/dual_strategy_table.tex}`\n",
    "\n",
    "3. **üñºÔ∏è Integra grafici**:\n",
    "   - Usa path: `\\includegraphics{img/multi_model_comparison/side_by_side/...}`\n",
    "   - I grafici sono ottimizzati per stampa (300 DPI, alta qualit√†)\n",
    "\n",
    "4. **üìñ Narrativa tesi**: Usa i risultati per supportare:\n",
    "   - Efficacia delle informazioni geometriche\n",
    "   - Differenze tra modelli nell'utilizzo del contesto spaziale\n",
    "   - Trade-off accuratezza vs complessit√†\n",
    "\n",
    "### üîç Troubleshooting Struttura Ibrida\n",
    "\n",
    "- **Directory miste**: Configurazione automatica gestisce sia `results/{model}/` che directory separate\n",
    "- **DeepSeek**: Usa `results_deepseek-coder_33b_*` (directory separate)\n",
    "- **Mixtral geom**: Usa `results_mixtr_with_geom/` (directory separata)\n",
    "- **Altri modelli**: Seguono struttura standard `results/{model}/{strategy}/`\n",
    "\n",
    "### ‚ö†Ô∏è Troubleshooting Dual-Strategy\n",
    "\n",
    "- **Nessun confronto generato**: Controlla che esista almeno 1 modello con ENTRAMBE le strategie\n",
    "- **Grafici mancanti**: Verifica che directory `img/multi_model_comparison/` sia scrivibile\n",
    "- **Errori LaTeX**: Path relativi potrebbero necessitare aggiustamento (`../../img/...`)\n",
    "- **Performance inaspettate**: Alcuni modelli potrebbero non beneficiare dalle info geometriche\n",
    "\n",
    "### üéØ Interpretazione Risultati Dual-Strategy\n",
    "\n",
    "**Miglioramenti positivi** (Œî > 0): Modello beneficia delle informazioni geometriche\n",
    "**Miglioramenti negativi** (Œî < 0): Strategia base supera quella geometrica  \n",
    "**Miglioramenti nulli** (Œî ‚âà 0): Nessun impatto significativo delle info spaziali\n",
    "\n",
    "### üìä Metriche Chiave per la Tesi\n",
    "\n",
    "1. **Tasso di successo geometrico**: % di metriche migliorate con strategia geometrica\n",
    "2. **Miglioramento medio**: Media dei Œî% per Top-1, Top-5, MRR\n",
    "3. **Modello pi√π reattivo**: Quale modello beneficia di pi√π dalle info geometriche\n",
    "4. **Consistenza miglioramenti**: Deviazione standard dei miglioramenti\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Analisi Dual-Strategy Completata!** \n",
    "\n",
    "Ora hai un sistema completo per confrontare l'impatto delle informazioni geometriche sui diversi modelli LLM. I grafici affiancati e l'analisi quantitativa dei miglioramenti forniranno una base solida per le conclusioni della tua tesi sulla mobilit√† turistica predittiva."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
