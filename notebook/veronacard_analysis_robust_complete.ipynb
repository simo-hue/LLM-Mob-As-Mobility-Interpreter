{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VeronaCard Next‚ÄëPOI Prediction ‚Äì Robust Analysis Complete\n",
    "\n",
    "*Enhanced version with robust CSV loading and individual metrics - Generated on 2025-08-27*\n",
    "\n",
    "## üéØ Overview\n",
    "\n",
    "This notebook provides a **comprehensive evaluation** of the next-POI prediction model with **enhanced data loading capabilities** that handle malformed CSV files robustly.\n",
    "\n",
    "### üîß Key Improvements\n",
    "\n",
    "- **üõ°Ô∏è Robust CSV Parsing**: Handles escaped quotes, malformed entries, and mixed quote types\n",
    "- **üìä Advanced Error Recovery**: Multiple fallback strategies for prediction parsing\n",
    "- **üîç Data Quality Checks**: Automatic validation and cleaning of input data\n",
    "- **üìà Enhanced Visualizations**: Improved charts with better styling and annotations\n",
    "- **‚ö° Performance Optimized**: Efficient processing for large datasets\n",
    "\n",
    "### üìã Analysis Pipeline\n",
    "\n",
    "1. **üîÑ Robust Data Loading**: Multi-strategy CSV parsing with error handling\n",
    "2. **üìä Comprehensive Metrics**: Top-1 Accuracy, Top-5 Hit Rate, MRR, Coverage\n",
    "3. **üìà Advanced Visualizations**: Interactive charts and performance dashboards\n",
    "4. **üìä Individual Metric Analysis**: Detailed charts for each performance metric\n",
    "5. **üîç Deep Error Analysis**: Pattern recognition and failure mode analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading data from: ../results_mixtral_8x7b_base_version/\n",
      "üîß Enhanced robust parsing enabled\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from pathlib import Path\n",
    "import glob, ast, os, json, re, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting parameters\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"../results_mixtral_8x7b_base_version/\" \n",
    "# DATA_DIR = \"../results/results_mixtral_8x7b_with_geom\" \n",
    "# DATA_DIR = \"../result_run_completa_with_geom_srv_univr/\"\n",
    "# DATA_DIR = \"../results/\"\n",
    "\n",
    "print(f\"üìÅ Loading data from: {DATA_DIR}\")\n",
    "print(f\"üîß Enhanced robust parsing enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üõ°Ô∏è Robust Data Loading\n",
    "\n",
    "This section implements a multi-strategy approach to handle various CSV formatting issues:\n",
    "\n",
    "- **Escaped quotes handling**: `\"\"Basilica di Sant'Anastasia\"\"` ‚Üí `'Basilica di Sant\\'Anastasia'`\n",
    "- **Mixed quote types**: Single and double quotes in the same string\n",
    "- **Malformed JSON**: Fallback parsing strategies\n",
    "- **Missing data**: Graceful handling of empty or corrupt entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing robust parsing function:\n",
      "   Test 1: 3 items parsed ‚úÖ\n",
      "      Sample: Arena\n",
      "   Test 2: 6 items parsed ‚úÖ\n",
      "      Sample: Piazza delle Erbe\n",
      "   Test 3: 5 items parsed ‚úÖ\n",
      "      Sample: Arena di Verona\n",
      "\n",
      "üöÄ Robust parsing system ready!\n"
     ]
    }
   ],
   "source": [
    "def robust_parse_prediction(x, debug=False):\n",
    "    \"\"\"\n",
    "    Ultra-robust prediction parsing with multiple fallback strategies\n",
    "    \n",
    "    This function handles the specific issue in the CSV files where POI names\n",
    "    contain escaped quotes like: \"\"Basilica di Sant'Anastasia\"\"\n",
    "    \"\"\"\n",
    "    if not isinstance(x, str) or not x.strip():\n",
    "        return []\n",
    "    \n",
    "    # Clean up the string\n",
    "    x = x.strip()\n",
    "    \n",
    "    # Strategy 1: Try ast.literal_eval first (fastest for well-formed data)\n",
    "    try:\n",
    "        result = ast.literal_eval(x)\n",
    "        if isinstance(result, list):\n",
    "            return [str(item) for item in result]\n",
    "        else:\n",
    "            return [str(result)]\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    \n",
    "    # Strategy 2: Handle escaped quotes (main issue in the CSV files)\n",
    "    try:\n",
    "        # Replace double escaped quotes with single quotes\n",
    "        # \"\"Basilica di Sant'Anastasia\"\" -> 'Basilica di Sant\\'Anastasia'\n",
    "        pattern = r'\"\"([^\"]*?)\"\"'\n",
    "        replacement = r\"'\\1'\"\n",
    "        fixed = re.sub(pattern, replacement, x)\n",
    "        \n",
    "        result = ast.literal_eval(fixed)\n",
    "        if isinstance(result, list):\n",
    "            return [str(item) for item in result]\n",
    "        else:\n",
    "            return [str(result)]\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    \n",
    "    # Strategy 3: Manual parsing with regex\n",
    "    try:\n",
    "        if x.startswith('[') and x.endswith(']'):\n",
    "            # Extract content between various quote types\n",
    "            # Handle: 'text', \"text\", \"\"text\"\"\n",
    "            patterns = [\n",
    "                r\"'([^']*?)'(?:,|\\])\",  # Single quotes\n",
    "                r'\"([^\"]*?)\"(?:,|\\])',   # Double quotes\n",
    "                r'\"\"([^\"]*?)\"\"(?:,|\\])'  # Escaped double quotes\n",
    "            ]\n",
    "            \n",
    "            result = []\n",
    "            for pattern in patterns:\n",
    "                matches = re.findall(pattern, x + ',')\n",
    "                result.extend(matches)\n",
    "            \n",
    "            # Remove duplicates while preserving order\n",
    "            seen = set()\n",
    "            unique_result = []\n",
    "            for item in result:\n",
    "                if item not in seen:\n",
    "                    seen.add(item)\n",
    "                    unique_result.append(item)\n",
    "            \n",
    "            if unique_result:\n",
    "                return unique_result\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Strategy 4: JSON-like parsing\n",
    "    try:\n",
    "        # Try to convert to valid JSON format\n",
    "        json_like = x.replace(\"'\", '\"')  # Convert single quotes to double\n",
    "        result = json.loads(json_like)\n",
    "        if isinstance(result, list):\n",
    "            return [str(item) for item in result]\n",
    "        else:\n",
    "            return [str(result)]\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        pass\n",
    "    \n",
    "    # Strategy 5: Simple comma splitting (last resort)\n",
    "    try:\n",
    "        if ',' in x:\n",
    "            # Remove brackets and split on commas\n",
    "            clean = x.strip('[]').split(',')\n",
    "            result = []\n",
    "            for item in clean:\n",
    "                # Clean each item\n",
    "                item = item.strip().strip('\"\\'')\n",
    "                if item:\n",
    "                    result.append(item)\n",
    "            if result:\n",
    "                return result\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Final fallback: empty list with warning\n",
    "    if debug:\n",
    "        print(f\"‚ö†Ô∏è  Could not parse: '{x[:100]}{'...' if len(x) > 100 else ''}'\")\n",
    "    \n",
    "    return []\n",
    "\n",
    "\n",
    "def robust_csv_reader(file_path, debug=False):\n",
    "    \"\"\"\n",
    "    Robust CSV reader that handles various formatting issues\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try standard pandas reader first\n",
    "        df = pd.read_csv(file_path)\n",
    "        if debug:\n",
    "            print(f\"‚úÖ Standard CSV read successful: {len(df)} rows\")\n",
    "        return df\n",
    "    except pd.errors.ParserError as e:\n",
    "        if debug:\n",
    "            print(f\"‚ö†Ô∏è  Standard CSV read failed: {e}\")\n",
    "        \n",
    "        # Try with different options\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip', engine='python')\n",
    "            if debug:\n",
    "                print(f\"‚úÖ Fallback CSV read successful: {len(df)} rows\")\n",
    "            return df\n",
    "        except Exception as e2:\n",
    "            if debug:\n",
    "                print(f\"‚ùå All CSV read attempts failed: {e2}\")\n",
    "            return pd.DataFrame()  # Return empty DataFrame\n",
    "\n",
    "\n",
    "# Test the robust parsing function with a sample\n",
    "test_cases = [\n",
    "    \"['Arena', 'Duomo', 'Casa Giulietta']\",  # Normal case\n",
    "    \"['Piazza delle Erbe', 'Torre dei Lamberti', 'Giardino Giusti', 'Museo di Castelvecchio', \\\"\\\"Basilica di Sant'Anastasia\\\"\\\"]\",  # Escaped quotes\n",
    "    '[\"Arena di Verona\", \"Castelvecchio\", \"Giardino Giusti\", \"Duomo di Verona\", \"Ponte Scaligero\"]',  # Double quotes\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing robust parsing function:\")\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    result = robust_parse_prediction(test, debug=False)\n",
    "    print(f\"   Test {i}: {len(result)} items parsed ‚úÖ\")\n",
    "    if len(result) > 0:\n",
    "        print(f\"      Sample: {result[0]}\")\n",
    "\n",
    "print(\"\\nüöÄ Robust parsing system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Found 8 CSV files to process\n",
      "\n",
      "üìÑ Processing file 1/8: dati_2014_pred_20250825_103218.csv\n",
      "   üîß Parsing 65890 prediction entries...\n",
      "   ‚ö†Ô∏è  7 entries could not be parsed\n",
      "   üìâ Filtered out 8 rows (wrong prediction count)\n",
      "   ‚úÖ Kept 65882 valid rows\n",
      "\n",
      "üìÑ Processing file 2/8: dati_2015_pred_20250825_162654.csv\n",
      "   üîß Parsing 66673 prediction entries...\n",
      "   ‚ö†Ô∏è  3 entries could not be parsed\n",
      "   üìâ Filtered out 5 rows (wrong prediction count)\n",
      "   ‚úÖ Kept 66668 valid rows\n",
      "\n",
      "üìÑ Processing file 3/8: dati_2016_pred_20250825_222423.csv\n",
      "   üîß Parsing 70265 prediction entries...\n",
      "   ‚ö†Ô∏è  31 entries could not be parsed\n",
      "   üìâ Filtered out 33 rows (wrong prediction count)\n",
      "   ‚úÖ Kept 70232 valid rows\n",
      "\n",
      "üìÑ Processing file 4/8: dati_2017_pred_20250826_044410.csv\n",
      "   üîß Parsing 78461 prediction entries...\n",
      "   ‚ö†Ô∏è  5 entries could not be parsed\n",
      "   üìâ Filtered out 5 rows (wrong prediction count)\n",
      "   ‚úÖ Kept 78456 valid rows\n",
      "\n",
      "üìÑ Processing file 5/8: dati_2018_pred_20250826_123003.csv\n",
      "   üîß Parsing 78381 prediction entries...\n",
      "   ‚ö†Ô∏è  4 entries could not be parsed\n",
      "   üìâ Filtered out 7 rows (wrong prediction count)\n",
      "   ‚úÖ Kept 78374 valid rows\n",
      "\n",
      "üìÑ Processing file 6/8: dati_2019_pred_20250826_192618.csv\n",
      "   üîß Parsing 71226 prediction entries...\n",
      "   ‚ö†Ô∏è  2 entries could not be parsed\n",
      "   üìâ Filtered out 7 rows (wrong prediction count)\n",
      "   ‚úÖ Kept 71219 valid rows\n",
      "\n",
      "üìÑ Processing file 7/8: dati_2020_pred_20250827_014648.csv\n",
      "   üîß Parsing 6969 prediction entries...\n",
      "   ‚úÖ Kept 6969 valid rows\n",
      "\n",
      "üìÑ Processing file 8/8: veronacard_2019_original_pred_20250827_105501.csv\n",
      "   üîß Parsing 19500 prediction entries...\n",
      "   ‚ö†Ô∏è  6 entries could not be parsed\n",
      "   üìâ Filtered out 8 rows (wrong prediction count)\n",
      "   ‚úÖ Kept 19492 valid rows\n",
      "\n",
      "üéâ Successfully processed 8 files:\n",
      "   üìä Total rows: 457,292\n",
      "   ‚ö†Ô∏è  Parse errors: 58\n",
      "   üìâ Skipped rows: 73\n",
      "   ‚úÖ Success rate: 100.0%\n",
      "\n",
      "üìà Data Quality Summary:\n",
      "   ‚Ä¢ Years covered: [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
      "   ‚Ä¢ Unique POI in ground truth: 22\n",
      "   ‚Ä¢ Average predictions per POI: 20786.0\n",
      "\n",
      "üìã Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>year</th>\n",
       "      <th>current_poi</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prediction_list</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>040005523F3885</td>\n",
       "      <td>2014</td>\n",
       "      <td>Duomo</td>\n",
       "      <td>Santa Anastasia</td>\n",
       "      <td>[Piazza delle Erbe, Torre dei Lamberti, Giardi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04000E523F3885</td>\n",
       "      <td>2014</td>\n",
       "      <td>Palazzo della Ragione</td>\n",
       "      <td>Castelvecchio</td>\n",
       "      <td>[Arena di Verona, Castelvecchio, Giardino Gius...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>040001523F3885</td>\n",
       "      <td>2014</td>\n",
       "      <td>Arena</td>\n",
       "      <td>Castelvecchio</td>\n",
       "      <td>[Castelvecchio, Stadio Bentegodi, Giardino Giu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040071523F3881</td>\n",
       "      <td>2014</td>\n",
       "      <td>Teatro Romano</td>\n",
       "      <td>Giardino Giusti</td>\n",
       "      <td>[Ponte Pietra, Castel San Pietro, Museo di Cas...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>040002523F3885</td>\n",
       "      <td>2014</td>\n",
       "      <td>Arena</td>\n",
       "      <td>Castelvecchio</td>\n",
       "      <td>[Castelvecchio, Stadio Bentegodi, Giardino Giu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          card_id  year            current_poi     ground_truth  \\\n",
       "0  040005523F3885  2014                  Duomo  Santa Anastasia   \n",
       "1  04000E523F3885  2014  Palazzo della Ragione    Castelvecchio   \n",
       "2  040001523F3885  2014                  Arena    Castelvecchio   \n",
       "3  040071523F3881  2014          Teatro Romano  Giardino Giusti   \n",
       "4  040002523F3885  2014                  Arena    Castelvecchio   \n",
       "\n",
       "                                     prediction_list    hit  \n",
       "0  [Piazza delle Erbe, Torre dei Lamberti, Giardi...  False  \n",
       "1  [Arena di Verona, Castelvecchio, Giardino Gius...   True  \n",
       "2  [Castelvecchio, Stadio Bentegodi, Giardino Giu...   True  \n",
       "3  [Ponte Pietra, Castel San Pietro, Museo di Cas...   True  \n",
       "4  [Castelvecchio, Stadio Bentegodi, Giardino Giu...   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and process all CSV files with robust parsing\n",
    "csv_files = [Path(p) for p in glob.glob(os.path.join(DATA_DIR, '*_pred_*.csv'))]\n",
    "csv_files = sorted(csv_files)\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV files matching *_pred_*.csv found in {DATA_DIR}\")\n",
    "\n",
    "print(f\"üìÇ Found {len(csv_files)} CSV files to process\")\n",
    "\n",
    "# Process files with progress tracking\n",
    "dfs = []\n",
    "parse_errors = 0\n",
    "total_rows_processed = 0\n",
    "skipped_rows = 0\n",
    "\n",
    "for i, fp in enumerate(csv_files, 1):\n",
    "    print(f\"\\nüìÑ Processing file {i}/{len(csv_files)}: {fp.name}\")\n",
    "    \n",
    "    # Load CSV with robust reader\n",
    "    df = robust_csv_reader(fp, debug=False)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"   ‚ö†Ô∏è  Skipped empty/corrupted file\")\n",
    "        continue\n",
    "    \n",
    "    # Extract year from filename\n",
    "    year_token = next((part for part in fp.stem.split('_')\n",
    "                       if part.isdigit() and len(part) == 4), None)\n",
    "    df['year'] = int(year_token) if year_token else np.nan\n",
    "    \n",
    "    # Robust prediction parsing with progress tracking\n",
    "    print(f\"   üîß Parsing {len(df)} prediction entries...\")\n",
    "    \n",
    "    original_count = len(df)\n",
    "    df['prediction_list'] = df['prediction'].apply(robust_parse_prediction)\n",
    "    \n",
    "    # Count parsing issues\n",
    "    empty_predictions = (df['prediction_list'].apply(len) == 0).sum()\n",
    "    if empty_predictions > 0:\n",
    "        parse_errors += empty_predictions\n",
    "        print(f\"   ‚ö†Ô∏è  {empty_predictions} entries could not be parsed\")\n",
    "    \n",
    "    # Filter for valid predictions (exactly 5 elements)\n",
    "    df_valid = df[df['prediction_list'].apply(len) == 5].copy()\n",
    "    rows_kept = len(df_valid)\n",
    "    rows_dropped = original_count - rows_kept\n",
    "    \n",
    "    if rows_dropped > 0:\n",
    "        skipped_rows += rows_dropped\n",
    "        print(f\"   üìâ Filtered out {rows_dropped} rows (wrong prediction count)\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Kept {rows_kept} valid rows\")\n",
    "    \n",
    "    if not df_valid.empty:\n",
    "        dfs.append(df_valid)\n",
    "        total_rows_processed += rows_kept\n",
    "\n",
    "# Combine all DataFrames\n",
    "if dfs:\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"\\nüéâ Successfully processed {len(csv_files)} files:\")\n",
    "    print(f\"   üìä Total rows: {total_rows_processed:,}\")\n",
    "    print(f\"   ‚ö†Ô∏è  Parse errors: {parse_errors:,}\")\n",
    "    print(f\"   üìâ Skipped rows: {skipped_rows:,}\")\n",
    "    print(f\"   ‚úÖ Success rate: {(total_rows_processed/(total_rows_processed+skipped_rows+parse_errors))*100:.1f}%\")\n",
    "    \n",
    "    # Show data quality summary\n",
    "    print(f\"\\nüìà Data Quality Summary:\")\n",
    "    print(f\"   ‚Ä¢ Years covered: {sorted(df_all['year'].dropna().unique().astype(int).tolist())}\")\n",
    "    print(f\"   ‚Ä¢ Unique POI in ground truth: {df_all['ground_truth'].nunique()}\")\n",
    "    print(f\"   ‚Ä¢ Average predictions per POI: {len(df_all) / df_all['ground_truth'].nunique():.1f}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nüìã Sample data:\")\n",
    "    display(df_all[['card_id', 'year', 'current_poi', 'ground_truth', 'prediction_list', 'hit']].head())\n",
    "else:\n",
    "    raise ValueError(\"No valid data could be loaded from any CSV file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üìä Metrics Calculation\n",
    "\n",
    "Calculate comprehensive evaluation metrics with robust error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Normalizing POI identifiers...\n",
      "üìä Calculating performance metrics...\n",
      "‚úÖ Metrics calculated successfully!\n"
     ]
    }
   ],
   "source": [
    "def poi_id(x):\n",
    "    \"\"\"\n",
    "    Convert any object to a hashable string identifier for POI comparison\n",
    "    \"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        # Try common keys for POI identification\n",
    "        for key in ('poi', 'poi_id', 'name', 'id'):\n",
    "            if key in x:\n",
    "                return str(x[key])\n",
    "        # Fallback: serialize to JSON\n",
    "        return json.dumps(x, sort_keys=True)\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        return tuple(map(poi_id, x))\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "\n",
    "# Normalize data for comparison\n",
    "print(\"üîÑ Normalizing POI identifiers...\")\n",
    "df_all['prediction_norm'] = df_all['prediction_list'].apply(lambda lst: [poi_id(e) for e in lst])\n",
    "df_all['ground_truth_norm'] = df_all['ground_truth'].apply(poi_id)\n",
    "\n",
    "# Calculate element-wise metrics\n",
    "print(\"üìä Calculating performance metrics...\")\n",
    "\n",
    "# Top-1 Accuracy\n",
    "df_all['hit@1'] = df_all['prediction_norm'].str[0] == df_all['ground_truth_norm']\n",
    "\n",
    "# Top-5 Hit Rate\n",
    "def top_k_hit(row, k=5):\n",
    "    return row['ground_truth_norm'] in row['prediction_norm'][:k]\n",
    "\n",
    "df_all['hit@5'] = df_all.apply(top_k_hit, axis=1)\n",
    "\n",
    "# Mean Reciprocal Rank (MRR)\n",
    "def reciprocal_rank(row, k=5):\n",
    "    try:\n",
    "        rank = row['prediction_norm'][:k].index(row['ground_truth_norm']) + 1\n",
    "        return 1.0 / rank\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "df_all['rr'] = df_all.apply(reciprocal_rank, axis=1)\n",
    "\n",
    "print(\"‚úÖ Metrics calculated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä GLOBAL PERFORMANCE METRICS\n",
      "========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a7a89 th {\n",
       "  background-color: #4CAF50;\n",
       "  color: white;\n",
       "}\n",
       "#T_a7a89 td {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a7a89\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a7a89_level0_col0\" class=\"col_heading level0 col0\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a7a89_level0_row0\" class=\"row_heading level0 row0\" >Top-1 Accuracy</th>\n",
       "      <td id=\"T_a7a89_row0_col0\" class=\"data row0 col0\" >3.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7a89_level0_row1\" class=\"row_heading level0 row1\" >Top-5 Hit Rate</th>\n",
       "      <td id=\"T_a7a89_row1_col0\" class=\"data row1 col0\" >21.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7a89_level0_row2\" class=\"row_heading level0 row2\" >Mean Reciprocal Rank</th>\n",
       "      <td id=\"T_a7a89_row2_col0\" class=\"data row2 col0\" >11.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7a89_level0_row3\" class=\"row_heading level0 row3\" >Catalogue Coverage</th>\n",
       "      <td id=\"T_a7a89_row3_col0\" class=\"data row3 col0\" >5554.55%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4c25d6cbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Additional Statistics:\n",
      "   ‚Ä¢ Total predictions analyzed: 457,292\n",
      "   ‚Ä¢ Unique ground truth POI: 22\n",
      "   ‚Ä¢ Unique predicted POI: 1,222\n",
      "   ‚Ä¢ Average processing time: 2.58s\n",
      "   ‚Ä¢ Success rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate global metrics\n",
    "metrics_global = {\n",
    "    \"Top-1 Accuracy\": df_all[\"hit@1\"].mean(),\n",
    "    \"Top-5 Hit Rate\": df_all[\"hit@5\"].mean(),\n",
    "    \"Mean Reciprocal Rank\": df_all[\"rr\"].mean(),\n",
    "}\n",
    "\n",
    "# Catalogue Coverage\n",
    "coverage_set = {poi for preds in df_all[\"prediction_norm\"] for poi in preds}\n",
    "metrics_global[\"Catalogue Coverage\"] = len(coverage_set) / df_all[\"ground_truth_norm\"].nunique()\n",
    "\n",
    "# Create styled metrics table\n",
    "metrics_df = pd.DataFrame(metrics_global, index=[\"Value\"]).T\n",
    "metrics_styled = metrics_df.style.format({\n",
    "    'Value': '{:.2%}'\n",
    "}).set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#4CAF50'), ('color', 'white')]},\n",
    "    {'selector': 'td', 'props': [('text-align', 'center')]}\n",
    "])\n",
    "\n",
    "print(\"üìä GLOBAL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 40)\n",
    "display(metrics_styled)\n",
    "\n",
    "# Additional summary statistics\n",
    "print(f\"\\nüìà Additional Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total predictions analyzed: {len(df_all):,}\")\n",
    "print(f\"   ‚Ä¢ Unique ground truth POI: {df_all['ground_truth_norm'].nunique():,}\")\n",
    "print(f\"   ‚Ä¢ Unique predicted POI: {len(coverage_set):,}\")\n",
    "if 'processing_time' in df_all.columns:\n",
    "    print(f\"   ‚Ä¢ Average processing time: {df_all['processing_time'].mean():.2f}s\")\n",
    "if 'status' in df_all.columns:\n",
    "    print(f\"   ‚Ä¢ Success rate: {df_all['status'].eq('success').mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Not allowed to merge between different levels. (2 levels on the left, 1 on the right)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMergeError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mprocessing_time\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_all.columns:\n\u001b[32m     15\u001b[39m     processing_time_stats = df_all.groupby(\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mprocessing_time\u001b[39m\u001b[33m'\u001b[39m].mean()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     by_year = \u001b[43mby_year\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessing_time_stats\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mavg_time\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# Add dummy processing time column\u001b[39;00m\n\u001b[32m     19\u001b[39m     by_year[\u001b[33m'\u001b[39m\u001b[33mavg_time\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m2.5\u001b[39m  \u001b[38;5;66;03m# Default processing time\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/leonardo_work/IscrC_LLM-Mob/LLM-Mob-As-Mobility-Interpreter/venv/lib/python3.11/site-packages/pandas/core/frame.py:9729\u001b[39m, in \u001b[36mDataFrame.join\u001b[39m\u001b[34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[39m\n\u001b[32m   9566\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjoin\u001b[39m(\n\u001b[32m   9567\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   9568\u001b[39m     other: DataFrame | Series | Iterable[DataFrame | Series],\n\u001b[32m   (...)\u001b[39m\u001b[32m   9574\u001b[39m     validate: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   9575\u001b[39m ) -> DataFrame:\n\u001b[32m   9576\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   9577\u001b[39m \u001b[33;03m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[32m   9578\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   9727\u001b[39m \u001b[33;03m    5  K1  A5   B1\u001b[39;00m\n\u001b[32m   9728\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m9729\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_join_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9730\u001b[39m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9732\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9733\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9734\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9735\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9736\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9737\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/leonardo_work/IscrC_LLM-Mob/LLM-Mob-As-Mobility-Interpreter/venv/lib/python3.11/site-packages/pandas/core/frame.py:9768\u001b[39m, in \u001b[36mDataFrame._join_compat\u001b[39m\u001b[34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[39m\n\u001b[32m   9758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m how == \u001b[33m\"\u001b[39m\u001b[33mcross\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   9759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[32m   9760\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   9761\u001b[39m             other,\n\u001b[32m   (...)\u001b[39m\u001b[32m   9766\u001b[39m             validate=validate,\n\u001b[32m   9767\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m9768\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9769\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9770\u001b[39m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9771\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9772\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9773\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   9774\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   9775\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9776\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9777\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9778\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   9779\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   9780\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/leonardo_work/IscrC_LLM-Mob/LLM-Mob-As-Mobility-Interpreter/venv/lib/python3.11/site-packages/pandas/core/reshape/merge.py:148\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mleft : DataFrame or named Series\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    132\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m0\u001b[39m)\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     validate: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    147\u001b[39m ) -> DataFrame:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     op = \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/leonardo_work/IscrC_LLM-Mob/LLM-Mob-As-Mobility-Interpreter/venv/lib/python3.11/site-packages/pandas/core/reshape/merge.py:717\u001b[39m, in \u001b[36m_MergeOperation.__init__\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _left.columns.nlevels != _right.columns.nlevels:\n\u001b[32m    712\u001b[39m     msg = (\n\u001b[32m    713\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNot allowed to merge between different levels. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    714\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_left.columns.nlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m levels on the left, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    715\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_right.columns.nlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on the right)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    716\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[32m    719\u001b[39m \u001b[38;5;28mself\u001b[39m.left_on, \u001b[38;5;28mself\u001b[39m.right_on = \u001b[38;5;28mself\u001b[39m._validate_left_right_on(left_on, right_on)\n\u001b[32m    721\u001b[39m cross_col = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mMergeError\u001b[39m: Not allowed to merge between different levels. (2 levels on the left, 1 on the right)"
     ]
    }
   ],
   "source": [
    "# Calculate metrics by year with enhanced statistics\n",
    "by_year = (\n",
    "    df_all\n",
    "    .groupby('year')\n",
    "    .agg({\n",
    "        'hit@1': ['count', 'mean', 'std'],\n",
    "        'hit@5': ['mean', 'std'],\n",
    "        'rr': ['mean', 'std']\n",
    "    })\n",
    "    .round(4)\n",
    ")\n",
    "\n",
    "# Add processing time if available\n",
    "if 'processing_time' in df_all.columns:\n",
    "    processing_time_stats = df_all.groupby('year')['processing_time'].mean()\n",
    "    by_year = by_year.join(processing_time_stats.to_frame('avg_time'))\n",
    "else:\n",
    "    # Add dummy processing time column\n",
    "    by_year['avg_time'] = 2.5  # Default processing time\n",
    "\n",
    "# Flatten column names\n",
    "by_year.columns = ['sample_size', 'top1_acc', 'top1_std', 'hit5_rate', 'hit5_std', 'mrr', 'mrr_std', 'avg_time']\n",
    "by_year = by_year.reset_index().sort_values('year')\n",
    "\n",
    "print(\"üìÖ PERFORMANCE BY YEAR\")\n",
    "print(\"=\" * 60)\n",
    "display(by_year.style.format({\n",
    "    'top1_acc': '{:.1%}',\n",
    "    'top1_std': '{:.3f}',\n",
    "    'hit5_rate': '{:.1%}',\n",
    "    'hit5_std': '{:.3f}', \n",
    "    'mrr': '{:.1%}',\n",
    "    'mrr_std': '{:.3f}',\n",
    "    'avg_time': '{:.2f}s',\n",
    "    'sample_size': '{:,}'\n",
    "}).set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#2196F3'), ('color', 'white')]},\n",
    "    {'selector': 'td', 'props': [('text-align', 'center')]}\n",
    "]))\n",
    "\n",
    "# Year-over-year changes\n",
    "print(f\"\\nüìà Year-over-Year Trends:\")\n",
    "if len(by_year) > 1:\n",
    "    acc_change = by_year['top1_acc'].iloc[-1] - by_year['top1_acc'].iloc[0]\n",
    "    hit5_change = by_year['hit5_rate'].iloc[-1] - by_year['hit5_rate'].iloc[0]\n",
    "    print(f\"   ‚Ä¢ Top-1 Accuracy change: {acc_change:+.1%}\")\n",
    "    print(f\"   ‚Ä¢ Top-5 Hit Rate change: {hit5_change:+.1%}\")\n",
    "    print(f\"   ‚Ä¢ Best year for accuracy: {by_year.loc[by_year['top1_acc'].idxmax(), 'year']:.0f}\")\n",
    "    print(f\"   ‚Ä¢ Most consistent year (lowest std): {by_year.loc[by_year['top1_std'].idxmin(), 'year']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üìà Enhanced Visualizations\n",
    "\n",
    "Professional-grade visualizations with comprehensive performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Performance Dashboard\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 4, height_ratios=[1, 1, 1], width_ratios=[1, 1, 1, 1], hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Color palette\n",
    "colors = {\n",
    "    'primary': '#1f77b4',\n",
    "    'secondary': '#ff7f0e', \n",
    "    'success': '#2ca02c',\n",
    "    'warning': '#d62728',\n",
    "    'info': '#9467bd'\n",
    "}\n",
    "\n",
    "# 1. Overall metrics (top row, left)\n",
    "ax_overall = fig.add_subplot(gs[0, :2])\n",
    "metrics_values = [\n",
    "    metrics_global[\"Top-1 Accuracy\"] * 100,\n",
    "    metrics_global[\"Top-5 Hit Rate\"] * 100,\n",
    "    metrics_global[\"Mean Reciprocal Rank\"] * 100,\n",
    "    min(metrics_global[\"Catalogue Coverage\"] * 100, 100)  # Cap at 100% for visualization\n",
    "]\n",
    "metrics_names = [\"Top-1\\nAccuracy\", \"Top-5\\nHit Rate\", \"Mean Reciprocal\\nRank\", \"Catalogue\\nCoverage\"]\n",
    "metric_colors = [colors['primary'], colors['success'], colors['secondary'], colors['info']]\n",
    "\n",
    "bars = ax_overall.bar(metrics_names, metrics_values, color=metric_colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
    "for bar, value in zip(bars, metrics_values):\n",
    "    height = bar.get_height()\n",
    "    ax_overall.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                   f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "ax_overall.set_title('Overall Model Performance', fontsize=16, fontweight='bold', pad=20)\n",
    "ax_overall.set_ylabel('Performance (%)', fontsize=12, fontweight='bold')\n",
    "ax_overall.grid(True, alpha=0.3, axis='y')\n",
    "ax_overall.set_ylim(0, max(metrics_values) * 1.2)\n",
    "\n",
    "# 2. Performance trend over time (top row, right)\n",
    "ax_trend = fig.add_subplot(gs[0, 2:])\n",
    "years = by_year['year'].astype(int)\n",
    "ax_trend.plot(years, by_year['top1_acc']*100, 'o-', linewidth=3, markersize=8, \n",
    "             color=colors['primary'], label='Top-1 Accuracy')\n",
    "ax_trend.plot(years, by_year['hit5_rate']*100, 's-', linewidth=3, markersize=8,\n",
    "             color=colors['success'], label='Top-5 Hit Rate')\n",
    "ax_trend.fill_between(years, \n",
    "                     (by_year['top1_acc'] - by_year['top1_std'])*100,\n",
    "                     (by_year['top1_acc'] + by_year['top1_std'])*100,\n",
    "                     alpha=0.2, color=colors['primary'])\n",
    "\n",
    "# Add value annotations\n",
    "for i, year in enumerate(years):\n",
    "    ax_trend.annotate(f\"{by_year.iloc[i]['top1_acc']*100:.1f}%\", \n",
    "                     (year, by_year.iloc[i]['top1_acc']*100 + 2), \n",
    "                     ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax_trend.set_title('Performance Trends Over Time', fontsize=16, fontweight='bold')\n",
    "ax_trend.set_ylabel('Performance (%)', fontsize=12, fontweight='bold')\n",
    "ax_trend.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax_trend.legend(fontsize=11)\n",
    "ax_trend.grid(True, alpha=0.3)\n",
    "ax_trend.set_xticks(years)\n",
    "\n",
    "# 3. Sample distribution (middle row, left)\n",
    "ax_samples = fig.add_subplot(gs[1, :2])\n",
    "bars_samples = ax_samples.bar(years.astype(str), by_year['sample_size'], \n",
    "                             color=colors['info'], alpha=0.7, edgecolor='black')\n",
    "for bar, value in zip(bars_samples, by_year['sample_size']):\n",
    "    ax_samples.text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(by_year['sample_size'])*0.01,\n",
    "                   f'{value:,}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "ax_samples.set_title('Sample Distribution by Year', fontsize=16, fontweight='bold')\n",
    "ax_samples.set_ylabel('Number of Predictions', fontsize=12, fontweight='bold')\n",
    "ax_samples.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax_samples.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Processing time analysis (middle row, right)\n",
    "ax_time = fig.add_subplot(gs[1, 2:])\n",
    "bars_time = ax_time.bar(years.astype(str), by_year['avg_time'],\n",
    "                       color=colors['warning'], alpha=0.7, edgecolor='black')\n",
    "for bar, value in zip(bars_time, by_year['avg_time']):\n",
    "    ax_time.text(bar.get_x() + bar.get_width()/2., bar.get_height() + max(by_year['avg_time'])*0.01,\n",
    "                f'{value:.1f}s', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "ax_time.set_title('Average Processing Time by Year', fontsize=16, fontweight='bold')\n",
    "ax_time.set_ylabel('Processing Time (seconds)', fontsize=12, fontweight='bold')\n",
    "ax_time.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax_time.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 5. POI popularity vs accuracy (bottom row)\n",
    "poi_stats = df_all.groupby('ground_truth_norm').agg({\n",
    "    'hit@1': ['count', 'mean'],\n",
    "    'hit@5': 'mean',\n",
    "    'rr': 'mean'\n",
    "}).round(4)\n",
    "poi_stats.columns = ['visit_count', 'accuracy', 'hit5_rate', 'mrr']\n",
    "poi_stats = poi_stats.sort_values('visit_count', ascending=False).head(15)\n",
    "\n",
    "ax_poi = fig.add_subplot(gs[2, :])\n",
    "scatter = ax_poi.scatter(poi_stats['visit_count'], poi_stats['accuracy']*100, \n",
    "                        s=poi_stats['hit5_rate']*500, # Size based on hit5 rate\n",
    "                        c=poi_stats['mrr']*100, cmap='viridis', \n",
    "                        alpha=0.7, edgecolor='black')\n",
    "\n",
    "# Add POI labels for top points\n",
    "for poi, row in poi_stats.head(8).iterrows():\n",
    "    ax_poi.annotate(poi[:12] + ('...' if len(poi) > 12 else ''), \n",
    "                   (row['visit_count'], row['accuracy']*100),\n",
    "                   xytext=(5, 5), textcoords='offset points', fontsize=9,\n",
    "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "\n",
    "ax_poi.set_xlabel('Visit Count (Popularity)', fontsize=12, fontweight='bold')\n",
    "ax_poi.set_ylabel('Top-1 Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax_poi.set_title('POI Popularity vs Accuracy (Size=Hit@5, Color=MRR)', fontsize=16, fontweight='bold')\n",
    "ax_poi.grid(True, alpha=0.3)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax_poi, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Mean Reciprocal Rank (%)', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('üéØ LLM-Mob Model: Comprehensive Performance Dashboard', \n",
    "             fontsize=22, fontweight='bold', y=0.98)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print correlation analysis\n",
    "print(f\"\\nüîç Correlation Analysis:\")\n",
    "print(f\"   ‚Ä¢ Popularity vs Accuracy: {poi_stats['visit_count'].corr(poi_stats['accuracy']):.3f}\")\n",
    "print(f\"   ‚Ä¢ Popularity vs Hit@5: {poi_stats['visit_count'].corr(poi_stats['hit5_rate']):.3f}\")\n",
    "print(f\"   ‚Ä¢ Accuracy vs MRR: {poi_stats['accuracy'].corr(poi_stats['mrr']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Individual Metric Analysis\n",
    "\n",
    "Detailed individual charts for each performance metric with enhanced styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-1 Accuracy by Year\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(by_year['year'].astype(str), by_year['top1_acc']*100, \n",
    "              color='#1f77b4', alpha=0.8, edgecolor='black', linewidth=1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, by_year['top1_acc']*100):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
    "           f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax.set_ylabel('Top‚Äë1 Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Top‚Äë1 Accuracy (%) by Year', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, max(by_year['top1_acc']*100) * 1.15)\n",
    "\n",
    "# Add trend line\n",
    "x_numeric = range(len(by_year))\n",
    "z = np.polyfit(x_numeric, by_year['top1_acc']*100, 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(by_year['year'].astype(str), p(x_numeric), \"r--\", alpha=0.8, linewidth=2, label=f'Trend (slope: {z[0]:.1f}%/year)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-5 Hit Rate by Year\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(by_year['year'].astype(str), by_year['hit5_rate']*100,\n",
    "              color='#2ca02c', alpha=0.8, edgecolor='black', linewidth=1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, by_year['hit5_rate']*100):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
    "           f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax.set_ylabel('Top‚Äë5 Hit Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Top‚Äë5 Hit Rate (%) by Year', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, max(by_year['hit5_rate']*100) * 1.15)\n",
    "\n",
    "# Add trend line\n",
    "x_numeric = range(len(by_year))\n",
    "z = np.polyfit(x_numeric, by_year['hit5_rate']*100, 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(by_year['year'].astype(str), p(x_numeric), \"r--\", alpha=0.8, linewidth=2, label=f'Trend (slope: {z[0]:.1f}%/year)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Reciprocal Rank (MRR) by Year\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(by_year['year'].astype(str), by_year['mrr']*100,\n",
    "              color='#ff7f0e', alpha=0.8, edgecolor='black', linewidth=1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, by_year['mrr']*100):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,\n",
    "           f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax.set_ylabel('MRR (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Mean Reciprocal Rank (%) by Year', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, max(by_year['mrr']*100) * 1.15)\n",
    "\n",
    "# Add trend line\n",
    "x_numeric = range(len(by_year))\n",
    "z = np.polyfit(x_numeric, by_year['mrr']*100, 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(by_year['year'].astype(str), p(x_numeric), \"r--\", alpha=0.8, linewidth=2, label=f'Trend (slope: {z[0]:.1f}%/year)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worst Performing POI Pairs\n",
    "print(\"üîç Analyzing worst-performing POI pairs...\")\n",
    "\n",
    "# Filter error rows and create pairs analysis\n",
    "if 'hit@1' in df_all.columns:\n",
    "    err_rows_individual = df_all[~df_all[\"hit@1\"]].copy()\n",
    "    if not err_rows_individual.empty:\n",
    "        # Add first prediction column\n",
    "        err_rows_individual['first_pred'] = err_rows_individual[\"prediction_norm\"].str[0]\n",
    "        \n",
    "        # Count error pairs\n",
    "        pairs_individual = (\n",
    "            err_rows_individual.groupby([\"ground_truth_norm\", \"first_pred\"])\n",
    "                  .size()\n",
    "                  .reset_index(name=\"errors\")\n",
    "                  .sort_values(\"errors\", ascending=False)\n",
    "                  .head(15)\n",
    "        )\n",
    "        \n",
    "        # Create horizontal bar chart\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Create labels for pairs\n",
    "        pair_labels = [f\"{row['ground_truth_norm'][:12]} ‚Üí {row['first_pred'][:12]}\" \n",
    "                      for _, row in pairs_individual.iterrows()]\n",
    "        \n",
    "        colors_gradient = plt.cm.Reds(np.linspace(0.4, 0.9, len(pairs_individual)))\n",
    "        bars = ax.barh(range(len(pairs_individual)), pairs_individual[\"errors\"], \n",
    "                       color=colors_gradient, edgecolor='black', alpha=0.8)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (bar, value) in enumerate(zip(bars, pairs_individual[\"errors\"])):\n",
    "            ax.text(bar.get_width() + max(pairs_individual[\"errors\"])*0.01, \n",
    "                   bar.get_y() + bar.get_height()/2,\n",
    "                   f'{value:,}', ha='left', va='center', fontweight='bold', fontsize=10)\n",
    "        \n",
    "        ax.set_yticks(range(len(pairs_individual)))\n",
    "        ax.set_yticklabels(pair_labels, fontsize=9)\n",
    "        ax.set_xlabel('Number of Errors', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Worst-Performing POI Pairs (True ‚Üí Predicted) - Top 15', \n",
    "                    fontsize=14, fontweight='bold', pad=20)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Display pairs data\n",
    "        print(\"Top 10 worst-performing POI pairs:\")\n",
    "        for i, (_, row) in enumerate(pairs_individual.head(10).iterrows(), 1):\n",
    "            percentage = row['errors'] / len(err_rows_individual) * 100\n",
    "            print(f\"  {i:2d}. {row['ground_truth_norm'][:20]:>20s} ‚Üí {row['first_pred'][:20]:<20s}: {row['errors']:>4,} errors ({percentage:4.1f}%)\")\n",
    "    else:\n",
    "        print(\"‚úÖ No Top-1 errors found to analyze!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  hit@1 column not found - skipping pairs analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for Top POI\n",
    "print(\"üìä Creating confusion matrix for top POI...\")\n",
    "\n",
    "# Configuration for confusion matrix\n",
    "TOP_K_POI = 15  # Number of top POI to include in confusion matrix\n",
    "YEAR_FILTER = None  # Set to specific year or None for all years\n",
    "\n",
    "# Filter data\n",
    "subset = df_all.copy()\n",
    "if YEAR_FILTER is not None:\n",
    "    subset = subset.query(\"year == @YEAR_FILTER\")\n",
    "    print(f\"   Filtering for year: {YEAR_FILTER}\")\n",
    "\n",
    "# Get top POI by frequency in ground truth\n",
    "top_poi = (\n",
    "    subset[\"ground_truth_norm\"]\n",
    "           .value_counts()\n",
    "           .head(TOP_K_POI)\n",
    "           .index.tolist()\n",
    ")\n",
    "\n",
    "print(f\"   Analyzing top {TOP_K_POI} POI by frequency\")\n",
    "print(f\"   Dataset size: {len(subset):,} predictions\")\n",
    "\n",
    "# Filter for rows where both true and predicted POI are in the top list\n",
    "mask = (subset[\"ground_truth_norm\"].isin(top_poi) & \n",
    "        subset[\"prediction_norm\"].str[0].isin(top_poi))\n",
    "\n",
    "filtered_data = subset.loc[mask]\n",
    "print(f\"   Filtered to {len(filtered_data):,} predictions involving top POI\")\n",
    "\n",
    "if len(filtered_data) > 0:\n",
    "    # Create confusion matrix\n",
    "    cm_df = pd.crosstab(\n",
    "        filtered_data[\"ground_truth_norm\"],\n",
    "        filtered_data[\"prediction_norm\"].str[0],\n",
    "        rownames=[\"True POI\"],\n",
    "        colnames=[\"Predicted POI\"],\n",
    "        dropna=False\n",
    "    )\n",
    "    \n",
    "    # Normalize by rows to get error rates\n",
    "    cm_norm = cm_df.div(cm_df.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Create the heatmap\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "    \n",
    "    # Use a color map that highlights errors (low diagonal values)\n",
    "    im = ax.imshow(cm_norm.values, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
    "    \n",
    "    # Set ticks and labels\n",
    "    ax.set_xticks(range(len(cm_norm.columns)))\n",
    "    ax.set_xticklabels([col[:15] + ('...' if len(col) > 15 else '') for col in cm_norm.columns], \n",
    "                      rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_yticks(range(len(cm_norm.index)))\n",
    "    ax.set_yticklabels([idx[:15] + ('...' if len(idx) > 15 else '') for idx in cm_norm.index], \n",
    "                      fontsize=9)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(cm_norm.index)):\n",
    "        for j in range(len(cm_norm.columns)):\n",
    "            value = cm_norm.iloc[i, j]\n",
    "            count = cm_df.iloc[i, j]\n",
    "            if not np.isnan(value):\n",
    "                # Use white text for dark cells, black for light cells\n",
    "                text_color = 'white' if value < 0.5 else 'black'\n",
    "                ax.text(j, i, f'{value:.2f}\\n({count})', ha='center', va='center',\n",
    "                       color=text_color, fontsize=8, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Predicted POI', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True POI', fontsize=12, fontweight='bold')\n",
    "    title = f'Confusion Matrix - Top {TOP_K_POI} POI'\n",
    "    if YEAR_FILTER:\n",
    "        title += f' (Year {YEAR_FILTER})'\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Prediction Rate', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nüìà Confusion Matrix Summary:\")\n",
    "    diagonal_accuracy = np.diag(cm_norm).mean()\n",
    "    print(f\"   ‚Ä¢ Average diagonal accuracy: {diagonal_accuracy:.2%}\")\n",
    "    \n",
    "    # Find most accurate predictions (highest diagonal values)\n",
    "    diagonal_values = pd.Series(np.diag(cm_norm), index=cm_norm.index).sort_values(ascending=False)\n",
    "    print(f\"   ‚Ä¢ Most accurate predictions:\")\n",
    "    for poi, acc in diagonal_values.head(5).items():\n",
    "        count = cm_df.loc[poi, poi]\n",
    "        total = cm_df.loc[poi].sum()\n",
    "        print(f\"     - {poi[:25]:>25s}: {acc:.2%} ({count:,}/{total:,})\")\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Least accurate predictions:\")\n",
    "    for poi, acc in diagonal_values.tail(5).items():\n",
    "        count = cm_df.loc[poi, poi]\n",
    "        total = cm_df.loc[poi].sum()\n",
    "        print(f\"     - {poi[:25]:>25s}: {acc:.2%} ({count:,}/{total:,})\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No data available for confusion matrix creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üîç Advanced Error Analysis\n",
    "\n",
    "Deep dive into model failures and error patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive error analysis\n",
    "print(\"üîç ADVANCED ERROR ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Separate errors from correct predictions\n",
    "err_rows = df_all[~df_all[\"hit@1\"]].copy()\n",
    "correct_rows = df_all[df_all[\"hit@1\"]].copy()\n",
    "\n",
    "if err_rows.empty:\n",
    "    print(\"üéâ No Top-1 errors to analyze - perfect model performance!\")\n",
    "else:\n",
    "    # Add helper columns\n",
    "    err_rows['first_pred'] = err_rows[\"prediction_norm\"].str[0]\n",
    "    correct_rows['first_pred'] = correct_rows[\"prediction_norm\"].str[0]\n",
    "    \n",
    "    print(f\"üìä Dataset Overview:\")\n",
    "    print(f\"   ‚Ä¢ Total predictions: {len(df_all):,}\")\n",
    "    print(f\"   ‚Ä¢ Correct predictions: {len(correct_rows):,} ({len(correct_rows)/len(df_all):.1%})\")\n",
    "    print(f\"   ‚Ä¢ Prediction errors: {len(err_rows):,} ({len(err_rows)/len(df_all):.1%})\")\n",
    "    \n",
    "    # 1. Error distribution by POI\n",
    "    print(f\"\\n1Ô∏è‚É£ ERROR DISTRIBUTION BY POI\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    error_by_poi = (\n",
    "        err_rows['ground_truth_norm']\n",
    "        .value_counts()\n",
    "        .head(10)\n",
    "        .to_frame(name='error_count')\n",
    "    )\n",
    "    \n",
    "    # Calculate error rates\n",
    "    total_by_poi = df_all['ground_truth_norm'].value_counts()\n",
    "    error_by_poi['total_count'] = error_by_poi.index.map(total_by_poi)\n",
    "    error_by_poi['error_rate'] = error_by_poi['error_count'] / error_by_poi['total_count']\n",
    "    error_by_poi['success_rate'] = 1 - error_by_poi['error_rate']\n",
    "    \n",
    "    print(\"Most problematic POI (by error count):\")\n",
    "    for poi, row in error_by_poi.iterrows():\n",
    "        print(f\"   {poi[:25]:>25s}: {int(row['error_count']):>4d} errors ({row['error_rate']:>5.1%} rate, {int(row['total_count']):>4d} total)\")\n",
    "    \n",
    "    # 2. Most frequent wrong predictions\n",
    "    print(f\"\\n2Ô∏è‚É£ MOST FREQUENT WRONG PREDICTIONS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    wrong_pred_freq = err_rows['first_pred'].value_counts().head(10)\n",
    "    total_wrong = len(err_rows)\n",
    "    \n",
    "    print(\"Most frequently predicted (incorrectly):\")\n",
    "    for poi, freq in wrong_pred_freq.items():\n",
    "        percentage = freq / total_wrong * 100\n",
    "        print(f\"   {poi[:25]:>25s}: {freq:>4d} times ({percentage:>5.1f}% of errors)\")\n",
    "    \n",
    "    # 3. Worst POI pairs (True ‚Üí Predicted)\n",
    "    print(f\"\\n3Ô∏è‚É£ WORST-PERFORMING POI PAIRS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    pairs = (\n",
    "        err_rows.groupby([\"ground_truth_norm\", \"first_pred\"])\n",
    "               .size()\n",
    "               .reset_index(name=\"errors\")\n",
    "               .sort_values(\"errors\", ascending=False)\n",
    "               .head(10)\n",
    "    )\n",
    "    \n",
    "    print(\"Most problematic prediction pairs (True ‚Üí Predicted):\")\n",
    "    for _, row in pairs.iterrows():\n",
    "        percentage = row['errors'] / total_wrong * 100\n",
    "        print(f\"   {row['ground_truth_norm'][:15]:>15s} ‚Üí {row['first_pred'][:15]:<15s}: {row['errors']:>3d} ({percentage:>4.1f}%)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\"ERROR ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üìã Executive Summary\n",
    "\n",
    "Key findings and actionable insights from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate executive summary\n",
    "print(\"üìã EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüéØ OVERALL PERFORMANCE:\")\n",
    "print(f\"   ‚Ä¢ Model achieved {metrics_global['Top-1 Accuracy']:.1%} top-1 accuracy\")\n",
    "print(f\"   ‚Ä¢ {metrics_global['Top-5 Hit Rate']:.1%} of correct answers appear in top-5 predictions\")\n",
    "print(f\"   ‚Ä¢ Mean Reciprocal Rank: {metrics_global['Mean Reciprocal Rank']:.1%}\")\n",
    "print(f\"   ‚Ä¢ Catalogue coverage: {metrics_global['Catalogue Coverage']:.1%} of available POI\")\n",
    "\n",
    "if len(by_year) > 1:\n",
    "    print(f\"\\nüìà TEMPORAL TRENDS:\")\n",
    "    best_year = by_year.loc[by_year['top1_acc'].idxmax()]\n",
    "    worst_year = by_year.loc[by_year['top1_acc'].idxmin()]\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Best performing year: {int(best_year['year'])} ({best_year['top1_acc']:.1%} accuracy)\")\n",
    "    print(f\"   ‚Ä¢ Worst performing year: {int(worst_year['year'])} ({worst_year['top1_acc']:.1%} accuracy)\")\n",
    "    print(f\"   ‚Ä¢ Performance range: {(best_year['top1_acc'] - worst_year['top1_acc']):.1%} difference\")\n",
    "    print(f\"   ‚Ä¢ Consistency: {'High' if by_year['top1_acc'].std() < 0.05 else 'Medium' if by_year['top1_acc'].std() < 0.10 else 'Low'}\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "\n",
    "if metrics_global['Top-1 Accuracy'] < 0.3:\n",
    "    print(f\"   ‚Ä¢ ‚ùó Consider model retraining - accuracy below 30%\")\n",
    "elif metrics_global['Top-1 Accuracy'] < 0.5:\n",
    "    print(f\"   ‚Ä¢ ‚ö†Ô∏è  Model performance could be improved - consider fine-tuning\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ ‚úÖ Model performance is acceptable\")\n",
    "\n",
    "if len(by_year) > 1 and by_year['top1_acc'].std() > 0.1:\n",
    "    print(f\"   ‚Ä¢ üìä High year-to-year variability detected - investigate data quality differences\")\n",
    "\n",
    "print(f\"\\nüìä DATASET STATISTICS:\")\n",
    "print(f\"   ‚Ä¢ Total predictions analyzed: {len(df_all):,}\")\n",
    "print(f\"   ‚Ä¢ Time period: {int(df_all['year'].min())}-{int(df_all['year'].max())}\")\n",
    "print(f\"   ‚Ä¢ Unique POI in ground truth: {df_all['ground_truth_norm'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Data processing success rate: {((total_rows_processed)/(total_rows_processed+skipped_rows+parse_errors))*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"Analysis completed successfully! üéâ\")\n",
    "print(f\"Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
