{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f278234a",
   "metadata": {},
   "source": [
    "# Analisi dei risultati delle raccomandazioni\n",
    "Questo notebook carica i file `.csv` presenti nella cartella `results/`, li unisce in un unico DataFrame e calcola alcune metriche di qualità (accuratezza globale, accuratezza per cluster, confusion matrix), visualizzando anche gli errori principali.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d30dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import ast\n",
    "import os\n",
    "def in_top_k(row, k):\n",
    "    preds = row['prediction_list']\n",
    "    # se non è lista, trattiamola come lista vuota\n",
    "    if not isinstance(preds, list):\n",
    "        preds = []\n",
    "    return row['ground_truth'] in preds[:k]\n",
    "\n",
    "# funzione per parsing della colonna prediction\n",
    "def safe_parse(string):\n",
    "    try:\n",
    "        return ast.literal_eval(string)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "# Percorso ai file CSV\n",
    "csv_files = glob.glob(os.path.join('../esults_srv_univr_(_no_SPACE-GEO_n-1_come_current_POI_)', '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError('Non sono stati trovati file CSV nella cartella results/.')\n",
    "\n",
    "# Caricamento e concatenazione\n",
    "df_list = []\n",
    "for f in csv_files:\n",
    "    try:\n",
    "        df_list.append(pd.read_csv(f))\n",
    "    except Exception as e:\n",
    "        print(f\"Errore caricando {f}: {e}\")\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Parsing della colonna prediction (lista di stringhe -> lista)\n",
    "df['prediction_list'] = df['prediction'].apply(safe_parse)\n",
    "\n",
    "# Top‑1 prediction\n",
    "df['pred_top1'] = df['prediction_list'].apply(lambda x: x[0] if isinstance(x, list) and x else None)\n",
    "\n",
    "# Funzione per k=5 e k=10\n",
    "df['hit_top5']  = df.apply(lambda r: in_top_k(r, 5),  axis=1)\n",
    "df['hit_top10'] = df.apply(lambda r: in_top_k(r, 10), axis=1)\n",
    "\n",
    "# Mostriamo le prime righe\n",
    "#df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ec2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Accuratezza globale (basata sul campo 'hit' booleano)\n",
    "acc_top1  = df['hit'].mean()\n",
    "acc_top5  = df['hit_top5'].mean()\n",
    "acc_top10 = df['hit_top10'].mean()\n",
    "print(f\"Accuratezza globale Top-1:  {acc_top1:.2%}\")\n",
    "print(f\"Accuratezza globale Top-5:  {acc_top5:.2%}\")\n",
    "print(f\"Accuratezza globale Top-10: {acc_top10:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad9b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Accuratezza per cluster\n",
    "cluster_metrics = df.groupby('cluster').agg(\n",
    "    Top1  = ('hit',       'mean'),\n",
    "    Top5  = ('hit_top5',  'mean'),\n",
    "    Top10 = ('hit_top10', 'mean')\n",
    ").sort_index()\n",
    "display(cluster_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Confusion matrix semplificata\n",
    "cm = pd.crosstab(df['ground_truth'], df['pred_top1'], rownames=['Ground Truth'], colnames=['Predizione Top‑1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705fee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assicuriamoci di avere i cluster ordinati per ID\n",
    "cluster_acc_sorted = cluster_acc.sort_index()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = cluster_acc_sorted.plot(kind='bar', ax=ax)\n",
    "\n",
    "# Titoli e etichette\n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Accuratezza')\n",
    "ax.set_title('Accuratezza per Cluster')\n",
    "\n",
    "# Aggiungiamo le percentuali sopra le barre\n",
    "for bar in bars.patches:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f\"{height:.1%}\",\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # spostamento verticale in punti\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = cluster_metrics.plot(\n",
    "    kind='bar', figsize=(10,6)\n",
    ")\n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Accuratezza')\n",
    "ax.set_title('Accuratezza per Cluster: Top-1, Top-5, Top-10')\n",
    "ax.legend(title='Metriche')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
