{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "presentation_header",
   "metadata": {},
   "source": [
    "# üìä Export CSV per Presentazione Canva\n",
    "\n",
    "Questo notebook estrae i dati chiave dall'analisi delle metriche e li esporta in formato CSV\n",
    "ottimizzato per l'importazione diretta in Canva per mantenere uno stile coerente nella presentazione.\n",
    "\n",
    "## üìã File CSV generati:\n",
    "1. **`metriche_per_anno.csv`** - Performance per anno (Top-1, Top-5, MRR)\n",
    "2. **`confronto_modelli.csv`** - Confronto tra diversi modelli \n",
    "3. **`metriche_globali.csv`** - Performance aggregate generali\n",
    "4. **`coverage_analysis.csv`** - Analisi della copertura del catalogo\n",
    "5. **`yearly_summary.csv`** - Riassunto annuale con conteggi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directory output creata: ../csv_for_canva\n",
      "üìÅ I file CSV verranno salvati in: /leonardo_work/IscrC_LLM-Mob/LLM-Mob-As-Mobility-Interpreter/notebook/../csv_for_canva\n"
     ]
    }
   ],
   "source": [
    "# Importazioni necessarie\n",
    "from pathlib import Path\n",
    "import glob, ast, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Crea directory output per i CSV\n",
    "output_dir = Path('../csv_for_canva')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Directory output creata: {output_dir}\")\n",
    "print(f\"üìÅ I file CSV verranno salvati in: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {},
   "source": [
    "## üîÑ Caricamento Dati\n",
    "Utilizziamo lo stesso codice del notebook principale per caricare e processare i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funzioni di caricamento dati definite (versione corretta)\n"
     ]
    }
   ],
   "source": [
    "# Funzioni di parsing (copiate dal notebook principale)\n",
    "def safe_parse_prediction(x, debug_mode=False):\n",
    "    \"\"\"\n",
    "    Parsing sicuro delle predizioni da stringa a lista\n",
    "    Gestisce vari formati inclusi dict e stringhe\n",
    "    \"\"\"\n",
    "    if pd.isna(x) or x == \"[]\" or x == \"\" or not isinstance(x, str):\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        parsed = ast.literal_eval(x)\n",
    "        \n",
    "        if isinstance(parsed, list):\n",
    "            # Se √® una lista, estrai le stringhe (gestisce sia str che dict)\n",
    "            result = []\n",
    "            for item in parsed:\n",
    "                if isinstance(item, str):\n",
    "                    result.append(item.strip())\n",
    "                elif isinstance(item, dict):\n",
    "                    # Se √® un dict, prova a estrarre un campo chiave\n",
    "                    if 'name' in item:\n",
    "                        result.append(str(item['name']).strip())\n",
    "                    elif 'poi' in item:\n",
    "                        result.append(str(item['poi']).strip())\n",
    "                    else:\n",
    "                        # Prendi il primo valore del dict\n",
    "                        values = list(item.values())\n",
    "                        if values:\n",
    "                            result.append(str(values[0]).strip())\n",
    "                else:\n",
    "                    # Converti altri tipi in stringa\n",
    "                    result.append(str(item).strip())\n",
    "            return result\n",
    "        else:\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        if debug_mode:\n",
    "            print(f\"Errore parsing: {x} -> {e}\")\n",
    "        return []\n",
    "\n",
    "def normalize_poi_name(poi_name):\n",
    "    \"\"\"\n",
    "    Normalizza il nome di un POI per confronti consistenti\n",
    "    \"\"\"\n",
    "    if pd.isna(poi_name) or not isinstance(poi_name, str):\n",
    "        return str(poi_name).strip()\n",
    "    \n",
    "    # Rimuovi spazi extra e normalizza\n",
    "    normalized = poi_name.strip()\n",
    "    \n",
    "    # Potrebbero esserci altre normalizzazioni specifiche\n",
    "    # Es: rimuovere caratteri speciali, convertire a lowercase, etc.\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def load_and_process_data(model_name, version=\"base_version\"):\n",
    "    \"\"\"\n",
    "    Carica e processa i dati per un modello specifico\n",
    "    \"\"\"\n",
    "    # Path dei file CSV\n",
    "    csv_pattern = f'../results/{model_name}/{version}/*_pred_*.csv'\n",
    "    csv_files = [Path(p) for p in glob.glob(csv_pattern)]\n",
    "    csv_files = sorted(csv_files)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"‚ùå Nessun file trovato per {model_name}/{version}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìÇ Trovati {len(csv_files)} file per {model_name}/{version}\")\n",
    "    \n",
    "    # Lista per contenere tutti i DataFrame\n",
    "    dfs = []\n",
    "    total_processed = 0\n",
    "    \n",
    "    for fp in csv_files:\n",
    "        print(f\"  Processando {fp.name}...\")\n",
    "        try:\n",
    "            df = pd.read_csv(fp)\n",
    "        except pd.errors.ParserError:\n",
    "            print(f\"‚ö†Ô∏è Errore parsing {fp.name}, usando error handling...\")\n",
    "            df = pd.read_csv(fp, on_bad_lines='skip', engine='python')\n",
    "        \n",
    "        print(f\"    Righe caricate: {len(df)}\")\n",
    "        \n",
    "        # Estrai anno dal nome file\n",
    "        year_token = next((part for part in fp.stem.split('_') \n",
    "                          if part.isdigit() and len(part) == 4), None)\n",
    "        if year_token:\n",
    "            df['year'] = int(year_token)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Anno non trovato in {fp.name}\")\n",
    "            continue\n",
    "        \n",
    "        # Parsing predizioni con gestione errori migliorata\n",
    "        df['prediction_list'] = df['prediction'].apply(safe_parse_prediction)\n",
    "        \n",
    "        # Debug: mostra alcuni esempi di parsing\n",
    "        valid_predictions = df[df['prediction_list'].apply(lambda x: len(x) > 0)]\n",
    "        invalid_predictions = df[df['prediction_list'].apply(lambda x: len(x) == 0)]\n",
    "        \n",
    "        print(f\"    Predizioni valide: {len(valid_predictions)}\")\n",
    "        print(f\"    Predizioni invalide: {len(invalid_predictions)}\")\n",
    "        \n",
    "        # Filtra righe valide (con predizioni non vuote)\n",
    "        df = df[df['prediction_list'].apply(lambda x: isinstance(x, list) and len(x) > 0)]\n",
    "        \n",
    "        if len(df) > 0:\n",
    "            dfs.append(df)\n",
    "            total_processed += len(df)\n",
    "            print(f\"    ‚úÖ Righe valide aggiunte: {len(df)}\")\n",
    "        else:\n",
    "            print(f\"    ‚ùå Nessuna riga valida in {fp.name}\")\n",
    "    \n",
    "    if not dfs:\n",
    "        print(f\"‚ùå Nessun dato valido trovato per {model_name}\")\n",
    "        return None\n",
    "    \n",
    "    # Concatena tutti i DataFrame\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"‚úÖ Dataset combinato: {len(df_all):,} righe\")\n",
    "    \n",
    "    # Normalizzazione POI (migliorata)\n",
    "    df_all['prediction_norm'] = df_all['prediction_list'].apply(\n",
    "        lambda x: [normalize_poi_name(poi) for poi in x] if isinstance(x, list) else []\n",
    "    )\n",
    "    df_all['ground_truth_norm'] = df_all['ground_truth'].apply(normalize_poi_name)\n",
    "    \n",
    "    return df_all\n",
    "\n",
    "print(\"‚úÖ Funzioni di caricamento dati definite (versione corretta)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "calculate_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n",
      "‚úÖ Funzioni di calcolo metriche definite\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(df):\n",
    "    \"\"\"\n",
    "    Calcola le metriche per un dataset\n",
    "    \"\"\"\n",
    "    def safe_top1_accuracy(row):\n",
    "        pred_norm = row['prediction_norm']\n",
    "        if not pred_norm or len(pred_norm) == 0:\n",
    "            return False\n",
    "        return pred_norm[0] == row['ground_truth_norm']\n",
    "    \n",
    "    def safe_top_k_hit(row, k=5):\n",
    "        pred_norm = row['prediction_norm']\n",
    "        if not pred_norm or len(pred_norm) == 0:\n",
    "            return False\n",
    "        return row['ground_truth_norm'] in pred_norm[:k]\n",
    "    \n",
    "    def safe_reciprocal_rank(row, k=5):\n",
    "        pred_norm = row['prediction_norm']\n",
    "        if not pred_norm or len(pred_norm) == 0:\n",
    "            return 0.0\n",
    "        try:\n",
    "            rank = pred_norm[:k].index(row['ground_truth_norm']) + 1\n",
    "            return 1.0 / rank\n",
    "        except ValueError:\n",
    "            return 0.0\n",
    "    \n",
    "    # Calcola metriche\n",
    "    df['hit@1'] = df.apply(safe_top1_accuracy, axis=1)\n",
    "    df['hit@5'] = df.apply(safe_top_k_hit, axis=1)\n",
    "    df['rr'] = df.apply(safe_reciprocal_rank, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Funzioni di calcolo metriche definite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "process_models",
   "metadata": {},
   "source": [
    "## ü§ñ Processamento Modelli\n",
    "Carichiamo e processiamo i dati per tutti i modelli disponibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "load_models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Processando qwen2.5_14b...\n",
      "üìÇ Trovati 12 file per qwen2.5_14b/base_version\n",
      "  Processando dati_2014_pred_20250829_013511.csv...\n",
      "    Righe caricate: 65891\n",
      "    Predizioni valide: 65891\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 65891\n",
      "  Processando dati_2015_pred_20250829_071654.csv...\n",
      "    Righe caricate: 66672\n",
      "    Predizioni valide: 66672\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 66672\n",
      "  Processando dati_2016_pred_20250829_130518.csv...\n",
      "    Righe caricate: 70875\n",
      "    Predizioni valide: 70875\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 70875\n",
      "  Processando dati_2017_pred_20250829_191315.csv...\n",
      "    Righe caricate: 81342\n",
      "    Predizioni valide: 81342\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 81342\n",
      "  Processando dati_2018_pred_20250830_021506.csv...\n",
      "    Righe caricate: 78382\n",
      "    Predizioni valide: 78382\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 78382\n",
      "  Processando dati_2019_pred_20250830_090457.csv...\n",
      "    Righe caricate: 71224\n",
      "    Predizioni valide: 71224\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 71224\n",
      "  Processando dati_2020_pred_20250830_151512.csv...\n",
      "    Righe caricate: 6968\n",
      "    Predizioni valide: 6968\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 6968\n",
      "  Processando veronacard_2019_original_pred_20250830_155334.csv...\n",
      "    Righe caricate: 70813\n",
      "    Predizioni valide: 70813\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 70813\n",
      "  Processando veronacard_2020_original_pred_20250901_045437.csv...\n",
      "    Righe caricate: 6969\n",
      "    Predizioni valide: 6969\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 6969\n",
      "  Processando veronacard_2021_original_pred_20250901_053317.csv...\n",
      "    Righe caricate: 21983\n",
      "    Predizioni valide: 21983\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 21983\n",
      "  Processando veronacard_2022_original_pred_20250901_072912.csv...\n",
      "    Righe caricate: 72904\n",
      "    Predizioni valide: 72904\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 72904\n",
      "  Processando veronacard_2023_original_parziale_pred_20250901_134553.csv...\n",
      "    Righe caricate: 10704\n",
      "    Predizioni valide: 10704\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 10704\n",
      "‚úÖ Dataset combinato: 624,727 righe\n",
      "‚úÖ qwen2.5_14b: 624,727 predizioni caricate\n",
      "   üìÖ Anni coperti: 2014 - 2023 (10 anni)\n",
      "   üéØ Top-1 Accuracy: 2.9%\n",
      "\n",
      "üîÑ Processando deepseek-coder_33b...\n",
      "üìÇ Trovati 12 file per deepseek-coder_33b/base_version\n",
      "  Processando dati_2014_pred_20250828_122255.csv...\n",
      "    Righe caricate: 65889\n",
      "    Predizioni valide: 63308\n",
      "    Predizioni invalide: 2581\n",
      "    ‚úÖ Righe valide aggiunte: 63308\n",
      "  Processando dati_2015_pred_20250829_015619.csv...\n",
      "‚ö†Ô∏è Errore parsing dati_2015_pred_20250829_015619.csv, usando error handling...\n",
      "    Righe caricate: 66674\n",
      "    Predizioni valide: 65209\n",
      "    Predizioni invalide: 1465\n",
      "    ‚úÖ Righe valide aggiunte: 65209\n",
      "  Processando dati_2016_pred_20250830_170142.csv...\n",
      "    Righe caricate: 70266\n",
      "    Predizioni valide: 70266\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 70266\n",
      "  Processando dati_2017_pred_20250830_231147.csv...\n",
      "    Righe caricate: 81342\n",
      "    Predizioni valide: 81342\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 81342\n",
      "  Processando dati_2018_pred_20250831_061726.csv...\n",
      "    Righe caricate: 78383\n",
      "    Predizioni valide: 78383\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 78383\n",
      "  Processando dati_2019_pred_20250831_130510.csv...\n",
      "    Righe caricate: 71226\n",
      "    Predizioni valide: 71226\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 71226\n",
      "  Processando dati_2020_pred_20250831_191552.csv...\n",
      "    Righe caricate: 6969\n",
      "    Predizioni valide: 6969\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 6969\n",
      "  Processando veronacard_2019_original_pred_20250831_195407.csv...\n",
      "    Righe caricate: 71226\n",
      "    Predizioni valide: 71226\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 71226\n",
      "  Processando veronacard_2020_original_pred_20250901_020304.csv...\n",
      "    Righe caricate: 6971\n",
      "    Predizioni valide: 6971\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 6971\n",
      "  Processando veronacard_2021_original_pred_20250901_024244.csv...\n",
      "    Righe caricate: 21983\n",
      "    Predizioni valide: 21983\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 21983\n",
      "  Processando veronacard_2022_original_pred_20250901_043734.csv...\n",
      "    Righe caricate: 72904\n",
      "    Predizioni valide: 72904\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 72904\n",
      "  Processando veronacard_2023_original_parziale_pred_20250901_105419.csv...\n",
      "    Righe caricate: 10706\n",
      "    Predizioni valide: 10706\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 10706\n",
      "‚úÖ Dataset combinato: 620,493 righe\n",
      "‚úÖ deepseek-coder_33b: 620,493 predizioni caricate\n",
      "   üìÖ Anni coperti: 2014 - 2023 (10 anni)\n",
      "   üéØ Top-1 Accuracy: 2.3%\n",
      "\n",
      "üîÑ Processando qwen2.5_7b...\n",
      "üìÇ Trovati 12 file per qwen2.5_7b/base_version\n",
      "  Processando dati_2014_pred_20250827_150933.csv...\n",
      "    Righe caricate: 65389\n",
      "    Predizioni valide: 49142\n",
      "    Predizioni invalide: 16247\n",
      "    ‚úÖ Righe valide aggiunte: 49142\n",
      "  Processando dati_2015_pred_20250827_183858.csv...\n",
      "    Righe caricate: 66676\n",
      "    Predizioni valide: 48462\n",
      "    Predizioni invalide: 18214\n",
      "    ‚úÖ Righe valide aggiunte: 48462\n",
      "  Processando dati_2016_pred_20250827_215458.csv...\n",
      "    Righe caricate: 70264\n",
      "    Predizioni valide: 52344\n",
      "    Predizioni invalide: 17920\n",
      "    ‚úÖ Righe valide aggiunte: 52344\n",
      "  Processando dati_2017_pred_20250828_012428.csv...\n",
      "    Righe caricate: 81338\n",
      "    Predizioni valide: 59271\n",
      "    Predizioni invalide: 22067\n",
      "    ‚úÖ Righe valide aggiunte: 59271\n",
      "  Processando dati_2018_pred_20250828_062734.csv...\n",
      "    Righe caricate: 78384\n",
      "    Predizioni valide: 58357\n",
      "    Predizioni invalide: 20027\n",
      "    ‚úÖ Righe valide aggiunte: 58357\n",
      "  Processando dati_2019_pred_20250828_102909.csv...\n",
      "    Righe caricate: 71222\n",
      "    Predizioni valide: 50782\n",
      "    Predizioni invalide: 20440\n",
      "    ‚úÖ Righe valide aggiunte: 50782\n",
      "  Processando dati_2020_pred_20250828_140213.csv...\n",
      "    Righe caricate: 6969\n",
      "    Predizioni valide: 5032\n",
      "    Predizioni invalide: 1937\n",
      "    ‚úÖ Righe valide aggiunte: 5032\n",
      "  Processando veronacard_2019_original_pred_20250828_142638.csv...\n",
      "‚ö†Ô∏è Errore parsing veronacard_2019_original_pred_20250828_142638.csv, usando error handling...\n",
      "    Righe caricate: 71218\n",
      "    Predizioni valide: 51379\n",
      "    Predizioni invalide: 19839\n",
      "    ‚úÖ Righe valide aggiunte: 51379\n",
      "  Processando veronacard_2020_original_pred_20250828_195211.csv...\n",
      "    Righe caricate: 6971\n",
      "    Predizioni valide: 4898\n",
      "    Predizioni invalide: 2073\n",
      "    ‚úÖ Righe valide aggiunte: 4898\n",
      "  Processando veronacard_2021_original_pred_20250828_201553.csv...\n",
      "    Righe caricate: 21982\n",
      "    Predizioni valide: 15933\n",
      "    Predizioni invalide: 6049\n",
      "    ‚úÖ Righe valide aggiunte: 15933\n",
      "  Processando veronacard_2022_original_pred_20250828_212613.csv...\n",
      "    Righe caricate: 72903\n",
      "    Predizioni valide: 52895\n",
      "    Predizioni invalide: 20008\n",
      "    ‚úÖ Righe valide aggiunte: 52895\n",
      "  Processando veronacard_2023_original_parziale_pred_20250829_011909.csv...\n",
      "    Righe caricate: 10706\n",
      "    Predizioni valide: 7598\n",
      "    Predizioni invalide: 3108\n",
      "    ‚úÖ Righe valide aggiunte: 7598\n",
      "‚úÖ Dataset combinato: 456,093 righe\n",
      "‚úÖ qwen2.5_7b: 456,093 predizioni caricate\n",
      "   üìÖ Anni coperti: 2014 - 2023 (10 anni)\n",
      "   üéØ Top-1 Accuracy: 0.0%\n",
      "\n",
      "üîÑ Processando llama3.1_8b...\n",
      "üìÇ Trovati 14 file per llama3.1_8b/base_version\n",
      "  Processando dati_2014_pred_20250519_085850.csv...\n",
      "    Righe caricate: 65892\n",
      "    Predizioni valide: 65254\n",
      "    Predizioni invalide: 638\n",
      "    ‚úÖ Righe valide aggiunte: 65254\n",
      "  Processando dati_2014_pred_20250521_160430.csv...\n",
      "    Righe caricate: 65892\n",
      "    Predizioni valide: 65318\n",
      "    Predizioni invalide: 574\n",
      "    ‚úÖ Righe valide aggiunte: 65318\n",
      "  Processando dati_2015_pred_20250520_085854.csv...\n",
      "    Righe caricate: 66677\n",
      "    Predizioni valide: 66029\n",
      "    Predizioni invalide: 648\n",
      "    ‚úÖ Righe valide aggiunte: 66029\n",
      "  Processando dati_2015_pred_20250522_162942.csv...\n",
      "    Righe caricate: 66677\n",
      "    Predizioni valide: 66068\n",
      "    Predizioni invalide: 609\n",
      "    ‚úÖ Righe valide aggiunte: 66068\n",
      "  Processando dati_2016_pred_20250523_170126.csv...\n",
      "    Righe caricate: 70266\n",
      "    Predizioni valide: 69570\n",
      "    Predizioni invalide: 696\n",
      "    ‚úÖ Righe valide aggiunte: 69570\n",
      "  Processando dati_2017_pred_20250524_184410.csv...\n",
      "    Righe caricate: 81342\n",
      "    Predizioni valide: 80566\n",
      "    Predizioni invalide: 776\n",
      "    ‚úÖ Righe valide aggiunte: 80566\n",
      "  Processando dati_2018_pred_20250526_004927.csv...\n",
      "    Righe caricate: 78385\n",
      "    Predizioni valide: 77672\n",
      "    Predizioni invalide: 713\n",
      "    ‚úÖ Righe valide aggiunte: 77672\n",
      "  Processando dati_2019_pred_20250605_180243.csv...\n",
      "    Righe caricate: 71225\n",
      "    Predizioni valide: 70107\n",
      "    Predizioni invalide: 1118\n",
      "    ‚úÖ Righe valide aggiunte: 70107\n",
      "  Processando dati_2020_pred_20250606_203234.csv...\n",
      "    Righe caricate: 6969\n",
      "    Predizioni valide: 6856\n",
      "    Predizioni invalide: 113\n",
      "    ‚úÖ Righe valide aggiunte: 6856\n",
      "  Processando veronacard_2019_original_pred_20250606_230215.csv...\n",
      "    Righe caricate: 71225\n",
      "    Predizioni valide: 70142\n",
      "    Predizioni invalide: 1083\n",
      "    ‚úÖ Righe valide aggiunte: 70142\n",
      "  Processando veronacard_2020_original_pred_20250608_012635.csv...\n",
      "    Righe caricate: 6971\n",
      "    Predizioni valide: 6870\n",
      "    Predizioni invalide: 101\n",
      "    ‚úÖ Righe valide aggiunte: 6870\n",
      "  Processando veronacard_2021_original_pred_20250608_035712.csv...\n",
      "    Righe caricate: 21983\n",
      "    Predizioni valide: 21663\n",
      "    Predizioni invalide: 320\n",
      "    ‚úÖ Righe valide aggiunte: 21663\n",
      "  Processando veronacard_2022_original_pred_20250608_115630.csv...\n",
      "    Righe caricate: 72904\n",
      "    Predizioni valide: 71772\n",
      "    Predizioni invalide: 1132\n",
      "    ‚úÖ Righe valide aggiunte: 71772\n",
      "  Processando veronacard_2023_original_parziale_pred_20250609_151147.csv...\n",
      "    Righe caricate: 10706\n",
      "    Predizioni valide: 10546\n",
      "    Predizioni invalide: 160\n",
      "    ‚úÖ Righe valide aggiunte: 10546\n",
      "‚úÖ Dataset combinato: 748,433 righe\n",
      "‚úÖ llama3.1_8b: 748,433 predizioni caricate\n",
      "   üìÖ Anni coperti: 2014 - 2023 (10 anni)\n",
      "   üéØ Top-1 Accuracy: 10.0%\n",
      "\n",
      "üîÑ Processando mixtral_8x7b...\n",
      "üìÇ Trovati 12 file per mixtral_8x7b/base_version\n",
      "  Processando dati_2014_pred_20250825_103218.csv...\n",
      "    Righe caricate: 65890\n",
      "    Predizioni valide: 65883\n",
      "    Predizioni invalide: 7\n",
      "    ‚úÖ Righe valide aggiunte: 65883\n",
      "  Processando dati_2015_pred_20250825_162654.csv...\n",
      "    Righe caricate: 66673\n",
      "    Predizioni valide: 66670\n",
      "    Predizioni invalide: 3\n",
      "    ‚úÖ Righe valide aggiunte: 66670\n",
      "  Processando dati_2016_pred_20250825_222423.csv...\n",
      "    Righe caricate: 70265\n",
      "    Predizioni valide: 70234\n",
      "    Predizioni invalide: 31\n",
      "    ‚úÖ Righe valide aggiunte: 70234\n",
      "  Processando dati_2017_pred_20250826_044410.csv...\n",
      "‚ö†Ô∏è Errore parsing dati_2017_pred_20250826_044410.csv, usando error handling...\n",
      "    Righe caricate: 78461\n",
      "    Predizioni valide: 78456\n",
      "    Predizioni invalide: 5\n",
      "    ‚úÖ Righe valide aggiunte: 78456\n",
      "  Processando dati_2018_pred_20250826_123003.csv...\n",
      "    Righe caricate: 78381\n",
      "    Predizioni valide: 78377\n",
      "    Predizioni invalide: 4\n",
      "    ‚úÖ Righe valide aggiunte: 78377\n",
      "  Processando dati_2019_pred_20250826_192618.csv...\n",
      "    Righe caricate: 71226\n",
      "    Predizioni valide: 71224\n",
      "    Predizioni invalide: 2\n",
      "    ‚úÖ Righe valide aggiunte: 71224\n",
      "  Processando dati_2020_pred_20250827_014648.csv...\n",
      "    Righe caricate: 6969\n",
      "    Predizioni valide: 6969\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 6969\n",
      "  Processando veronacard_2019_original_pred_20250827_105501.csv...\n",
      "    Righe caricate: 70220\n",
      "    Predizioni valide: 70201\n",
      "    Predizioni invalide: 19\n",
      "    ‚úÖ Righe valide aggiunte: 70201\n",
      "  Processando veronacard_2020_original_pred_20250827_171743.csv...\n",
      "    Righe caricate: 6971\n",
      "    Predizioni valide: 6970\n",
      "    Predizioni invalide: 1\n",
      "    ‚úÖ Righe valide aggiunte: 6970\n",
      "  Processando veronacard_2021_original_pred_20250827_180005.csv...\n",
      "    Righe caricate: 21983\n",
      "    Predizioni valide: 21980\n",
      "    Predizioni invalide: 3\n",
      "    ‚úÖ Righe valide aggiunte: 21980\n",
      "  Processando veronacard_2022_original_pred_20250827_195951.csv...\n",
      "    Righe caricate: 72904\n",
      "    Predizioni valide: 72898\n",
      "    Predizioni invalide: 6\n",
      "    ‚úÖ Righe valide aggiunte: 72898\n",
      "  Processando veronacard_2023_original_parziale_pred_20250828_022436.csv...\n",
      "    Righe caricate: 10706\n",
      "    Predizioni valide: 10706\n",
      "    Predizioni invalide: 0\n",
      "    ‚úÖ Righe valide aggiunte: 10706\n",
      "‚úÖ Dataset combinato: 620,568 righe\n",
      "‚úÖ mixtral_8x7b: 620,568 predizioni caricate\n",
      "   üìÖ Anni coperti: 2014 - 2023 (10 anni)\n",
      "   üéØ Top-1 Accuracy: 3.6%\n",
      "\n",
      "üîÑ Processando deepseek-r1_32b...\n",
      "‚ùå Nessun file trovato per deepseek-r1_32b/base_version\n",
      "‚ùå deepseek-r1_32b: Dataset vuoto o errore nel caricamento\n",
      "\n",
      "üìä RIEPILOGO CARICAMENTO:\n",
      "‚úÖ Modelli caricati con successo: 5\n",
      "‚ùå Modelli falliti: 1\n",
      "   Modelli falliti: deepseek-r1_32b\n",
      "üìà Dataset combinato: 3,070,314 predizioni totali\n",
      "ü§ñ Modelli nel dataset combinato: qwen2.5_14b, deepseek-coder_33b, qwen2.5_7b, llama3.1_8b, mixtral_8x7b\n",
      "üìä Distribuzione predizioni per modello:\n",
      "   llama3.1_8b: 748,433\n",
      "   qwen2.5_14b: 624,727\n",
      "   mixtral_8x7b: 620,568\n",
      "   deepseek-coder_33b: 620,493\n",
      "   qwen2.5_7b: 456,093\n"
     ]
    }
   ],
   "source": [
    "# Lista dei modelli da processare (in ordine di priorit√†)\n",
    "models_to_process = [\n",
    "    'qwen2.5_14b',\n",
    "    'deepseek-coder_33b', \n",
    "    'qwen2.5_7b',\n",
    "    'llama3.1_8b',\n",
    "    'mixtral_8x7b',\n",
    "    'deepseek-r1_32b'  # Aggiungo anche questo se presente\n",
    "]\n",
    "\n",
    "# Dizionario per contenere i dati di tutti i modelli\n",
    "models_data = {}\n",
    "failed_models = []\n",
    "\n",
    "# Carica dati per ogni modello\n",
    "for model in models_to_process:\n",
    "    print(f\"\\nüîÑ Processando {model}...\")\n",
    "    try:\n",
    "        df = load_and_process_data(model, \"base_version\")\n",
    "        if df is not None and len(df) > 0:\n",
    "            df = calculate_metrics(df)\n",
    "            df['model'] = model  # Aggiungi colonna modello\n",
    "            models_data[model] = df\n",
    "            print(f\"‚úÖ {model}: {len(df):,} predizioni caricate\")\n",
    "            \n",
    "            # Mostra alcune statistiche di base\n",
    "            years = sorted(df['year'].unique())\n",
    "            print(f\"   üìÖ Anni coperti: {years[0]} - {years[-1]} ({len(years)} anni)\")\n",
    "            print(f\"   üéØ Top-1 Accuracy: {df['hit@1'].mean():.1%}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {model}: Dataset vuoto o errore nel caricamento\")\n",
    "            failed_models.append(model)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {model}: Errore - {str(e)}\")\n",
    "        failed_models.append(model)\n",
    "\n",
    "print(f\"\\nüìä RIEPILOGO CARICAMENTO:\")\n",
    "print(f\"‚úÖ Modelli caricati con successo: {len(models_data)}\")\n",
    "print(f\"‚ùå Modelli falliti: {len(failed_models)}\")\n",
    "\n",
    "if failed_models:\n",
    "    print(f\"   Modelli falliti: {', '.join(failed_models)}\")\n",
    "\n",
    "# Crea un dataset combinato per alcune analisi (solo se ci sono dati)\n",
    "if models_data:\n",
    "    try:\n",
    "        combined_df = pd.concat(models_data.values(), ignore_index=True)\n",
    "        print(f\"üìà Dataset combinato: {len(combined_df):,} predizioni totali\")\n",
    "        print(f\"ü§ñ Modelli nel dataset combinato: {', '.join(models_data.keys())}\")\n",
    "        \n",
    "        # Verifica la distribuzione per modello\n",
    "        model_counts = combined_df['model'].value_counts()\n",
    "        print(\"üìä Distribuzione predizioni per modello:\")\n",
    "        for model, count in model_counts.items():\n",
    "            print(f\"   {model}: {count:,}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Errore nella creazione del dataset combinato: {e}\")\n",
    "        combined_df = None\n",
    "else:\n",
    "    combined_df = None\n",
    "    print(\"‚ùå Nessun modello caricato con successo\")\n",
    "    print(\"üîß Suggerimenti:\")\n",
    "    print(\"   - Verifica che i file CSV esistano nella directory ../results/\")\n",
    "    print(\"   - Controlla che i path dei modelli siano corretti\")\n",
    "    print(\"   - Verifica la struttura dei file CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export_section",
   "metadata": {},
   "source": [
    "## üì§ Esportazione CSV per Canva\n",
    "Generiamo tutti i file CSV ottimizzati per Canva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "export_yearly_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Usando qwen2.5_14b come modello principale per metriche annuali\n",
      "‚úÖ Esportato: ../csv_for_canva/metriche_per_anno.csv\n",
      "üìä Dati per 10 anni + riga media (modello: qwen2.5_14b)\n",
      "üìã Prime righe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Top-1_Accuracy</th>\n",
       "      <th>Top-5_Hit_Rate</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Num_Predictions</th>\n",
       "      <th>Top-1_Accuracy_Percent</th>\n",
       "      <th>Top-5_Hit_Rate_Percent</th>\n",
       "      <th>MRR_Percent</th>\n",
       "      <th>Model_Used</th>\n",
       "      <th>Model_Display</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>0.0983</td>\n",
       "      <td>65891</td>\n",
       "      <td>3.18</td>\n",
       "      <td>24.27</td>\n",
       "      <td>9.83</td>\n",
       "      <td>qwen2.5_14b</td>\n",
       "      <td>Qwen2.5 14B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.2506</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>66672</td>\n",
       "      <td>3.19</td>\n",
       "      <td>25.06</td>\n",
       "      <td>10.22</td>\n",
       "      <td>qwen2.5_14b</td>\n",
       "      <td>Qwen2.5 14B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>70875</td>\n",
       "      <td>3.09</td>\n",
       "      <td>25.70</td>\n",
       "      <td>10.24</td>\n",
       "      <td>qwen2.5_14b</td>\n",
       "      <td>Qwen2.5 14B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>81342</td>\n",
       "      <td>2.85</td>\n",
       "      <td>27.35</td>\n",
       "      <td>10.23</td>\n",
       "      <td>qwen2.5_14b</td>\n",
       "      <td>Qwen2.5 14B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>78382</td>\n",
       "      <td>2.82</td>\n",
       "      <td>27.03</td>\n",
       "      <td>10.15</td>\n",
       "      <td>qwen2.5_14b</td>\n",
       "      <td>Qwen2.5 14B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  Top-1_Accuracy  Top-5_Hit_Rate     MRR  Num_Predictions  \\\n",
       "0  2014          0.0318          0.2427  0.0983            65891   \n",
       "1  2015          0.0319          0.2506  0.1022            66672   \n",
       "2  2016          0.0309          0.2570  0.1024            70875   \n",
       "3  2017          0.0285          0.2735  0.1023            81342   \n",
       "4  2018          0.0282          0.2703  0.1015            78382   \n",
       "\n",
       "   Top-1_Accuracy_Percent  Top-5_Hit_Rate_Percent  MRR_Percent   Model_Used  \\\n",
       "0                    3.18                   24.27         9.83  qwen2.5_14b   \n",
       "1                    3.19                   25.06        10.22  qwen2.5_14b   \n",
       "2                    3.09                   25.70        10.24  qwen2.5_14b   \n",
       "3                    2.85                   27.35        10.23  qwen2.5_14b   \n",
       "4                    2.82                   27.03        10.15  qwen2.5_14b   \n",
       "\n",
       "  Model_Display  \n",
       "0   Qwen2.5 14B  \n",
       "1   Qwen2.5 14B  \n",
       "2   Qwen2.5 14B  \n",
       "3   Qwen2.5 14B  \n",
       "4   Qwen2.5 14B  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. METRICHE PER ANNO (usando il modello migliore disponibile)\n",
    "if models_data:\n",
    "    # Scegli il modello principale in ordine di priorit√†\n",
    "    primary_model = None\n",
    "    priority_order = ['qwen2.5_14b', 'deepseek-coder_33b', 'qwen2.5_7b', 'llama3.1_8b', 'mixtral_8x7b']\n",
    "    \n",
    "    for preferred_model in priority_order:\n",
    "        if preferred_model in models_data:\n",
    "            primary_model = preferred_model\n",
    "            break\n",
    "    \n",
    "    # Se nessun modello prioritario, prendi il primo disponibile\n",
    "    if primary_model is None:\n",
    "        primary_model = list(models_data.keys())[0]\n",
    "    \n",
    "    df_primary = models_data[primary_model]\n",
    "    print(f\"üéØ Usando {primary_model} come modello principale per metriche annuali\")\n",
    "    \n",
    "    try:\n",
    "        # Calcola metriche per anno\n",
    "        yearly_metrics = df_primary.groupby('year').agg({\n",
    "            'hit@1': 'mean',\n",
    "            'hit@5': 'mean', \n",
    "            'rr': 'mean',\n",
    "            'card_id': 'count'\n",
    "        }).round(4)\n",
    "        \n",
    "        # Rinomina colonne per Canva\n",
    "        yearly_metrics.columns = ['Top-1_Accuracy', 'Top-5_Hit_Rate', 'MRR', 'Num_Predictions']\n",
    "        \n",
    "        # Converti percentuali\n",
    "        yearly_metrics['Top-1_Accuracy_Percent'] = (yearly_metrics['Top-1_Accuracy'] * 100).round(2)\n",
    "        yearly_metrics['Top-5_Hit_Rate_Percent'] = (yearly_metrics['Top-5_Hit_Rate'] * 100).round(2) \n",
    "        yearly_metrics['MRR_Percent'] = (yearly_metrics['MRR'] * 100).round(2)\n",
    "        \n",
    "        # Aggiungi informazioni sul modello\n",
    "        yearly_metrics['Model_Used'] = primary_model\n",
    "        yearly_metrics['Model_Display'] = primary_model.replace('_', ' ').replace('-', ' ').title()\n",
    "        \n",
    "        # Reset index per avere year come colonna\n",
    "        yearly_metrics = yearly_metrics.reset_index()\n",
    "        \n",
    "        # Aggiungi medie per riferimento\n",
    "        overall_means = {\n",
    "            'year': 'MEDIA',\n",
    "            'Top-1_Accuracy': yearly_metrics['Top-1_Accuracy'].mean(),\n",
    "            'Top-5_Hit_Rate': yearly_metrics['Top-5_Hit_Rate'].mean(),\n",
    "            'MRR': yearly_metrics['MRR'].mean(),\n",
    "            'Num_Predictions': yearly_metrics['Num_Predictions'].sum(),\n",
    "            'Top-1_Accuracy_Percent': yearly_metrics['Top-1_Accuracy_Percent'].mean(),\n",
    "            'Top-5_Hit_Rate_Percent': yearly_metrics['Top-5_Hit_Rate_Percent'].mean(),\n",
    "            'MRR_Percent': yearly_metrics['MRR_Percent'].mean(),\n",
    "            'Model_Used': primary_model,\n",
    "            'Model_Display': yearly_metrics['Model_Display'].iloc[0]\n",
    "        }\n",
    "        \n",
    "        # Aggiungi la riga media\n",
    "        yearly_metrics = pd.concat([yearly_metrics, pd.DataFrame([overall_means])], ignore_index=True)\n",
    "        \n",
    "        # Esporta\n",
    "        yearly_csv = output_dir / 'metriche_per_anno.csv'\n",
    "        yearly_metrics.to_csv(yearly_csv, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Esportato: {yearly_csv}\")\n",
    "        print(f\"üìä Dati per {len(yearly_metrics)-1} anni + riga media (modello: {primary_model})\")\n",
    "        print(\"üìã Prime righe:\")\n",
    "        display(yearly_metrics.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore nell'esportazione metriche annuali: {e}\")\n",
    "        print(\"üîß Controllare che il dataset contenga colonne year, hit@1, hit@5, rr, card_id\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nessun modello disponibile per le metriche annuali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "export_model_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generando confronto tra modelli...\n",
      "‚úÖ Esportato: ../csv_for_canva/confronto_modelli.csv\n",
      "ü§ñ Confronto di 5 modelli\n",
      "üèÜ Top 3 modelli per Top-1 Accuracy:\n",
      "   1. Llama3.1 8B: 10.05%\n",
      "   2. Mixtral 8X7B: 3.61%\n",
      "   3. Qwen2.5 14B: 2.89%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Top-1_Accuracy_Percent</th>\n",
       "      <th>Top-5_Hit_Rate_Percent</th>\n",
       "      <th>MRR_Percent</th>\n",
       "      <th>Performance_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama3.1 8B</td>\n",
       "      <td>10.05</td>\n",
       "      <td>16.23</td>\n",
       "      <td>12.58</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mixtral 8X7B</td>\n",
       "      <td>3.61</td>\n",
       "      <td>21.35</td>\n",
       "      <td>11.18</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2.5 14B</td>\n",
       "      <td>2.89</td>\n",
       "      <td>26.18</td>\n",
       "      <td>10.09</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deepseek Coder 33B</td>\n",
       "      <td>2.32</td>\n",
       "      <td>21.93</td>\n",
       "      <td>8.36</td>\n",
       "      <td>Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2.5 7B</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Top-1_Accuracy_Percent  Top-5_Hit_Rate_Percent  \\\n",
       "3         Llama3.1 8B                   10.05                   16.23   \n",
       "4        Mixtral 8X7B                    3.61                   21.35   \n",
       "0         Qwen2.5 14B                    2.89                   26.18   \n",
       "1  Deepseek Coder 33B                    2.32                   21.93   \n",
       "2          Qwen2.5 7B                    0.00                    0.25   \n",
       "\n",
       "   MRR_Percent Performance_Level  \n",
       "3        12.58         Excellent  \n",
       "4        11.18              Good  \n",
       "0        10.09              Base  \n",
       "1         8.36              Base  \n",
       "2         0.11               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. CONFRONTO TRA MODELLI\n",
    "if len(models_data) > 1:\n",
    "    print(\"üîÑ Generando confronto tra modelli...\")\n",
    "    try:\n",
    "        model_comparison = []\n",
    "        \n",
    "        for model_name, df in models_data.items():\n",
    "            # Verifica che il DataFrame contenga le colonne necessarie\n",
    "            required_cols = ['hit@1', 'hit@5', 'rr', 'year']\n",
    "            missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "            \n",
    "            if missing_cols:\n",
    "                print(f\"‚ö†Ô∏è {model_name}: colonne mancanti {missing_cols}, skip\")\n",
    "                continue\n",
    "            \n",
    "            # Calcola metriche globali per ogni modello\n",
    "            metrics = {\n",
    "                'Model': model_name.replace('_', ' ').replace('-', ' ').title(),\n",
    "                'Model_Code': model_name,\n",
    "                'Top-1_Accuracy': df['hit@1'].mean() if len(df) > 0 else 0,\n",
    "                'Top-5_Hit_Rate': df['hit@5'].mean() if len(df) > 0 else 0,\n",
    "                'MRR': df['rr'].mean() if len(df) > 0 else 0,\n",
    "                'Total_Predictions': len(df),\n",
    "                'Years_Covered': len(df['year'].unique()) if 'year' in df.columns else 0,\n",
    "                'Year_Range': f\"{df['year'].min()}-{df['year'].max()}\" if 'year' in df.columns and len(df) > 0 else \"N/A\"\n",
    "            }\n",
    "            \n",
    "            # Converti in percentuali\n",
    "            metrics['Top-1_Accuracy_Percent'] = round(metrics['Top-1_Accuracy'] * 100, 2)\n",
    "            metrics['Top-5_Hit_Rate_Percent'] = round(metrics['Top-5_Hit_Rate'] * 100, 2)\n",
    "            metrics['MRR_Percent'] = round(metrics['MRR'] * 100, 2)\n",
    "            \n",
    "            # Aggiungi metriche di qualit√†\n",
    "            metrics['Error_Rate_Percent'] = round(100 - metrics['Top-1_Accuracy_Percent'], 2)\n",
    "            metrics['Predictions_Per_Year'] = round(metrics['Total_Predictions'] / max(1, metrics['Years_Covered']), 0)\n",
    "            \n",
    "            model_comparison.append(metrics)\n",
    "        \n",
    "        if model_comparison:\n",
    "            # Crea DataFrame e ordina per Top-1 Accuracy\n",
    "            model_comparison_df = pd.DataFrame(model_comparison)\n",
    "            model_comparison_df = model_comparison_df.sort_values('Top-1_Accuracy_Percent', ascending=False)\n",
    "            \n",
    "            # Aggiungi ranking\n",
    "            model_comparison_df['Rank_Top1'] = range(1, len(model_comparison_df) + 1)\n",
    "            model_comparison_df['Rank_Top5'] = model_comparison_df['Top-5_Hit_Rate_Percent'].rank(ascending=False, method='min').astype(int)\n",
    "            model_comparison_df['Rank_MRR'] = model_comparison_df['MRR_Percent'].rank(ascending=False, method='min').astype(int)\n",
    "            \n",
    "            # Aggiungi classificazioni qualitative\n",
    "            model_comparison_df['Performance_Level'] = pd.cut(\n",
    "                model_comparison_df['Top-1_Accuracy_Percent'],\n",
    "                bins=[0, 3, 5, 7, 100],\n",
    "                labels=['Base', 'Good', 'Very Good', 'Excellent']\n",
    "            )\n",
    "            \n",
    "            # Esporta\n",
    "            comparison_csv = output_dir / 'confronto_modelli.csv'\n",
    "            model_comparison_df.to_csv(comparison_csv, index=False)\n",
    "            \n",
    "            print(f\"‚úÖ Esportato: {comparison_csv}\")\n",
    "            print(f\"ü§ñ Confronto di {len(model_comparison_df)} modelli\")\n",
    "            print(\"üèÜ Top 3 modelli per Top-1 Accuracy:\")\n",
    "            top_models = model_comparison_df.head(3)[['Model', 'Top-1_Accuracy_Percent', 'Rank_Top1']]\n",
    "            for _, row in top_models.iterrows():\n",
    "                print(f\"   {row['Rank_Top1']}. {row['Model']}: {row['Top-1_Accuracy_Percent']}%\")\n",
    "            \n",
    "            display(model_comparison_df[['Model', 'Top-1_Accuracy_Percent', 'Top-5_Hit_Rate_Percent', 'MRR_Percent', 'Performance_Level']].head())\n",
    "        else:\n",
    "            print(\"‚ùå Nessun modello valido per il confronto\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore nella generazione confronto modelli: {e}\")\n",
    "        print(\"üîß Verificare che i modelli abbiano le colonne hit@1, hit@5, rr\")\n",
    "\n",
    "elif len(models_data) == 1:\n",
    "    print(\"‚ö†Ô∏è Un solo modello disponibile, creando file di confronto con singolo modello\")\n",
    "    try:\n",
    "        single_model = list(models_data.keys())[0]\n",
    "        df = models_data[single_model]\n",
    "        \n",
    "        single_model_data = [{\n",
    "            'Model': single_model.replace('_', ' ').replace('-', ' ').title(),\n",
    "            'Model_Code': single_model,\n",
    "            'Top-1_Accuracy_Percent': round(df['hit@1'].mean() * 100, 2),\n",
    "            'Top-5_Hit_Rate_Percent': round(df['hit@5'].mean() * 100, 2),\n",
    "            'MRR_Percent': round(df['rr'].mean() * 100, 2),\n",
    "            'Total_Predictions': len(df),\n",
    "            'Years_Covered': len(df['year'].unique()),\n",
    "            'Rank_Top1': 1,\n",
    "            'Performance_Level': 'Single Model',\n",
    "            'Note': 'Only model available'\n",
    "        }]\n",
    "        \n",
    "        single_model_df = pd.DataFrame(single_model_data)\n",
    "        comparison_csv = output_dir / 'confronto_modelli.csv'\n",
    "        single_model_df.to_csv(comparison_csv, index=False)\n",
    "        print(f\"‚úÖ Esportato confronto singolo modello: {comparison_csv}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore nell'esportazione singolo modello: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Nessun modello disponibile per il confronto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "export_global_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Esportato: ../csv_for_canva/metriche_globali.csv\n",
      "üåç Scope: Tutti i Modelli\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "      <th>Percentage</th>\n",
       "      <th>Scope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-1 Accuracy</td>\n",
       "      <td>4.236147e-02</td>\n",
       "      <td>4.24</td>\n",
       "      <td>Tutti i Modelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top-5 Hit Rate</td>\n",
       "      <td>1.806913e-01</td>\n",
       "      <td>18.07</td>\n",
       "      <td>Tutti i Modelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean Reciprocal Rank</td>\n",
       "      <td>9.084302e-02</td>\n",
       "      <td>9.08</td>\n",
       "      <td>Tutti i Modelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total Predictions</td>\n",
       "      <td>3.070314e+06</td>\n",
       "      <td>3070314.00</td>\n",
       "      <td>Tutti i Modelli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric         Value  Percentage            Scope\n",
       "0        Top-1 Accuracy  4.236147e-02        4.24  Tutti i Modelli\n",
       "1        Top-5 Hit Rate  1.806913e-01       18.07  Tutti i Modelli\n",
       "2  Mean Reciprocal Rank  9.084302e-02        9.08  Tutti i Modelli\n",
       "3     Total Predictions  3.070314e+06  3070314.00  Tutti i Modelli"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. METRICHE GLOBALI (aggregate su tutti i modelli o modello principale)\n",
    "if combined_df is not None:\n",
    "    # Usa il dataset combinato se disponibile\n",
    "    df_for_global = combined_df\n",
    "    scope = \"Tutti i Modelli\"\n",
    "else:\n",
    "    # Usa il modello principale\n",
    "    df_for_global = df_primary\n",
    "    scope = f\"Modello {primary_model}\"\n",
    "\n",
    "# Calcola metriche globali\n",
    "global_metrics = {\n",
    "    'Metric': ['Top-1 Accuracy', 'Top-5 Hit Rate', 'Mean Reciprocal Rank', 'Total Predictions'],\n",
    "    'Value': [\n",
    "        df_for_global['hit@1'].mean(),\n",
    "        df_for_global['hit@5'].mean(), \n",
    "        df_for_global['rr'].mean(),\n",
    "        len(df_for_global)\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        round(df_for_global['hit@1'].mean() * 100, 2),\n",
    "        round(df_for_global['hit@5'].mean() * 100, 2),\n",
    "        round(df_for_global['rr'].mean() * 100, 2),\n",
    "        len(df_for_global)  # Mantieni conteggio come numero\n",
    "    ],\n",
    "    'Scope': [scope] * 4\n",
    "}\n",
    "\n",
    "global_metrics_df = pd.DataFrame(global_metrics)\n",
    "\n",
    "# Esporta\n",
    "global_csv = output_dir / 'metriche_globali.csv'\n",
    "global_metrics_df.to_csv(global_csv, index=False)\n",
    "\n",
    "print(f\"‚úÖ Esportato: {global_csv}\")\n",
    "print(f\"üåç Scope: {scope}\")\n",
    "display(global_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "export_coverage_analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Esportato: ../csv_for_canva/coverage_analysis.csv\n",
      "üìã Analisi coverage per 5 modelli\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Model_Code</th>\n",
       "      <th>POI_Predicted_Unique</th>\n",
       "      <th>POI_GroundTruth_Unique</th>\n",
       "      <th>POI_Overlap</th>\n",
       "      <th>Catalogue_Coverage</th>\n",
       "      <th>Coverage_Recall</th>\n",
       "      <th>Coverage_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen2.5 14B</td>\n",
       "      <td>qwen2.5_14b</td>\n",
       "      <td>1433</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>6513.64</td>\n",
       "      <td>72.73</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deepseek Coder 33B</td>\n",
       "      <td>deepseek-coder_33b</td>\n",
       "      <td>2187</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>9940.91</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen2.5 7B</td>\n",
       "      <td>qwen2.5_7b</td>\n",
       "      <td>107559</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>488904.55</td>\n",
       "      <td>95.45</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama3.1 8B</td>\n",
       "      <td>llama3.1_8b</td>\n",
       "      <td>28780</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>130818.18</td>\n",
       "      <td>86.36</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mixtral 8X7B</td>\n",
       "      <td>mixtral_8x7b</td>\n",
       "      <td>1329</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>6040.91</td>\n",
       "      <td>81.82</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model          Model_Code  POI_Predicted_Unique  \\\n",
       "0         Qwen2.5 14B         qwen2.5_14b                  1433   \n",
       "1  Deepseek Coder 33B  deepseek-coder_33b                  2187   \n",
       "2          Qwen2.5 7B          qwen2.5_7b                107559   \n",
       "3         Llama3.1 8B         llama3.1_8b                 28780   \n",
       "4        Mixtral 8X7B        mixtral_8x7b                  1329   \n",
       "\n",
       "   POI_GroundTruth_Unique  POI_Overlap  Catalogue_Coverage  Coverage_Recall  \\\n",
       "0                      22           16             6513.64            72.73   \n",
       "1                      22           22             9940.91           100.00   \n",
       "2                      22           21           488904.55            95.45   \n",
       "3                      22           19           130818.18            86.36   \n",
       "4                      22           18             6040.91            81.82   \n",
       "\n",
       "   Coverage_Precision  \n",
       "0                1.12  \n",
       "1                1.01  \n",
       "2                0.02  \n",
       "3                0.07  \n",
       "4                1.35  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. ANALISI COVERAGE\n",
    "if models_data:\n",
    "    coverage_analysis = []\n",
    "    \n",
    "    for model_name, df in models_data.items():\n",
    "        # Calcola POI unici\n",
    "        all_predicted_pois = set()\n",
    "        for pred_list in df['prediction_norm']:\n",
    "            if pred_list:\n",
    "                all_predicted_pois.update(pred_list)\n",
    "        \n",
    "        ground_truth_pois = set(df['ground_truth_norm'].unique())\n",
    "        \n",
    "        # Calcola metriche di coverage\n",
    "        overlap = all_predicted_pois.intersection(ground_truth_pois)\n",
    "        coverage = len(all_predicted_pois) / len(ground_truth_pois) if len(ground_truth_pois) > 0 else 0\n",
    "        recall_coverage = len(overlap) / len(ground_truth_pois) if len(ground_truth_pois) > 0 else 0\n",
    "        precision_coverage = len(overlap) / len(all_predicted_pois) if len(all_predicted_pois) > 0 else 0\n",
    "        \n",
    "        coverage_data = {\n",
    "            'Model': model_name.replace('_', ' ').replace('-', ' ').title(),\n",
    "            'Model_Code': model_name,\n",
    "            'POI_Predicted_Unique': len(all_predicted_pois),\n",
    "            'POI_GroundTruth_Unique': len(ground_truth_pois),\n",
    "            'POI_Overlap': len(overlap),\n",
    "            'Catalogue_Coverage': round(coverage * 100, 2),\n",
    "            'Coverage_Recall': round(recall_coverage * 100, 2),\n",
    "            'Coverage_Precision': round(precision_coverage * 100, 2)\n",
    "        }\n",
    "        \n",
    "        coverage_analysis.append(coverage_data)\n",
    "    \n",
    "    coverage_df = pd.DataFrame(coverage_analysis)\n",
    "    \n",
    "    # Esporta\n",
    "    coverage_csv = output_dir / 'coverage_analysis.csv'\n",
    "    coverage_df.to_csv(coverage_csv, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Esportato: {coverage_csv}\")\n",
    "    print(f\"üìã Analisi coverage per {len(coverage_df)} modelli\")\n",
    "    display(coverage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "export_yearly_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Esportato: ../csv_for_canva/yearly_summary.csv\n",
      "üìÖ Riassunto per 10 anni\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Total_Predictions</th>\n",
       "      <th>Top1_Mean_Percent</th>\n",
       "      <th>Top5_Mean_Percent</th>\n",
       "      <th>MRR_Mean_Percent</th>\n",
       "      <th>Error_Rate_Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>374796</td>\n",
       "      <td>4.65</td>\n",
       "      <td>14.09</td>\n",
       "      <td>8.22</td>\n",
       "      <td>95.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>379110</td>\n",
       "      <td>5.01</td>\n",
       "      <td>15.47</td>\n",
       "      <td>8.93</td>\n",
       "      <td>94.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>333289</td>\n",
       "      <td>4.13</td>\n",
       "      <td>19.09</td>\n",
       "      <td>9.46</td>\n",
       "      <td>95.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>380977</td>\n",
       "      <td>3.93</td>\n",
       "      <td>19.47</td>\n",
       "      <td>9.17</td>\n",
       "      <td>96.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>371171</td>\n",
       "      <td>3.90</td>\n",
       "      <td>19.23</td>\n",
       "      <td>9.15</td>\n",
       "      <td>96.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>668324</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20.03</td>\n",
       "      <td>9.77</td>\n",
       "      <td>95.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020</td>\n",
       "      <td>65472</td>\n",
       "      <td>5.12</td>\n",
       "      <td>21.81</td>\n",
       "      <td>10.96</td>\n",
       "      <td>94.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021</td>\n",
       "      <td>103542</td>\n",
       "      <td>3.37</td>\n",
       "      <td>16.21</td>\n",
       "      <td>7.76</td>\n",
       "      <td>96.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>343373</td>\n",
       "      <td>3.64</td>\n",
       "      <td>17.47</td>\n",
       "      <td>8.43</td>\n",
       "      <td>96.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023</td>\n",
       "      <td>50260</td>\n",
       "      <td>3.86</td>\n",
       "      <td>18.34</td>\n",
       "      <td>8.74</td>\n",
       "      <td>96.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  Total_Predictions  Top1_Mean_Percent  Top5_Mean_Percent  \\\n",
       "0  2014             374796               4.65              14.09   \n",
       "1  2015             379110               5.01              15.47   \n",
       "2  2016             333289               4.13              19.09   \n",
       "3  2017             380977               3.93              19.47   \n",
       "4  2018             371171               3.90              19.23   \n",
       "5  2019             668324               4.37              20.03   \n",
       "6  2020              65472               5.12              21.81   \n",
       "7  2021             103542               3.37              16.21   \n",
       "8  2022             343373               3.64              17.47   \n",
       "9  2023              50260               3.86              18.34   \n",
       "\n",
       "   MRR_Mean_Percent  Error_Rate_Percent  \n",
       "0              8.22               95.35  \n",
       "1              8.93               94.99  \n",
       "2              9.46               95.87  \n",
       "3              9.17               96.07  \n",
       "4              9.15               96.10  \n",
       "5              9.77               95.63  \n",
       "6             10.96               94.88  \n",
       "7              7.76               96.63  \n",
       "8              8.43               96.36  \n",
       "9              8.74               96.14  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. RIASSUNTO ANNUALE DETTAGLIATO\n",
    "if models_data:\n",
    "    # Usa il dataset combinato se disponibile, altrimenti il modello principale\n",
    "    df_for_yearly = combined_df if combined_df is not None else df_primary\n",
    "    \n",
    "    # Calcola statistiche dettagliate per anno\n",
    "    yearly_summary = df_for_yearly.groupby('year').agg({\n",
    "        'hit@1': ['count', 'mean', 'std'],\n",
    "        'hit@5': ['mean', 'std'],\n",
    "        'rr': ['mean', 'std'],\n",
    "        'card_id': 'nunique'  # Numero di utenti unici\n",
    "    }).round(4)\n",
    "    \n",
    "    # Flattening delle colonne\n",
    "    yearly_summary.columns = [\n",
    "        'Total_Predictions', 'Top1_Mean', 'Top1_Std',\n",
    "        'Top5_Mean', 'Top5_Std', 'MRR_Mean', 'MRR_Std', 'Unique_Users'\n",
    "    ]\n",
    "    \n",
    "    # Converti in percentuali\n",
    "    for col in ['Top1_Mean', 'Top1_Std', 'Top5_Mean', 'Top5_Std', 'MRR_Mean', 'MRR_Std']:\n",
    "        yearly_summary[f'{col}_Percent'] = (yearly_summary[col] * 100).round(2)\n",
    "    \n",
    "    # Calcola tasso di errore\n",
    "    yearly_summary['Error_Rate_Percent'] = (100 - yearly_summary['Top1_Mean_Percent']).round(2)\n",
    "    \n",
    "    # Reset index\n",
    "    yearly_summary = yearly_summary.reset_index()\n",
    "    \n",
    "    # Aggiungi informazioni aggiuntive\n",
    "    yearly_summary['Data_Source'] = 'Combined Models' if combined_df is not None else primary_model\n",
    "    \n",
    "    # Esporta\n",
    "    summary_csv = output_dir / 'yearly_summary.csv'\n",
    "    yearly_summary.to_csv(summary_csv, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Esportato: {summary_csv}\")\n",
    "    print(f\"üìÖ Riassunto per {len(yearly_summary)} anni\")\n",
    "    \n",
    "    # Mostra colonne principali\n",
    "    display(yearly_summary[['year', 'Total_Predictions', 'Top1_Mean_Percent', \n",
    "                           'Top5_Mean_Percent', 'MRR_Mean_Percent', 'Error_Rate_Percent']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "## üìã Riepilogo File Esportati\n",
    "Verifica finale dei file CSV generati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "final_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä FILE CSV ESPORTATI PER CANVA:\n",
      "==================================================\n",
      "‚úÖ confronto_modelli.csv\n",
      "   üìè Dimensioni: 5 righe √ó 17 colonne\n",
      "   üíæ Dimensione file: 989 bytes (1.0 KB)\n",
      "   üìÇ Path: ../csv_for_canva/confronto_modelli.csv\n",
      "   üìã Colonne: Model, Model_Code, Top-1_Accuracy, Top-5_Hit_Rate, MRR, ... (+12 altre)\n",
      "\n",
      "‚úÖ coverage_analysis.csv\n",
      "   üìè Dimensioni: 5 righe √ó 8 colonne\n",
      "   üíæ Dimensione file: 418 bytes (0.4 KB)\n",
      "   üìÇ Path: ../csv_for_canva/coverage_analysis.csv\n",
      "   üìã Colonne: Model, Model_Code, POI_Predicted_Unique, POI_GroundTruth_Unique, POI_Overlap, ... (+3 altre)\n",
      "\n",
      "‚úÖ metriche_globali.csv\n",
      "   üìè Dimensioni: 4 righe √ó 4 colonne\n",
      "   üíæ Dimensione file: 259 bytes (0.3 KB)\n",
      "   üìÇ Path: ../csv_for_canva/metriche_globali.csv\n",
      "   üìã Colonne: Metric, Value, Percentage, Scope\n",
      "\n",
      "‚úÖ metriche_per_anno.csv\n",
      "   üìè Dimensioni: 11 righe √ó 10 colonne\n",
      "   üíæ Dimensione file: 998 bytes (1.0 KB)\n",
      "   üìÇ Path: ../csv_for_canva/metriche_per_anno.csv\n",
      "   üìã Colonne: year, Top-1_Accuracy, Top-5_Hit_Rate, MRR, Num_Predictions, ... (+5 altre)\n",
      "\n",
      "‚úÖ yearly_summary.csv\n",
      "   üìè Dimensioni: 10 righe √ó 17 colonne\n",
      "   üíæ Dimensione file: 1,370 bytes (1.3 KB)\n",
      "   üìÇ Path: ../csv_for_canva/yearly_summary.csv\n",
      "   üìã Colonne: year, Total_Predictions, Top1_Mean, Top1_Std, Top5_Mean, ... (+12 altre)\n",
      "\n",
      "üéØ TOTALE: 5 file CSV pronti per Canva\n",
      "üíæ Dimensione totale: 4,034 bytes (3.9 KB)\n",
      "üìÅ Directory: /leonardo_work/IscrC_LLM-Mob/LLM-Mob-As-Mobility-Interpreter/notebook/../csv_for_canva\n",
      "\n",
      "üîç VERIFICA INTEGRIT√Ä DATI:\n",
      "==============================\n",
      "‚úÖ yearly_summary.csv: Dati integri\n",
      "‚úÖ metriche_per_anno.csv: Dati integri\n",
      "‚úÖ coverage_analysis.csv: Dati integri\n",
      "\n",
      "‚ö†Ô∏è PROBLEMI RILEVATI:\n",
      "   metriche_globali.csv: 1 percentuali invalide in Percentage\n",
      "   confronto_modelli.csv: 1 valori mancanti\n",
      "\n",
      "üí° SUGGERIMENTI PER CANVA:\n",
      "==============================\n",
      "\n",
      "üìÑ yearly_summary.csv:\n",
      "   üìä Tabelle complete con statistiche\n",
      "   üìà Include deviazioni standard\n",
      "   üîç Dati dettagliati per analisi profonde\n",
      "\n",
      "üìÑ metriche_globali.csv:\n",
      "   üéØ KPI cards per dashboard\n",
      "   üìä Gauge charts con colonna Percentage\n",
      "   üìà Metriche principali per overview\n",
      "\n",
      "üìÑ metriche_per_anno.csv:\n",
      "   üìà Grafici temporali (line chart con anni sull'asse X)\n",
      "   üìä Bar chart per confronti annuali\n",
      "   üéØ Usa colonne *_Percent per percentuali gi√† formattate\n",
      "\n",
      "üìÑ coverage_analysis.csv:\n",
      "   üìä Grafici a barre per copertura\n",
      "   üéØ Scatter plot Precision vs Recall\n",
      "   üìã Tabelle dettagliate per appendice\n",
      "\n",
      "üìÑ confronto_modelli.csv:\n",
      "   üìä Horizontal bar chart per ranking modelli\n",
      "   üèÜ Usa Rank_Top1 per ordinamento\n",
      "   üìã Tabelle comparative con Performance_Level\n",
      "\n",
      "üé® FORMATO DATI OTTIMIZZATO:\n",
      "   ‚Ä¢ Percentuali gi√† convertite (es: 4.32 invece di 0.0432)\n",
      "   ‚Ä¢ Nomi modelli formattati per presentazione\n",
      "   ‚Ä¢ Encoding UTF-8 compatibile con Canva\n",
      "   ‚Ä¢ Struttura pulita senza indici complessi\n",
      "   ‚Ä¢ Colonne separate per valori assoluti e percentuali\n",
      "\n",
      "üöÄ PRONTO PER CANVA! Importa i file e crea visualizzazioni fantastiche!\n"
     ]
    }
   ],
   "source": [
    "# Verifica file esportati\n",
    "csv_files = list(output_dir.glob('*.csv'))\n",
    "\n",
    "print(\"üìä FILE CSV ESPORTATI PER CANVA:\")\n",
    "print(\"==\" * 25)\n",
    "\n",
    "if csv_files:\n",
    "    total_size = 0\n",
    "    for csv_file in sorted(csv_files):\n",
    "        try:\n",
    "            df_check = pd.read_csv(csv_file)\n",
    "            file_size = csv_file.stat().st_size\n",
    "            total_size += file_size\n",
    "            \n",
    "            print(f\"‚úÖ {csv_file.name}\")\n",
    "            print(f\"   üìè Dimensioni: {df_check.shape[0]} righe √ó {df_check.shape[1]} colonne\")\n",
    "            print(f\"   üíæ Dimensione file: {file_size:,} bytes ({file_size/1024:.1f} KB)\")\n",
    "            print(f\"   üìÇ Path: {csv_file}\")\n",
    "            \n",
    "            # Mostra le prime colonne per verifica\n",
    "            columns_preview = ', '.join(df_check.columns[:5])\n",
    "            if len(df_check.columns) > 5:\n",
    "                columns_preview += f\", ... (+{len(df_check.columns)-5} altre)\"\n",
    "            print(f\"   üìã Colonne: {columns_preview}\")\n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {csv_file.name}: Errore nella lettura - {e}\")\n",
    "            print()\n",
    "\n",
    "    print(f\"üéØ TOTALE: {len(csv_files)} file CSV pronti per Canva\")\n",
    "    print(f\"üíæ Dimensione totale: {total_size:,} bytes ({total_size/1024:.1f} KB)\")\n",
    "    print(f\"üìÅ Directory: {output_dir.absolute()}\")\n",
    "    \n",
    "    # Verifica integrit√† dei dati\n",
    "    print(\"\\nüîç VERIFICA INTEGRIT√Ä DATI:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    integrity_issues = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            issues = []\n",
    "            \n",
    "            # Controlla valori mancanti\n",
    "            missing_values = df.isnull().sum().sum()\n",
    "            if missing_values > 0:\n",
    "                issues.append(f\"{missing_values} valori mancanti\")\n",
    "            \n",
    "            # Controlla colonne percentuali\n",
    "            pct_cols = [col for col in df.columns if 'Percent' in col]\n",
    "            for col in pct_cols:\n",
    "                if col in df.columns:\n",
    "                    invalid_pcts = ((df[col] < 0) | (df[col] > 100)).sum()\n",
    "                    if invalid_pcts > 0:\n",
    "                        issues.append(f\"{invalid_pcts} percentuali invalide in {col}\")\n",
    "            \n",
    "            if issues:\n",
    "                integrity_issues.append(f\"{csv_file.name}: {', '.join(issues)}\")\n",
    "            else:\n",
    "                print(f\"‚úÖ {csv_file.name}: Dati integri\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            integrity_issues.append(f\"{csv_file.name}: Errore verifica - {e}\")\n",
    "    \n",
    "    if integrity_issues:\n",
    "        print(\"\\n‚ö†Ô∏è PROBLEMI RILEVATI:\")\n",
    "        for issue in integrity_issues:\n",
    "            print(f\"   {issue}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Tutti i file hanno superato la verifica di integrit√†\")\n",
    "\n",
    "    # Suggerimenti per Canva\n",
    "    print(\"\\nüí° SUGGERIMENTI PER CANVA:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    suggestions = {\n",
    "        'metriche_per_anno.csv': [\n",
    "            \"üìà Grafici temporali (line chart con anni sull'asse X)\",\n",
    "            \"üìä Bar chart per confronti annuali\",\n",
    "            \"üéØ Usa colonne *_Percent per percentuali gi√† formattate\"\n",
    "        ],\n",
    "        'confronto_modelli.csv': [\n",
    "            \"üìä Horizontal bar chart per ranking modelli\",\n",
    "            \"üèÜ Usa Rank_Top1 per ordinamento\",\n",
    "            \"üìã Tabelle comparative con Performance_Level\"\n",
    "        ],\n",
    "        'metriche_globali.csv': [\n",
    "            \"üéØ KPI cards per dashboard\",\n",
    "            \"üìä Gauge charts con colonna Percentage\",\n",
    "            \"üìà Metriche principali per overview\"\n",
    "        ],\n",
    "        'coverage_analysis.csv': [\n",
    "            \"üìä Grafici a barre per copertura\",\n",
    "            \"üéØ Scatter plot Precision vs Recall\",\n",
    "            \"üìã Tabelle dettagliate per appendice\"\n",
    "        ],\n",
    "        'yearly_summary.csv': [\n",
    "            \"üìä Tabelle complete con statistiche\",\n",
    "            \"üìà Include deviazioni standard\",\n",
    "            \"üîç Dati dettagliati per analisi profonde\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        file_name = csv_file.name\n",
    "        if file_name in suggestions:\n",
    "            print(f\"\\nüìÑ {file_name}:\")\n",
    "            for suggestion in suggestions[file_name]:\n",
    "                print(f\"   {suggestion}\")\n",
    "    \n",
    "    print(f\"\\nüé® FORMATO DATI OTTIMIZZATO:\")\n",
    "    print(\"   ‚Ä¢ Percentuali gi√† convertite (es: 4.32 invece di 0.0432)\")\n",
    "    print(\"   ‚Ä¢ Nomi modelli formattati per presentazione\")\n",
    "    print(\"   ‚Ä¢ Encoding UTF-8 compatibile con Canva\")\n",
    "    print(\"   ‚Ä¢ Struttura pulita senza indici complessi\")\n",
    "    print(\"   ‚Ä¢ Colonne separate per valori assoluti e percentuali\")\n",
    "    \n",
    "    print(f\"\\nüöÄ PRONTO PER CANVA! Importa i file e crea visualizzazioni fantastiche!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Nessun file CSV trovato!\")\n",
    "    print(\"\\nüîß RISOLUZIONE PROBLEMI:\")\n",
    "    print(\"   1. Verifica che almeno un modello sia stato caricato correttamente\")\n",
    "    print(\"   2. Controlla gli errori nelle sezioni di esportazione precedenti\")\n",
    "    print(\"   3. Verifica che la directory di output sia accessibile\")\n",
    "    print(\"   4. Re-esegui le celle di esportazione\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
