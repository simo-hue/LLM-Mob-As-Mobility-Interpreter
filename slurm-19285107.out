ğŸš€ LLM-MOB PRODUCTION RUN - TUTTI GLI UTENTI
=============================================
Job ID: 19285107
Nodo: lrdn1301.leonardo.local
Data: Sat Aug 23 16:41:55 CEST 2025
ğŸ’¡ MODALITÃ€: Processamento completo senza limiti utenti

ğŸ“¦ Caricamento moduli e ambiente...
Loading python/3.11.6--gcc--8.5.0
  Loading requirement: bzip2/1.0.8-gp5wcz5 libmd/1.0.4-wja3f5q
    libbsd/0.11.7-cgxjopl expat/2.5.0-bptl3xw ncurses/6.4-asx3jea
    readline/8.2-nyw6mp6 gdbm/1.23-fs6otck libiconv/1.17-d7yvx2s
    xz/5.4.1-hubmwr5 zlib-ng/2.1.4-6htiapk libxml2/2.10.3-5eeeokp
    pigz/2.7-bopr5vp zstd/1.5.5-gawytfl tar/1.34-amqus5s gettext/0.22.3-2g7elif
    libffi/3.4.4-6r7brdq libxcrypt/4.4.35-ss2rzin sqlite/3.43.2
    util-linux-uuid/2.38.1-jkdi7kv
âœ“ Python: Python 3.11.6
âœ“ Virtual env: /leonardo_work/IscrC_LLM-Mob/venv
âœ“ CUDA: Cuda compilation tools, release 12.3, V12.3.103

ğŸ” INFO GPU:
name, memory.total [MiB], memory.used [MiB], utilization.gpu [%], temperature.gpu
NVIDIA A100-SXM-64GB, 65536 MiB, 2 MiB, 0 %, 43
CUDA_VISIBLE_DEVICES: 0

âš™ï¸  Configurazione Ollama...
âœ“ Versione Ollama: 0.3.14

ğŸš€ Avvio server Ollama per produzione...
âœ“ Porta server: 39003
ğŸ§¹ Pulizia processi precedenti...
âœ“ Server PID: 793939
âœ“ Log file: ollama_production.log

â³ Attesa avvio server (max 60s)...
slurmstepd: error: *** JOB 19285107 ON lrdn1301 CANCELLED AT 2025-08-23T16:42:42 ***

ğŸ§¹ CLEANUP PRODUZIONE...
ğŸ• Tempo totale job: 47 secondi (0h 0m)
ğŸ“Š Stato GPU finale:
memory.used [MiB], memory.total [MiB], utilization.gpu [%], temperature.gpu
2 MiB, 65536 MiB, 0 %, 43
ğŸ“ Risultati generati: 7 files
ğŸ’¾ Dimensione risultati: 57M
ğŸ”„ Shutdown graceful Ollama...
âš¡ Force kill Ollama...
âœ“ Cleanup completato
