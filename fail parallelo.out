🚀 LLM-MOB PARALLEL PRODUCTION RUN - VERSIONE OTTIMIZZATA HPC
==============================================================
Job ID: 18855374
Nodo: lrdn1022.leonardo.local
Data: Wed Aug 13 13:48:57 CEST 2025
💡 MODALITÀ: Processamento parallelo completo
🔧 CPUs disponibili: 32
💾 Memoria allocata: 128GB

📦 Caricamento moduli e ambiente...
Loading python/3.11.6--gcc--8.5.0
  Loading requirement: bzip2/1.0.8-gp5wcz5 libmd/1.0.4-wja3f5q
    libbsd/0.11.7-cgxjopl expat/2.5.0-bptl3xw ncurses/6.4-asx3jea
    readline/8.2-nyw6mp6 gdbm/1.23-fs6otck libiconv/1.17-d7yvx2s
    xz/5.4.1-hubmwr5 zlib-ng/2.1.4-6htiapk libxml2/2.10.3-5eeeokp
    pigz/2.7-bopr5vp zstd/1.5.5-gawytfl tar/1.34-amqus5s gettext/0.22.3-2g7elif
    libffi/3.4.4-6r7brdq libxcrypt/4.4.35-ss2rzin sqlite/3.43.2
    util-linux-uuid/2.38.1-jkdi7kv
✔ Python: Python 3.11.6
✔ Virtual env: /leonardo/home/userexternal/smattiol/LLM-Mob-As-Mobility-Interpreter/llm
✔ CUDA: Cuda compilation tools, release 12.3, V12.3.103

🔍 INFO SISTEMA:
name, memory.total [MiB], memory.used [MiB], utilization.gpu [%], temperature.gpu
NVIDIA A100-SXM-64GB, 65536 MiB, 2 MiB, 0 %, 43
CUDA_VISIBLE_DEVICES: 0
CPU cores fisici: 32
Memoria totale: 502Gi

⚙️  Configurazione Ollama per parallelismo...
✔ Versione Ollama: 0.3.14

🔧 Configurazione parallelismo ottimale...
📊 Configurazione calcolata:
   - File workers: 4 (processi paralleli)
   - LLM threads: 8 (per processo)
   - Batch size: 50 utenti
   - Max parallelismo totale: 32 richieste LLM

🚀 Avvio server Ollama ottimizzato per parallelismo...
✔ Porta server: 39003
🧹 Pulizia processi precedenti...
✔ Server PID: 3022721
✔ Log file: ollama_parallel.log

⏳ Attesa avvio server (max 60s)...
✅ Server operativo dopo 10s

🔥 Preparazione modello per produzione parallela...
📋 Modelli disponibili:
  ✔ deepseek-coder:33b
  ✔ qwen2.5:72b
  ✔ mixtral:8x7b
  ✔ llama3.1:70b
  ✔ llama3.1:8b
✅ Modello llama3.1:8b disponibile
🔥 Warm-up modello con test request...
✅ Modello caricato in memoria

🎯 AVVIO PRODUZIONE PARALLELA - PROCESSAMENTO COMPLETO
======================================================
📁 Directory risultati: /leonardo/home/userexternal/smattiol/LLM-Mob-As-Mobility-Interpreter/results/
📁 Directory logs: /leonardo/home/userexternal/smattiol/LLM-Mob-As-Mobility-Interpreter/logs/
🚀 AVVIO SCRIPT PARALLELO...
🔧 Parametri di esecuzione:
   --parallel-files 4
   --parallel-llm 8
   --batch-size 50
   --append (riprende da dove interrotto)

2025-08-13 13:49:48,073 [MainProcess-MainThread] INFO: 🔧 Config finale: 4 file workers, 8 LLM threads, batch size 50
2025-08-13 13:49:48,074 [MainProcess-MainThread] INFO: 🔗 Ollama host: http://127.0.0.1:39003
2025-08-13 13:49:48,074 [MainProcess-MainThread] ERROR: ❌ Setup Ollama fallito: name 'wait_for_ollama' is not defined
🖥️  HPC Info: 32 cores, 502.9GB RAM
⚙️  Config: 4 file workers, 8 LLM threads

🎉 PRODUZIONE PARALLELA COMPLETATA CON SUCCESSO!
⏱️  Tempo totale Python: 3 secondi (0h 0m)
🚀 Speedup stimato: 4x rispetto a versione seriale

📋 REPORT FINALE PRODUZIONE PARALLELA
=====================================
⏱️  Tempo totale job: 51 secondi (0h 0m)
🔧 Versione Ollama: 0.3.14
📊 Modalità: Produzione parallela completa
/var/spool/slurmd/job18855374/slurm_script: line 389: 3022825 Terminated              monitor_progress
🔢 Configurazione parallelismo:
   - File workers utilizzati: 4
   - LLM threads per worker: 8
   - Batch size: 50
✅ Python success: true

📄 RISULTATI GENERATI:
   📊 Files totali: 0
   📝 Righe totali processate: ~0
   💾 Dimensione totale: 4.0K

   📋 Ultimi file generati:

🔧 STATO FINALE SISTEMA:
GPU:
memory.used [MiB], memory.total [MiB], utilization.gpu [%], temperature.gpu
8170 MiB, 65536 MiB, 0 %, 43

CPU e Memoria:
              total        used        free      shared  buff/cache   available
Mem:          502Gi       6.0Gi       482Gi       2.9Gi        14Gi       485Gi
Swap:            0B          0B          0B

 13:49:48 up 27 days, 20:13,  0 users,  load average: 1.57, 3.17, 3.70

📊 LOG OLLAMA (ultimi 30 righe):
llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'
llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'
llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'
llm_load_print_meta: max token length = 256
ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no
ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA A100-SXM-64GB, compute capability 8.0, VMM: yes
llm_load_tensors: ggml ctx size =    0.27 MiB
llm_load_tensors: offloading 32 repeating layers to GPU
llm_load_tensors: offloading non-repeating layers to GPU
llm_load_tensors: offloaded 33/33 layers to GPU
llm_load_tensors:        CPU buffer size =   281.81 MiB
llm_load_tensors:      CUDA0 buffer size =  4403.50 MiB
llama_new_context_with_model: n_ctx      = 16384
llama_new_context_with_model: n_batch    = 512
llama_new_context_with_model: n_ubatch   = 512
llama_new_context_with_model: flash_attn = 0
llama_new_context_with_model: freq_base  = 500000.0
llama_new_context_with_model: freq_scale = 1
llama_kv_cache_init:      CUDA0 KV buffer size =  2048.00 MiB
llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB
llama_new_context_with_model:  CUDA_Host  output buffer size =     4.04 MiB
llama_new_context_with_model:      CUDA0 compute buffer size =  1088.00 MiB
llama_new_context_with_model:  CUDA_Host compute buffer size =    40.01 MiB
llama_new_context_with_model: graph nodes  = 1030
llama_new_context_with_model: graph splits = 2
INFO [main] model loaded | tid="22654283812864" timestamp=1755085784
time=2025-08-13T13:49:45.033+02:00 level=INFO source=server.go:626 msg="llama runner started in 5.52 seconds"
[GIN] 2025/08/13 - 13:49:45 | 200 |  6.028892721s |       127.0.0.1 | POST     "/api/chat"

📊 LOG PYTHON (ultimi errori/warning):
2025-08-13 12:02:01,522 [MainProcess-MainThread] ERROR: ❌ Setup Ollama fallito: name 'wait_for_ollama' is not defined
2025-08-13 13:49:48,074 [MainProcess-MainThread] ERROR: ❌ Setup Ollama fallito: name 'wait_for_ollama' is not defined

📈 ANALISI PERFORMANCE:

🎉 JOB PRODUZIONE PARALLELA COMPLETATO CON SUCCESSO!
✅ Tutti i dataset processati con ottimizzazione parallela
🚀 Performance migliorate di ~4x

🕐 Fine job: Wed Aug 13 13:49:48 CEST 2025
======================================================

🧹 CLEANUP PRODUZIONE PARALLELA...
🕐 Tempo totale job: 51 secondi (0h 0m)
📊 Stato GPU finale:
memory.used [MiB], memory.total [MiB], utilization.gpu [%], temperature.gpu
8170 MiB, 65536 MiB, 0 %, 43
📊 Utilizzo CPU finale:
top - 13:49:48 up 27 days, 20:13,  0 users,  load average: 1.57, 3.17, 3.70
Tasks: 627 total,   1 running, 626 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,  0.2 sy,  0.0 ni, 99.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem : 514982.7 total, 494398.4 free,   6160.0 used,  14424.3 buff/cache
MiB Swap:      0.0 total,      0.0 free,      0.0 used. 497301.5 avail Mem 
📄 Risultati generati: 0 files
💾 Dimensione risultati: 4.0K
📊 Dettaglio per file:
🔄 Shutdown graceful Ollama...
✔ Cleanup completato
